Title: The Aviation Development Ecosystem – Applying DO-178C, ARP4754A, DO-254, & Related Guidelines – Chapter(s) 12 Author(s): Vance Hilderman, with 25+ Industry Experts Category: Aircraft, Safety, Regulations Tags: Regulations, Safety, Airworthiness, Certification DO-331 Model-Based Development DO-331 & The Four Supplements. DO-331, Model-Based Development and Verification Supplement to DO-178C and DO-278A, is a 125-page guideline governing model-based development (MBD) usage in airborne and ground-based aviation software. However, since MBD is relatively new to aviation software, the authors of DO-331 faced a large hurdle: how to provide meaningful guidelines to persons generally unfamiliar with model-based development? The answer was artfully handled within DO-331 by combining workable “guidelines” with a high-level MBD tutorial which laid a common foundation for MBD terminology and application. Ask any software developer (and their manager!) “What is the Holy Grail of software development?” and there will be one predominant answer: “software automatically generated from models with 100% reusability”. Admittedly, that answer will be provided with a smile (or a smirk, if interpreted by the engineer’s manager). But software is rarely 100% automatically generated and entirely reusable. Aviation makes ample use of software reusability and few would deny aviation software is among the best, if not the very best, in the entire world of safety-critical embedded software. Aviation authorities operate on the underlying factual premise that no software is perfect, and all software may eventually fail. That fact is unquestioned because the “answer”within aviation software is in detecting and mitigating such failures. Now, broaching modern software development practices causes one to embrace MBD as the “next great hope” in getting us a little closer to that Holy Grail: perfect and perfectly reusable software … At first glance, DO-331 may seem intuitive or almost easy. Whereas DO-178C, DO-254, and DO-278A have objectives covering the entire span of aviation software and hardware engineering and generally align with other safety-critical standards, remember that DO-331 is a “supplement”. Like a nutritional supplement, DO-331 augments, not replaces, DO-178C and DO-278A. The essential Supplements for DO-XXX are: DO-330: Tool Qualification DO-331: Model-Based Development (MBD) DO-332: Object-Oriented Technology (OOT) DO-333: Formal Methods (FM) When using any of above four technologies for aviation development, usage of the corresponding Supplement is usually mandatory. This book presents the above Supplement details in the following order since the following is the normal order of usage within aviation development: 1. DO-331: Model-Based Development (MBD) 2. DO-332: Object-Oriented Technology (OOT) 3. DO-330: Tool Qualification Before delving further into DO-331 MBD details, first consider why these Supplements were necessary, when previously these topics had been dealt with purely informally via certification authority position papers. Why Supplements for Software Technological Evolution? DO-331 provides a mixture of model-based development tutorial and guidelines covering development and verification of software when using modeling. While somewhat intuitive, DO-331’s real value is in the subtleties comprising provably deterministic MBD. With that, consider the following“easy” DO-331 MBD quiz: 1. If you use Modeling but not auto-code generation (e.g. you write code manually), do you still need a Software Modeling Standard and also Model Coverage Analysis? (Yes, No or Maybe) 2. When using models for verification, should expected results be determined prior to test execution? (Yes, No or Maybe) 3. Can the Design Model be developed from System Requirements without first decomposing System requirements to High Level Software requirements (Yes or No) 4. Must the System Requirements first be decomposed to High Level Software Requirements prior to making the Design Model? (Yes or No) 5. If System Requirements are used for the source of requirements in the Design Model, are those System Requirements then treated as High level Requirements and does the Design Model thus contain Low-Level Requirements? (Yes, No, or Maybe) Answers to the above questions are provided within this chapter.. Why Modeling? Software modeling is almost as old as software development, with models being actively used to assist engineers in early national aeronautics and space administration lunar launches. Today, modeling refers to a generic activity whereby structure and behavior by and between objects is defined at a higher level abstracted from logic development. Common usage of “model” implies developing a model of structure and behavior prior to using that model to generate actual software or hardware logic. (Remember, in the avionics world, the term “hardware”includes logic embedded in silicon, previously known as “firmware” but now termed “complex electronic hardware” via DO-254). However, modeling can actually follow the logic development process instead of preceding it; many legacy codebases have modeling applied to them post-facto to airport information desk in understanding, verifying, improving, or reusing those code bases; especially within the field of avionics whereby most systems make at least partial reuse of preceding, similar systems. This process is commonly known as “reverse engineering.” Why is modeling increasingly important to avionics as evidenced by the release of DO-331 in December of 2011? There are many reasons including those below: 1 _ Improveing handling of complex systems 2 – Improvement reusability 3 – Enables automated code generation 4 – improve logic clarity 5 – common language is equal few assumptions 6 – improved traceability 7 – Earlier verification As seen in the above Figure: “Benefits of Modeling”, there are many advantages to modeling complex systems and software. Other software domains such as telecommunications have been utilizing modeling for many years; avionics has been gradually catching up. It should be noted that the realm of avionics software certification guidance is generally devoid of cost and schedule considerations: while no one desires or expects avionics developers to go bankrupt, they are free to do so. Accordingly, what then keeps everyone from unanimously adopting modeling within their avionics development organizations? The following are often cited as reasons avionics developers avoid partial or full use of modeling: 1. Uncertainly about interpreting DO-331 or being held to an overly conservative interpretation; 2. Licensing cost of modeling tools; 3. Learning curve of modeling tools; 4. Perception of difficulty or need to qualify a modeling tool per DO-330; 5. Culture of traditional Systems Engineers preferring to work solely with English text and avoid any modeling tool usage or input; 6. Fear of doing something in a new way; 7. A lack of trust in the quality of the source code generated from models; 8. A concern about the lack of control over the specific source code statements generated from models. Are the aforementioned reasons for avoiding modeling valid? To the extent that perception equals reality for some people, the answer is “maybe”. But with a more informed understanding, perceptions may be changed. First, DO-331 provides a framework for enabling the usage of modeling within a prescribed regimen of modeling standards and model verification: just as for traditional software requirements and software design which must be verified to show compliance to user-defined standards, the same is true for avionics modeling. Second, modeling tool licensing costs are really not that great when considering the cost-savings obtained via engineering productivity improvements; and some modeling tools such as IBM’s Rhapsody™ and Magic Draw are quite affordable while providing the necessary key features. Third, like licensing costs, the learning curve of modeling tools is usually conquered in a matter of weeks or a few months at most; relatively short considering the multi-year duration of most avionic system developments. Fourth, it is not necessary to qualify a modeling tool: while benefits of qualification are noteworthy (such as eliminating the need for manual code peer reviews, automatic code generation, and model-level verification), all the benefits of modeling cited previously apply whether or not the modeling tool is Qualified. Fifth, all engineers are capable of learning new techniques and most actually embrace such knowledge improvements in recognition of the resume-enhancement benefits thereof. So the seeming disadvantages of modeling are readily dispelled. Furthermore, tools such as Simulink, IBM’s Rhapsody and Ansys SCADE tools have been around for 20 years and are quite mature in both the quality of the code that is generated and in the ability to control and customize the generation of that code. However, modeling per DO-331 does require attention to key attributes summarized in the following – Model standard, model requirements, model configuration items, model elements libraries, model and system interfaces, model configuration data index, model environment and user manual. Of particular importance in modeling is adherence to, and subsequent assessment of such adherence to, a modeling Standard. Unlike software coding standards such as MISRA C noted in the previous chapter on DO-178C, DO-331 makes no allusion to such explicit modeling standards. However, a DO-331 compliant modeling standard must provide assessable criteria for the following key topics: modeling techniques, modeling language, modeling tools, modeling guidelines, modeling constraints, identification of various model elements. Modeling Terminology Modeling is a domain which has its own vernacular; common modeling terms are summarized below. Code generation – the generation of a code from a design model in a specific software code language as C, C++ or Ada. Design model – A model that defines any software code design sucha as low level requirements, software architecture, algorithms, components internal data structures, data flow and/or control flow, a model used to generate source code is a design model. Model – an abstract representation of a given set of aspects of a system used for analysis, verification, simulation, code generation, or any combination thereof. It should be unambigous, regardless of its level of abstraction. Model bases development and verification – a technology in which models represent software requirements and/or software design descriptions to support the software development and verification processes. Model based test – the creation of test cases within a modeling language and tool for the purpose of verifying the model and/or generated source code. Model checking – the application of well-formedness rules to ensure that synthatic corrcteness of the models, such as the reachability of states and proper use of modeling language elements. Model coverage analysis – an analysis that determines which requirements expressed by the desing model were no exercised by verification based on the requirements from which the design model was developed. The purpose is to support the detection of unintended function in the design model. Model element – a unit form which a model is constructed Model element library – a collection of model elements used as baseline to construct a model. A model may or may not be developed using model elements lbrary. Model simulation – the activity of exercising the behavior of a model using a model simulator Model simulator – a device computer program or system that enables the execution of a model to demonstrate its behavior in support of verification and/or validation Modeling techniques – a combination ofa modeling language and a particular manner of using this modeling languag. It is driven by the level of abstraction of the information to be represented by the model and the selected modeling tools. Report generation – the generation of documents from a model for the particular purpose, often template-based to generate documents in a standardized format Reverse engineering – the creation of a model from a source code Specification model – a model representing high-level requirements providing an abstract representation of software functional, performance, interface, or safety characteristics. Excludes design details such as internal data structures, internal data flow, or internal control flow. Symbology – the graphical appearance of modeling elements. Some modeling environments allow customs symbology to be defined SysML – the system modeling language, a specialized language variant of the UML for use in system modeling UML – the unified modeling language, which is by far the most common software modeling language in used. The uml has language elements to specified software structures, behaviour, functionality and relationships. Specification Model and Design Model It is important to recall a basic DO-178C tenet is step-wise refinement: system requirements must precede high level requirements (HLR’s) and HLR’s must precede low-level requirements (LLR’s). The temptation to develop code directly from HLR’s must be avoided. Modeling provides the ability to express HLR’s and/or LLR’s directly within a Model. A key facet of DO-331 modeling is the differentiation between a Specification Model and a Design Model as depicted in the following; specification model – typically express high level requirements; desing model – typically expresses low level requirements, may be used to produce code. The Design Model and the Specification Model are different, just as HLR’s differ and precede LLR’s: step-wise refinement. Similar to HLR’s and LLR’s which may reside within the same requirements specification, the Design Model and Specification Model could reside within the same model. But when both models exist, the development of the Specification Model precedes the Design Model. Since the Specification Model and Design Model accomplish different purposes, they each must use a different modeling standard. In the UML, the specification model typically employs use cases to cluster requirements, and then employs various UML mechanisms (state machines, scenario modeling, and activity modeling) to quality and disambiguate requirements. The design model identifies the LLRs needed to meet the refined requirements and specification models. The «trace» relation supports traceability between the requirements, the specification model, and the design model. The process for model development is not specified within DO-178C or DO-331, although those standards specify the objectives with which such processes must comply and the evidence they must produce. A common process is the Harmony Process for Embedded Software (see Real-Time Agility or Real-Time UML Workshop for Embedded Systems 2nd Edition, both by Bruce Powel Douglass). Modeling Strategy Choices Like art, music, and gourmet dining, modeling means different things to different people and there are vastly different means to implement modeling. To narrow down the myriad modeling implementation possibilities, DO-331 describes five different modeling options and advises users to adopt one of those five. As with most decisions in life, there are choices, and one size does not fit everyone. But when considering where you are from, where you are at, and where you are going, a preferred choice can be more readily ascertained. The pro/con of each modeling option is summarized below: MB1 – Traditional engineering but with a design model: Introduces modeling into software development. Enables automatic code generation. Separates systems and software engineering. HLR independent of model MB2 – traditional engineering with both specification and design models Good use of specification model and design model . enables autocode generation. Still has separation of systems and software engineering MB3 – traditional engineering but with a specification model Introduces modeling for HLRs. No potential for autocode generation. potential to disincentivize model upkeep. MB4 – HLRs merge with the system requirements, software engineering develop design model. Promotes system insight and contribution to software requirements. Enables autocode generation. Doesn’t use a specification model so particularly comples may miss stepwise model refinement. MB5 – HLRs merged with system requirements, system engineering develop design model. Promotes strong system centric development and control of HLRs and the model, very little ambiguity. Doesn’t use specification model and possible large step between requirements and code. Inputs to Modeling: Verifying the Model In some software development domains, designers begin with a blank slate or concept, then iteratively evolve a corresponding software model. But in aviation, the “guilty until proven innocent” paradigm holds true: engineering work is not trusted until it is either qualified or verified. So consider: a model needs to be verified; can a model be verified merely by inspecting it? Which of the above five inputs are actually required to perform a requisite model review? All of them, and each of the five must be under configuration management, meaning it has a unique identifier and can be retrieved in exactitude at any time in the future to determine its exact content used during the corresponding model review. Note that a common challenge in modeling is requirement verification; again, models must have requirements (software functionality) which can be used during the model review to assess the correctness and completeness of the model. Verification through Testing In addition to review which assesses the model’s conformance to the applicable modeling standard and system/software requirements, , models themselves may be verified through testing. The UML Profile for Testing defines a standard way for test case specification, architecting, execution and analysis. This may be done by manually creating the test elements and using model simulation/execution to ensure that the outcomes match expectations. Tools such as IBM Rhapsody’s add-on Test Conductor automate some of these steps and may be used as well. Verification through Formal Methods (DO-333) Formal methods are another key means to verify models, especially subsets of system models. Some engineers attempt to verify entire system models via formal methods, and such is ostensibly “allowed” by DO-333 (the supplement commonly applied to DO-178C and DO-278A). However, a“Best Practice” is to instead focus formal method-based model verification to a particular algorithm or set of cohesive algorithms within a model to maximize provability. (See Formal Methods for additional information). Model Simulation Another advantage of modeling is simulation: a model simulator may be used to execute the model earlier in the development lifecycle. Model simulation can be used to airport information desk verification in the following ways: Compliance with system requirements (Specification Models) Compliance with high-level requirements (Design Models) Accuracy and consistency Verifiability Algorithm aspects However, model simulation is not intended for verification of the following: Compatibility with the target computer Conformance to standards Traceability Partitioning integrity Model and Code Verification The UML Testing Profile (www.omg.org) provides a standard approach for specifying, executing, and analyzing test cases in the UML language. This means that all the advantages of modeling can be gained not only from the specification and design models, but also the means by which those models are verified. The IBM Rhapsody tool add-on “Test Conductor” implements that standard and comes with a qualification kit for DO-178. This tool automates test generation, execution and analysis and can provide detailed statistics about model coverage (see the next section) and, when coupled with code verification tools, code-level coverage as well. Model Coverage Analysis & Traceability Since the models are developed by engineers and engineers can neglect to add necessary model details or remove model details which are no longer needed, model coverage analysis must be performed. Model coverage analysis can determine which model elements may not have been completely verified and it can also detect unintended functionality, or unverified elements, within the model. Model coverage analysis may be done via simulation or formal methods; however software structural coverage is performed via actual testing. Model traceability must also exist to prove that each model element is there for a reason. Each part of the model should be traced to: The requirement(s) that it implements, and The source code that implements it. Model traceability can of course be performed manually, but modeling tools increasingly have built-in capabilities to support and provide traceability. Conclusion Modeling is a powerful capability which is increasingly applied to avionics. DO-331 provides a framework to understand modeling, harness modeling’s power, and help prove the model is correct.