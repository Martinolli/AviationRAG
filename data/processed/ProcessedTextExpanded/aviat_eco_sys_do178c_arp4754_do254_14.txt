Title: The Aviation Development Ecosystem – Applying DO-178C, ARP4754A, DO-254, & Related Guidelines – Chapter(s) 13 - 14 Author(s): Vance Hilderman, with 25+ Industry Experts Category: Aircraft, Safety, Regulations Tags: Regulations, Safety, Airworthiness, Certification DO-332 Object-Oriented Technology (OOT) Introduction and History of DO-332/OBJECT-ORIENTED TECHNOLOGY DO-332, Object-Oriented Technology and Related Techniques Supplement to DO-178C and DO-278A, is a 150-page guideline governing OBJECT-ORIENTED TECHNOLOGY usage in airborne and ground-based aviation software. However, since true OBJECT-ORIENTED TECHNOLOGY is relatively new to aviation software, (though Ada ’95 has been around since… 1995), the authors of DO-332 faced a large hurdle: how to provide meaningful guidelines to persons generally unfamiliar with Object-Oriented software? The answer was skillfully handled within DO-332 by blending practical “guidelines” with an introduction to OBJECT-ORIENTED TECHNOLOGY which laid a common foundation for OBJECT-ORIENTED TECHNOLOGY terminology, application and certifiability. There are many ways of approaching software development; hundreds of books are in print with many seemingly preaching their own “methodology”. But as all the many colors in a peacock stem from basic Red-Green-Blue, software development at its most (overly) simplified vantage has two “primary colors”: functional structured implementation and object-oriented implementation. Unlike the peacock, with software these “colors” do not blend well; many software design elements are considered to be either “functional”or “Object-Oriented” but not both. Traditional functional software is implemented by considering then structuring each sequence of computer actions one at a time. Conversely, Object-Oriented software is designed by first articulating software objects and actions to be performed on those objects, then integrating such objects/actions into meaningful groups and events. Yes, functional design may have some objects. Yes, Object-Oriented design will use some sequential structural behaviors. But as a few drops of oil can float on water, that oil and water are hardly integrated; similarly functional and Object-Oriented design are two distinct approaches which in their pure forms do not integrate easily with each other. Prior to the publication of DO-332, safety-critical software developers had few rules for applying OBJECT-ORIENTED TECHNOLOGY. Programming standards such as MISRA C++ were available and well; those were used and should still be applied along with a commercial static analysis tool to sanitize and improve C++ source code. However, clear guidance for safety-critical OBJECT-ORIENTED TECHNOLOGY design and verification was lacking; DO-332 attempts to fill that void. In functional software design, the control flow is preordained by the developer thus the sequence of decisions (“control flow” in DO-178C) is considered along with the input and output data function-by-function (“data flow” in DO-178C). In object-oriented software design, the individual data flow and control flow aspects are encapsulated via objects as depicted in this OBJECT-ORIENTED TECHNOLOGY class diagram; Safety-critical domains including aviation are risk-averse; new technologies are considered suspect until their safety is proven. In safety-critical software, determinism and verifiability are paramount. For many years traditionalists held that functional software development was more deterministic than OBJECT-ORIENTED TECHNOLOGY: structured software’s execution sequencing was easily determined and repeatable. And at the unit level (software functions and collections of functions within a file), functional structured software was more readily verified: source code sections could be traced directly to associated software low-level requirements (LLR’s) and tested sequence by sequence. Thus functional software design readily enabled determinism and verifiability, while doing so reliably for decades. With such a successful track record of reliability, why would anyone desire OBJECT-ORIENTED TECHNOLOGY with its radical paradigm shift? Simple: the very essence of evolution … According to Darwinism, evolution occurs in nature when a genetic change is seen to provide advantages for survival. Similarly for technology, evolution occurs when a change provides economic advantage, which is commercial survival. The software evolution from functional design to OBJECT-ORIENTED TECHNOLOGY occurred for the simple reason that OBJECT-ORIENTED TECHNOLOGY increasingly embodied two economic advantages over functional design: 1) greater ability to manage increasing software complexity, and 2) greater reusability. The seeds of aviation software evolution thus sprouted. To understand the need for OBJECT-ORIENTED TECHNOLOGY is to understand the need for DO-332: aviation software, like all software, was (and still is today) growing dramatically in size, complexity, and thus cost. Enhanced safety meant increased software functionality which meant increased software size and complexity. Functional structured software is fine, even advantageous, when functionality is simple. Computing power increased exponentially according to Moore’s law allowing aviation developers to harness that increased capability. In a recent study for an aviation client, this author analyzed the size and cost of avionics software per aircraft type, and the resulting estimates are summarized in the following table (note this data is informal and un-provable since manufacturers will not reveal financial details and much of this analysis and development was done under Non-Disclosure Agreements): Avionics Software Physical & Financial Aspects per Representative Aircraft Type The following graph (by Dr. Barry Boehm, author of the COCOMO software estimation model and a professor at USC where author received one of his Masters Degrees) depicts related software development effort based upon project size, as measured in Lines Of Code (LOC). Clearly aviation software size, complexity, and cost have steadily increased along with available computing power. Also, the proliferation of different system configurations implied a greater need for software reuse. Structured software’s favorable determinism and verifiability dissipates with increased system complexity while reuse is inherently challenging: seemingly small logic changes may require large analysis and rework effort to ensure continued proper operation. The commercial non-safety-critical world had recognized the power of OBJECT-ORIENTED TECHNOLOGY long before in implementing increasingly large and complex systems with improved reusability. Aviation enjoys leading-edge technology while eschewing bleeding-edge. In its purest form OBJECT-ORIENTED TECHNOLOGY embodies a variety of attributes which can obfuscate determinism and provide verification challenges. Thus OBJECT-ORIENTED TECHNOLOGY was regarded with suspicion. DO-178B and DO-278 preceded widespread consideration of OBJECT-ORIENTED TECHNOLOGY thus offered little guidance. Yet software languages such as Ada 95 embodied key OBJECT-ORIENTED TECHNOLOGY attributes, arguably ahead of its time. While there is little doubt OBJECT-ORIENTED TECHNOLOGY could improve software manageability and reusability, OBJECT-ORIENTED TECHNOLOGY simultaneously has features which can challenge determinism and verifiability; DO-332 is a direct response to those challenges. To better understand OBJECT-ORIENTED TECHNOLOGY’s challenges for safety-critical system and DO-332’s guidelines for compliance, one first needs a brief understanding of OBJECT-ORIENTED TECHNOLOGY itself. OBJECT-ORIENTED TECHNOLOGY Background. In the iron age of computing (fifty to twenty five years ago), software was written manually by conceiving the sequential instruction execution necessary to accomplish an objective. When close hardware support was needed, assembly language was favored for more direct CPU-level control; otherwise source languages such as FORTRAN, Ada, or C were typically used for scientific programming. Aviation software grew exponentially in the 70’s and 80’s, meaning Ada and C predominated as the language of choice. Improving both reusability and complexity management was increasingly important, so smart developers deployed a variety of techniques toward these goals: encapsulation, hardware abstraction, wrappers, and building libraries of software components with generic and robust interfaces. While these techniques improved reusability and complexity management, the commercial consumer and financial sectors went much further: they rethought the entire premise of programming via writing sequential instructions and instead adopted Object-Oriented (OO) programming via a variety of languages designed especially for OBJECT-ORIENTED support. The safety-critical world slowly followed though OBJECT-ORIENTED posed challenges to verification, and thus certification. To understand why OBJECT-ORIENTED had such challenges, it’s necessary to first understand OBJECT-ORIENTED. Instead of merely conceiving and writing (“coding”) sequential instructions for a computer program, OBJECT-ORIENTED developers think in terms of Objects. An object contains encapsulated data and procedures which are combined together and thus represent an entity. An object is a data structure that contains data. Instructions (“code”) are implemented within procedures which are called“methods”. The object has interfaces which describe how it interacts within the program. Instead of thinking in terms of individual sequential instructions, object-oriented developers perform programming at a higher level by defining objects and interactions which consist of groups of instructions instead of single sequential instructions. An object’s methods can access, and possibly update, data within the object. Objects have many forms as shown below: At their most simplistic, there are three basic types of objects as; interface – objects that allow the system to the interface to the real world, devices, actors; control – objects that provide control functions, schedulers, process managers; entity – objects that provide information storage, transaction data, event histories. As can be seen, objects themselves are capable and interesting. But by themselves they are not that useful. Consider an aircraft engine: by itself it too is capable and interesting. However the engine becomes powerful and useful when combined with an aircraft structure, wings, and control systems. Similarly, an object becomes powerful and useful when used within the context of Object-Oriented Programming (OOP). The basic concepts of object-oriented programming are the software design capabilities incorporated within the programming language, typically C++ for aviation and many of today’s safety-critical systems. What is Required For OBJECT-ORIENTED TECHNOLOGY in Aviation? Much of DO-332’s 150-page length can be attributed to its tutorial nature; an OBJECT-ORIENTED TECHNOLOGY framework with definitions must be established to airport information desk consistent compliance. DO-332 doesn’t pretend to provide a full OBJECT-ORIENTED TECHNOLOGY tutorial though it does address the most common OBJECT-ORIENTED TECHNOLOGY issues pertinent to reliability and verification. Those issues largely relate to the very aspects which are unique to OBJECT-ORIENTED TECHNOLOGY, as summarized above. DO-332 prescribes a software engineering process which parallels that of DO-178C; namely written processes for OBJECT-ORIENTED TECHNOLOGY usage including OBJECT-ORIENTED TECHNOLOGY-related aspects added for each of the following already- required aviation software activities: Plans and Standards Software Requirements Software Design Software Code Software Integration Software Verification Configuration Management Quality Assurance Certification OBJECT-ORIENTED TECHNOLOGY within safety-critical systems must address and mitigate those aspects inherently unique to OBJECT-ORIENTED TECHNOLOGY which are potentially risky. Which aspects are those? Simple: those which add “vulnerability” to DO-178C’s requisite traceability, consistency, determinism, reviews, structural coverage, and tests. “Vulnerability” – Potential weakness which may reduce a system’s reliability. To address potential OBJECT-ORIENTED TECHNOLOGY vulnerabilities, DO-332 requires a regimen of assessment, prevention, and mitigation focused upon each aviation project’s specific OBJECT-ORIENTED TECHNOLOGY usage. Therefore a project is required to define how any OBJECT-ORIENTED TECHNOLOGY will be applied to airborne (DO-178C) or ground/space-based (DO-278A) runtime software. Then, vulnerability analysis specific to that project’s OBJECT-ORIENTED TECHNOLOGY must be performed. Projects define their OBJECT-ORIENTED TECHNOLOGY considerations within the following: Software plans (PSAC, SQAP, SCMP, SDP, and/or SVP) Software standards (Requirements, Design, and/or Code Standards) Engineering & Quality Assurance checklists Each aviation project’s plans, standards, and checklists must comply with DO-332 therefore must reflect the results of that project’s specific vulnerability analysis. Therefore each project must consider how its OBJECT-ORIENTED TECHNOLOGY usage may possess vulnerabilities. Each project must consider its software development environment and lifecycle to identify potential OBJECT-ORIENTED TECHNOLOGY vulnerabilities; for those which could potentially exist, a mitigation then verification strategy must be defined and provably performed. OBJECT-ORIENTED TECHNOLOGY clearly has many advantages and its use is growing within safety-critical software domains. The reasons for its initial slow adoption within aviation pertain largely to the OBJECT-ORIENTED TECHNOLOGY vulnerabilities summarized above. Those vulnerabilities are mitigated by constraining related OBJECT-ORIENTED TECHNOLOGY capabilities then verifying conformance with those constraints via reviews of requirements, design, and code to associated standards. However, even if these OBJECT-ORIENTED TECHNOLOGY constraints could result in total elimination of vulnerabilities (and they cannot), there are still several issues associated with OBJECT-ORIENTED TECHNOLOGY which must be addressed; these are described below. OBJECT-ORIENTED TECHNOLOGY Issues & Vulnerabilities in Safety-Critical Software Safety-critical software must be proven to meet defined objectives. Aviation software, like most safety-critical domains, assigns an assurance level to software components based upon that software’s potential contribution to a safety impact. For the higher assurance levels (DAL A-C for avionics software, DAL A-B for avionics complex electronic hardware, and AL 1 -3 for aviation CNS/ATM), those objectives require assessment of the actual logic design and implementation. This design and implementation assessment is termed “white-box” because the assessment must “see inside the box” of design and implementation. Conversely, lower assurance levels do not require white-box assessment but like the higher levels do require black-box assessment. OBJECT-ORIENTED TECHNOLOGY’s many advantages do not come risk-free. At the black-box level, there are small differences between OBJECT-ORIENTED TECHNOLOGY and functional software; these differences mostly pertain to software requirements which could infer a preference for an object-oriented design including networking, communications/video utilizing messaging and packets, and dynamic or high-bandwidth asynchronous processing. However, at the white-box level, OBJECT-ORIENTED TECHNOLOGY’s differences vis-à-vis functional software require additional consideration of the following issues, with DO-332 citing specific activities to address them. DO-332 OBJECT-ORIENTED TECHNOLOGY Conclusion OBJECT-ORIENTED TECHNOLOGY provides many advantages, especially for increasingly complex and continually evolving aviation software systems. OBJECT-ORIENTED TECHNOLOGY provides the ability to greatly improve software reusability, which is the Holy Grail of software development, particularly in aviation. Essentially, when wholly using previously certified software components, only the retest and test re-reviews need be repeated; OBJECT-ORIENTED TECHNOLOGY greatly airborne integrated data system this. Perhaps the largest obstacle to software reuse is political, not technical: everyone knows that building reusable software components saves huge monies on future projects but that building such reusability also increases initial development costs. The first project pays the increased costs for designing in reusability, whereas subsequent projects reap the benefits. Smart companies would be well-advised to place more emphasis on reusability, and its longer-term cost benefits; OBJECT-ORIENTED TECHNOLOGY is one secret to accomplishing that. While beneficial, OBJECT-ORIENTED TECHNOLOGY possesses vulnerabilities which may pose risks. The analogy to human health is strong: humans can almost always benefit from improved health via cardio and strength conditioning. Amateur runners and occasional weightlifters are commonly seen in hospital emergency rooms on Saturdays where they learn that more constrained training regimens yield better and safer results. For OBJECT-ORIENTED TECHNOLOGY, the recommended best practices are summarized below: Ensure each/every component, subclass, and interface has its own: Requirements Traceability Testing (Functional, Robustness, Structural) Templates should be instantiated and tested to each type of argument, unless identical binary ensues (equivalence class) Nested templates and Friend classes prohibited for Levels A, B, & C. Ensure your Data & Control Coupling address your C++ implementation for Levels A, B & C. Read Advisory Circular (AC) 20-148 and apply its software reuse practices even when not seeking formal Certification Authority Reusable Software Component (RSC) classification. For software safety and health, a clear understanding of OBJECT-ORIENTED TECHNOLOGY with formal constraints in software development will likewise yield improved software safety and health. Start any OBJECT-ORIENTED TECHNOLOGY training with a thorough read of DO-332 first as it comprises an excellent tutorial in safe development. DO-330 Tool Qualification Aviation Engineering “Tools” - Overview Systems, Software, and Hardware engineering “tools” are computer programs that help engineers create, analyze, verify, track, modify, produce or specify the application programs being developed. Such tools and programs have been in use since nearly the beginning of computing. Yes, there are other more physical “tools” used in engineering such as oscilloscopes and items from any maintenance/installation technician’s actual toolbox; those are indeed actual tools, but they are not Tools in the sense of aviation engineering. Quite literally the “Tool” in DO-330 refers to software/logic programs which are used within the engineering development or verification of aviation systems. Tools airport information desk the improvement of efficiency and effectiveness in the development process by automating mundane or complex operations; they also bring the level of abstraction and understanding closer to the developer. However, can tools always be trusted or must they be formally “qualified” in some cases? The answer to that important question follows, along with details of performing such tool qualification when necessary. However, it’s not a black and white question, but rather a pragmatic exercise to determine “to what extent should we trust a tool, AND under what conditions do we need to formally qualify our tools?” Today’s high-reliability products utilize development & verification tools within a variety of safety-critical applications; it is virtually impossible to accomplish the engineering development process without such tools. These tools may eliminate, reduce, or automate processes which ensure the correctness of the safety-critical application. Systems for aviation, medical, railroad, space, automotive, and military industries are developed with the assistance of development tools which may contribute to faulty operation resulting in malicious behavior of the application. The development environment can affect the design and behavior of the product and must be taken into consideration. Also, a tool used to assist in verification may be incorrect, leading to an undetected error within the product. In the aviation industry, engineering tools’ potentially negative effects on avionics products must be mitigated and are regulated through the application of RTCA/DO-178C/ED-12C for software and RTCA/DO-254/ED-80 for hardware development programs respectively. And ground-based systems for CNS/ATM (Communication Navigation Systems / Air Traffic Management Systems) also have similar tool qualification needs. What do these aviation related systems have in common? They all rely upon the guidance of DO-330 for tool qualification. And in many cases per DO-330, it’s not necessary to actually qualify a software tool unless the output of that tool is not otherwise verified. DO-330’s tool qualification background is summarized in the following; tools – softwares which doesn’t fly; tools automate – augment or replace certification steps; tools are unique domain, but not airborne; tool developers often differ from users; tool qualification rigor depends upon usage and impact; DO-330 applies to other domains, not only 178C. What is a Tool? Webster’s dictionary defines a tool as an instrument; anything used as a means to an end, something used in the performance of an operation, anything regarded as necessary to carrying out one’s occupation or profession, or a person that is used or manipulated by another (subject of another discussion, but an interesting analogy). RTCA/DO-178C, RTCA/DO-254 and federal aviation administration Order 8110.49 define a tool as a computer program used to develop, test, analyze, produce, or modify another program or its documentation. So for avionics, a tool consists of software itself used somewhere within the lifecycle of avionics systems. Consider the following common types of tools used to develop software below, and ask yourself if they need to be qualified (to be answered in the next section): software development tools – compilers, linkers, modeling tools, code generators; software verification tools – code statica analysis, test execution, structural coverage, test pass/fail checker Each of the tools in the above plays a key role in avionics engineering and each is available ready-to-use, as “commercial off-the-shelf” (COTS) software which can be purchased directly from any of dozens of software tool vendors. Under DO-178B, tools were simply classified as “development”tools or “verification” tools. However, DO-178C does away with such a simple classification because technical advances have allowed for hybrid tools which perform verification while also reducing subsequent development activities; this is explained later herein via tool “criteria”. Tools used during engineering exist in all project phases: requirements specification, software design and code, integration, configuration management, and verification. Although it is possible to develop a safety-critical application in the aviation industry with the use of only implementation tools (compiler, assembler, and linker), this is increasingly unlikely given the complexity and enormity of electronic systems and modern avionics in this era. When is It Necessary to Qualify a Tool? Tool qualification is required whenever the design assurance process(es) described in RTCA/DO-178C or RTCA/DO-254 are eliminated, reduced, or automated by the use of the tool unless the output of the tool is verified. Verification of the tool’s output must be accomplished through the verification process as defined by RTCA/DO-178C Section 6. Remember, in avionics development, “Verification” has a specific meaning (as the following is not official FAA/EASA policy, this author coined it and calls it the “DO-XXX Verification Equation”): V = R + T + A Verification = Review + Test + Analysis DO-330 is modeled after DO-178C in its structure (as it was released nearly simultaneously with DO-178C), and includes the similar three key Processes of Planning, Development, and Integral Correctness. DO-178B Versus DO-178C Tool Qualification Under the former DO-178B (which of course is eclipsed by DO-178C), tool qualification was addressed simply within DO-178B itself and clarified via the FAA’s ubiquitous 8110.49: tools were categorized as simply one of the following: 1. Development Tools:capable of inserting an error within operational flight software; or 2. Verification Tools: incapable of inserting an error, but potentially capable of failing to detect an error in the flight software. However, DO-178B was released in 1992, in the earlier days of advanced software development, which was before associated guidelines for complex electronic hardware (DO-254) and CNS/ATM (DO-278A) were released. The all-too-brief (less than four pages) tool qualification guidelines within DO-178B were just that: often too brief. So new avionics software tool qualification guidance was needed for multiple reasons. there were four key reasons for the introduction of DO-330 “Software Tool Qualification Considerations” to provide the necessary supplementary tool qualification information in one document. Determining whether any tool needs to be qualified is accomplished by assessing the outcome of three questions regardless of the tool category. 1. Can the tool insert an error into the airborne software/hardware or fail to detect an existing error in the software/hardware within the scope of its intended usage? 2. Will the tool’s output not be verified or confirmed by other verification activities as specified within for example, Section 6 of DO-178C for software? 3. Will the output of the tool be used to either meet an objective or replace an objective of RTCA/DO-178C, DO-254, DO-278A, etc.? If the answer to all three questions is YES then the tool will most likely be required to be qualified. The figure below poses these questions via a classic flow chart. It should be noted that the answer to the first and third question is almost always “Yes”, therefore the real question of tool qualification necessity normally comes down to just one question: “Will the tool output be verified?” If the answer is “No” then qualification is almost always required. A simple flow-chart for these questions is depicted below in Figure 4. To be honest, most tools can either insert an error or fail to detect an error; also most tools eliminate, reduce, or automate avionics development/verification processes. Therefore the real question to be answered in determining if a tool needs to be qualified is “Is the output of the tool otherwise verified?” If the output of a DO-178C, DO-254, or DO-278A tool is not verified then almost always that tool must be qualified. Once you determine that a tool needs to be qualified, then you determine the tool’s tool qualifiction level for your application and apply DO-330 objectives to that tool instance. Why Tool Qualification? Flight hardware, software, and systems are normally “certified”. However, tools are used in development and/or verification and the tool itself doesn’t normally fly or execute onboard the aircraft during flight. However, reliance is being placed on the tool to provide evidence and output which meet certification objectives; therefore confidence must be established to prove the tool provides at least the equivalent assurance of the certification process(es) which is/are eliminated, reduced, or automated. The dependability of the tool being used must be established. Establishing the dependability of the tool and building the confidence that the tool provides at least the equivalent design assurance process for the level required is accomplished by the tool qualification process. The first step of which is to establish whether a tool needs to be qualified as described above. Tool qualification determination and rationale, whether or not a tool requires qualification, should be established as early as possible with the certification authority and addressed in the certification planning documents. Tool assessment and evaluation should be performed during the planning phase of the project prior to proceeding with development and verification. If a tool is found not to require qualification, such agreement should be established early in order to avoid issues later in the project. Development may proceed prior to tool qualification being accomplished; however it’s important to consider qualifiability to ensure qualification can be performed when required. This author has encountered numerous projects over the decades which “assumed”tool qualification for a given project was not required; subsequent results were disastrous when use of that tool’s output was later disallowed when the tool was unable to be qualified. DO-330 provides for tool qualification activities to be directly related to the potential tool impact; that impact is based upon both the category of the tool and also the DAL (Design Assurance Level) it’s applied to. Therefore, DO-330 introduces five Tool Qualification Levels (TQLs) based upon three Tool Criteria. There are three tool criteria, meaning a tool’s usage is assessed to fall within one of the following three criteria categories: 1. Criteria 1:A tool whose output is part of the airborne software and thus could insert an error.Example: code generation tool which automatically generates source code from models 2. Criteria 2: A tool that automates verification process(es) and thus could fail to detect an error, and whose output is used to justify the elimination or reduction of: a. Verification process(es) other than that automated by the tool, or b. Development process(es) that could have an impact on the airborne software. Example: model-checking tool which verifies completeness while also checking coverage 3. Criteria 3: A tool that, within the scope of its intended use, could fail to detect an error. Example: structural coverage tool that assesses code coverage How is Tool Qualification Level (TQL) determined? Consider the preceding figure for Tool Qualification Level. If a tool’s output, such as a code-generator, comprises DAL B software, then it’s a Criteria 1 tool with a tool qualifiction level of 2. On the other hand, if the tool is a structural coverage verification-only tool, used on any DAL, it is a Criteria 3 tool with a tool qualifiction level of 5. Which Tools Require Qualification? Not all tools require qualification! By using the three determining questions previously discussed, it is relatively easy to establish which tools will or will not require qualification. Tools which typically reside in the requirements management, configuration management/data management, and quality management categories can generally be excluded from the tool qualification process. Why? Such tools generally do not supply output which either meet an objective or replace an objective of the Annex, or the tool’s output is verified by another verification activity downstream of the tool’s output. However, the assessment of the tool should be accomplished and will establish the need to qualify or not. The tools which generally require qualification fall cleanly into the Criteria 1, 2, or 3 categories. It is important to determine early if a tool needs to be qualified, and if so, its associated tool qualifiction level. Recommendation: even if the tool assessment is thus shown to preclude qualification, cite the tool within the certification planning documents along with the rationale for why tool qualification is not required: be honest, be up-front to prevent problems downstream. Compilers, assemblers, and linkers are typically Criteria 1 tools, but their output is often examined by another verification activity (i.e. review or testing). Therefore, they typically do not require tool qualification. Examples of Criteria 1 tools which may require qualification include: design tools that generate source code (code generators); implementation tools that produce executable code representations; code representations or simulation tools (i.e. not actual); and binary translation tools such as cross-compilers or format generators. Examples of Criteria 2 and 3 tools which may require qualification include: tools that automate code reviews and design reviews against standards; tools that generate test cases and/or procedures from requirements; tools that determine pass/fail status; tools that track and report structural coverage results; and tools which determine requirements coverage results. Avionics code itself, compiler libraries, and Real-Time Operating Systems (RTOS’s) are not considered tools since they form part of the actual executable software/hardware. They are verified by the design assurance process and require no tool qualification but rather full “flight software” certification per DO-178C. Lifecycle For Qualified Tools Quick question: can quality be built-in to a product after it’s developed? Of course not: true product quality relies upon high-quality planning, implementation per plan, and assessment of implementation along with supporting processes. The basic Tool Qualification steps are shown below, in typical sequential order: 1 – determine if tools needs qualification 2 – determina which tool qualification criteria applies 3 – determine wich tool qualification level applies 4 – identify applicable objectives and life cycle data per tool qualifiction level 5 – execute tool life cycle process: planning process, requirements process, design process, coding process, operational integration process, verification process, configuration management process, quality assurance process, certification liaison process. Just as DO-178C requires lifecycle processes for avionics software, DO-330 defines such a lifecycle for qualified tools as shown below in the following Figure. As shown in that following figure, the tool qualification lifecycle consists of three key activities: 1) Tool Planning, 2) Tool Development, and 3) Tool Verification; these activities must be performed sequentially, starting with Planning, then Development, and finally Verification. But continuously performed in the background during each of these activities are the corresponding Integral Processes of Tool Configuration Management, Tool Quality Assurance, and Tool Qualification Liaison. Designating The tool qualifiction level: Tool Qualification Level OK, you’ve identified all your tools, determined which must be qualified and by what Criteria, and are ready to perform the tool qualification starting with tool qualification planning. It is critical for the planner, or planning organization, to master the organization’s or project life-cycle processes, and their mapping to DO-178C/DO-254 Objectives, especially if multiple tools contribute to an Objective. But what is actually required to perform the tool qualification itself? It depends entirely on the tool’s tool qualifiction level. Remember, the reason for the five different tool qualifiction level’s is due to the simple fact that the potential adverse effect of incorrect tool usage or output varies dramatically between tool qualifiction level’s.: tool qualifiction level 1 tool problems are normally more threatening than tool qualifiction level 5 tool problems. Therefore, tool qualifiction level 1 tools require the most qualification rigor and artifacts, while tool qualifiction level 5 tools require the least. If a specific tool is used as a tool qualifiction level 3 tool, are you allowed to qualify it to a higher level, e.g. tool qualifiction level 2 or tool qualifiction level 1? Yes, certainly; you’re always allowed to do more work than required especially if you have unlimited budgets and schedule; but since you are intelligent, you will not do that unless you are reasonably sure you’ll need to prove the higher tool qualifiction level for a subsequent project. Are you allowed to qualify to a lower level, e.g. tool qualifiction level 4 or tool qualifiction level 5? Absolutely not, as those lower levels (ascending tool qualifiction level number means lower level) have fewer qualification objectives. Recommendation: avionics development is extremely expensive and time-consuming already; avoid extra work and qualify the tool to the minimum tool qualifiction level required unless you are certain you’ll re-use the tool on a different project requiring that higher tool qualifiction level. Planning the Tool Qualification. Now, the tool qualifiction level has been formalized, your certification authority has formally approved your plans, or you are reasonably sure they will, so actual tool qualification can begin. The required tool qualification objectives that must be satisfied are detailed in the ten Annex A tables at the back of DO-330. These objectives depend upon the tool qualifiction level, note that the required tool qualification objectives increase as the tool qualifiction level advances from the least rigorous (tool qualifiction level 5) to the most rigorous (tool qualifiction level 1): The first step in planning for software tool qualification is to ensure the tool qualification is necessary, as previously explained. Presuming tool qualification is necessary, the figure above summarizes key qualification objectives and data. First, it is important to understand what objectives you will be required to meet based upon your tool’s tool qualifiction level. DO-330 lists each specific objective based upon tool qualifiction level but the key objectives are cited in the figure above. Again, the key point to understand is that these tool qualification objectives are additive: as tool qualifiction level rigor increases, from tool qualifiction level 5 to tool qualifiction level 1, additional objectives are required. Is it possible that today’s tool qualifiction level 5 tool will be tomorrow’s tool qualifiction level 4 tool, or today’s tool qualifiction level 3 tool will be a tool qualifiction level 2 tool tomorrow? Absolutely. If you even suspect that such an increase in your tool’s tool qualifiction level could be required, should you simply do the additional work today? Yes, if you have surplus budget and schedule; which means probably not as almost no aviation related project has such. If you think there is a reasonable probability your tool will need to be qualified to a higher tool qualifiction level in the future, you should defer those additional objectives with the exception of“independence”. Independence refers to the verification process (reviews, tests, analysis) and if verification was not performed with independence it would need to be done over for the higher tool qualifiction level that required such. Recommendation: perform verification independently, even when not formally required; it may cost a little more for an independent engineer to gain familiarity with the technical artifacts, but the resultant independent verification will be of higher quality – just do it. What are the Traceability Relationships for Tool Qualification? Like the other DO-XXX guidelines, the AFuzion Incorporated training mantra of “Guilty until proven innocent: prove your innocence” reigns true for DO-330. The figure below summarizes the various provable traceability relationships which must be developed and assessed for various tool qualification requirements based upon tool qualifiction level (credit Jon Lynch, AFuzion Inc DER/Engineer). What Information & Data are Required for Tool Qualification? The format and packaging of the tool qualification data needed to be submitted and made available for review is dependent on the type and tool qualifiction level of tool being qualified. As expected, tool qualifiction level 1 tools typically require the most data, whereas tool qualifiction level 5 tools the least. The following Figure 8 summarizes typical tool qualification data by tool qualifiction level and at what stage in the development cycle it is prepared. It should be noted that certification authorities are more concerned about the “quality” of tool qualification data than the “packaging”. Thus there is much leeway to combine tool qualification data within few documents or even within corresponding application software development documents. While it might seem prudent to reduce the number of documents, be forewarned: good tools are leveraged on other projects or customized over time and therefore putting tool qualification data in separate documents actually simplifies re-use and re-qualification over time. And remember, the amount of data needed within each of the data items in the following figure is tool qualifiction level dependent; therefore a thorough reading of all 138 pages of DO-330 should be performed to ensure the required data is included and also to avoid gathering and documenting data which is not required at less rigorous tool qualifiction level’s. Why are some of the data items marked “M” (for “Maybe”) in the following chart? At less-rigorous tool qualifiction level’s, certain data is either not required or can be placed in other documents. For example, data normally contained in a Tool Qualification Plan (TQP) for a tool qualifiction level 5 tool can simply be included in the PSAC, thus negating the need for a separate tool qualifiction plan. Simple. One issue the planner will have to face is whether to produce one tool qualifiction plan per tool or produce a single consolidated tool qualifiction plan for all tools. Some groups opt for the later on this latest project to show how all the Tools are integrated into the life-cycle process. Many tool vendors do not provide a Tool Qualification Certificate with a completely executed Tool Qualification Plan and a complete set of Qualification artifacts. Instead, they provide a Tool Qualification Support Package which the organization has to take ownership of, tailor, as required, then execute to produce qualification artefacts. It is critical that the organization qualifying a tool get their hands on the Tool Qualification Support Package from the tool vendor as early as possible. Typically, a Tool Qualification Support Package contains: 1) a Tool Qualification Plan template; 2) the “default” Tool Operational Requirements; 3) a Tool Verification Plan; 4) Tool Qualification Procedures and Test Cases; 5) source code files or model files required to support the execution of the Test Cases; and 6) a pro-forma Tool Accomplishment Summary. In some cases, the Tool vendor will embed tailoring instructions in the template documents, others will provide a global description document. It is important to review and assess the quality of the tailoring instructions. Organizations will also need to assess the amount of Qualification support they will require from the Tool Vendor to tailor the Tool Qualification Support Package, and sometimes, to execute it. It should be noted the Tool Installation Report is not normally provided by the Tool Vendor and it will be critical that the organization get a good handle on this one. In some cases, it is preferable to produce a single consolidated type inspection report for all the tools. Tool Planning, Development, & Verification. As outlined above, there are three key activities for producing qualified avionics tools: Tool Qualification Planning; Tool Development; Tool Verification Each of these three key activities of tool qualification are described below. But first, consider the varying roles of the Tool stakeholders: 1. Tool Qualification Planning & Data. It should be no surprise that the engineering of qualified avionics tools bears strong resemblance to the engineering of avionics: “plan it”, “implement it per the plans”, and then “verify it”; all while following the Integral Processes of Planning, then Development, with CM, QA and Liaison performed in the background. Tool qualification planning has numerous objectives including: Determine then define the tool’s entire lifecycle and interrelationships between lifecycle processes; summarize such within a PSAC (and/or tool qualifiction plan). Identify the tool development and verification environments and related details, in advance. Specify applicable tool standards for requirements, design, and code; note these can be very similar to (or identical) with, similar standards for avionics software. Identify all applicable DO-330 objectives and define how each is to be accomplished. The output of the tool qualification process will be applicable data including the following; : Tool-Specific Information in PSAC Tool Qualification Plan (TQP) Tool Development Plan Tool Verification Plan Tool Configuration Management Plan Tool Quality Assurance Plan Tool Standards (Rqmts, Design, Code) 2. Tool Development & Data. AFTER the aforementioned tool qualification planning data are documented and reviewed, the tool implementation (or reverse engineering for pre-existing tools) is initiated to those plans. Applicable tool functional requirements, design, and code are developed in that order with transition and integration criteria (including traceability) affirmed and audited. Why are these important and required? Simple: to be qualified, a tool must undergo thorough verification including a minimum testing the tool’s functionality versus the specified functionality in its requirements; tools with more rigorous tool qualifiction level’s will even have additional testing of robustness and structural coverage of the tool’s source code. But testing alone can never by itself ensure high-quality. Like building a skyscraper, testing for earthquake survivability after the building is built is insufficient: such earthquake tolerances would have to be built into the building’s architecture and considered throughout while building the foundation, walls, and floors. Same for avionics tools: quality provisions must be addressed throughout the development lifecycle. Hence DO-330’s objectives for planning, processes, tool requirements/design/coding standards, integration, transition criteria, and traceability. 3. Tool Verification & Data. Just as for certified aviation logic itself, the associated qualified tools used to develop or verify that certified logic require a defined verification process with specific objectives. Verification of qualified tools requires two sequential verification processes: a. Tool verification process, followed by the: b. Tool operational verification and validation process “b” above is unique to tools: certification of avionics software (DO-178C) and hardware (DO-254) do not require operational verification and validation because the “operation” of such flight software and hardware is part of the system level requirements which are verified and validated at that that system level. However, unlike avionics hardware and software, tools do not have system level requirements. Therefore, tools qualified under DO-330 must have an additional process to ensure the tool can be operated as properly intended (“verification”), and that those corresponding tool operational requirements are correct (“validation”). Tool Requirements versus Tool Operational Requirements. Yes, qualified tools need two types of requirements: “Tool Requirements” which specify the tool’s functionality, and “Tool Operational Requirements” which specify the tool’s intended usage. Why two different types of requirements for tools? Remember, tools are commonly used by persons other than the developers of those tools. The tool developers’ work, the tool itself, needs to be verified against the intended functionality of the tool which are expressed as Tool Requirements. The tool user’s work needs to be verified against the intended usage of the tool which is expressed as Tool Operational Requirements. While there is a relationship between what a tool does versus how the tool is operated, the tool requirements are distinct from the tool operational requirements. As a final word, it never hurts to ask for assistance when considering tools in the development process. SEEK GUIDANCE! Remember all tools must be considered, categorized, and possibly qualified. A good practice is to specify in the certification planning documents ALL tools which are to be used and whether or not qualification will be sought. Obtain agreement on tool categorization, tool qualification necessity, and tool qualification methods established early.