Title: Investigating Human Error Incidents, Accidents, and Complex Systems – Chapter(s) 9 - 10 Author(s): Barry Strauch Category: Safety Tags: Human, Error, Investigation, Accidents, Incidents, System 9 Operator Teams In [the University of] Miami’s pass-oriented offense, they [the offensive linemen] do this by acting as one, a solid wall, so that their individual achievement is less visible than their group achievement. The Cane’s offensive line is the best such group in the country, Gonzalez says, because they are selfless and because they adjust to one another’s strengths and weaknesses. They act as a unit, both on and off the field. Jordan, 2001 New York Times Magazine Introduction Complex systems usually call for two or more individuals to operate the equipment. The sheer complexity of these systems, the number of tasks that must be performed, and the amount of information that must be processed call for multiple operators. Further, with additional operators, should a team member commit an error, another could correct it or minimize its consequences. The use of operator teams also enables operators to share duties as needed, helping to balance individual workloads as operating cycles change. Multiple operators work together from operator teams to oversee system operations. Teams have certain characteristics; as Dyer (1984) describes, A team consists of (a) at least two people who (b) are working towards a common goal/objective/mission, where (c) each person has been assigned specific roles or functions to perform, and where (d) completion of the mission requires some form of dependency among the group members. (p. 286) This definition, applying to all teams regardless of their contexts, helps explain the common objective of operator teams in complex systems: safe and effective system operation. Operator teams offer several advantages over single operators, and an extensive body of research supports the efficacy of operator teams in complex systems. As Salas, Grossman, Hughes, and Coultas (2015) write, 154 Teams are advantageous to individuals in many ways. They pool diverse knowledge and skills, allowing for convergent and divergent thinking, the building blocks of creativity and knowledge generation (Hoegl and Parboteeah, 2007). They also provide a source of backup and assistance for overworked or underskilled team members and can be a source of positive affect and increased morale (Salas, Sims, and Burke, 2005). They allow sharing workload so that some operators do not become overwhelmed by task requirements during certain operational phases; they allow specialization among team members so that different types of expertise can be brought to the system, enlarging the scope of expertise possible with only one operator, and they allow operators to observe the others’ performance, and prevent or mitigate the effects of errors before they can lead to serious consequences. The use of teams has become so influential in complex systems that teams have been characterized as “the strategy of choice when organizations are confronted with complex and difficult tasks” (Salas, Cooke, and Rosen, 2008, p. 540). The value of operator teams can be seen in several accidents in which teams provided greater levels of safety than single operators. For example, in a 1989 accident, a McDonnell Douglas DC-10 experienced a catastrophic engine failure that severed all hydraulic lines, leading to the loss of hydraulic systems and, with that, the loss of airplane control (National Transportation Safety Board, 1990). Fortunately, an instructor pilot who was seated in the cabin quickly recognized the severity of the problem and offered to assist the pilots. The instructor pilot had earlier practiced controlling and landing a DC-10 with a similar hydraulic failure in a flight simulator, using extraordinary and unconventional control techniques. He then guided the crew, helped manipulate the available controls, and assisted in bringing the airplane to an emergency landing. Their joint efforts saved the lives of over half the passengers and crew. Yet operator teams, while beneficial to system safety, can also allow the introduction of unique errors into systems because of the potential for errors resulting from interactions within the teams. In such cases, multiple operator teams not only do not enhance safety, but they can degrade it by creating unique error antecedents. This chapter will describe elements that contribute to team effectiveness, types of team errors, and how to identify and determine the effects of the error antecedents associated with operator teams. What Makes Effective Teams Leadership Effective leaders are necessary for effective teams. Burke et al. (2006a) conducted a meta-analysis of the team performance literature to determine the 155 types of leadership skills necessary for effective leadership. They observed that a leader “is effective to the degree that he/she ensures that all functions critical to task and team maintenance are completed” (Burke et al., 2006a, p. 289). They note that effective leaders carry this out by performing essentially two tasks: (1) overseeing team accomplishment of particular tasks and (2) facilitating team interaction and development. In their view, leaders need to be both task-oriented and people-oriented to be effective. Burke, Sims, Lazzara, and Salas (2007) sought to determine what makes team members follow effective leaders. They found that effective leaders engender trust among team members to enable them to follow their leadership. Among other characteristics, they suggest that trust is based upon leaders providing compelling direction to the team so that its members perceive the tasks as challenging, clear, and consequential, as well as an enabling structure that facilitates the team’s accomplishing the necessary tasks. Leaders are seen to genuinely care about the well-being of their subordinates and treat them fairly. They manifest integrity as leaders and provide a safe environment for their subordinates to express their views without fear of risk. Bienefeld and Grote (2014) examined the effectiveness of leadership in a system in which multiple teams work together within the larger system to achieve a common goal. Using a scenario based on an aircraft accident in which the pilots delayed landing after being informed of an inflight fire, they assessed how well teams of flight attendants and teams of pilots worked together, in their respective duties, to communicate the critical information pilots needed to commit to land the airplane as quickly as possible, to pre- pare the cabin and the passengers for the landing, and to communicate with each other to share critical information as needed. They found that “shared leadership” (p. 281), in which leaders of the respective teams led the teams in their tasks, working together toward the common goal, was a “powerful predictor” (p. 281) of the success of the teams in meeting the common goal. Teamwork Researchers have also focused on the role of team members and factors that influence the extent to which they effectively work together to meet the common goal, which is teamwork. Salas, Sims, and Burke (2005) suggest five core components, each of which is needed for effective teamwork: team leadership, mutual performance monitoring (the extent to which team members monitor each other’s performance to catch errors), backup behavior (providing resources to team members when needed), adaptability (recognizing and readjusting performance to respond appropriately to deviations), and team orientation (the tendency for team members to enhance each other’s performance while performing group tasks). These may be manifested differently among different teams, according to the demands on the team engendered by the particular circumstances. Teams work together through what Salas et al. (2005) describe as three coordinating mechanisms, shared 156 mental models among team members of the situation being encountered and the appropriate team response, closed-loop communications in which team members effectively communicate with each other (i.e., provide and under- stand communications as necessary), and lastly, mutual trust. Driskell, Goodwin, Salas, and O’Shea (2006) examined attributes that contribute to effective team member performance. Recognizing that teamwork requires skills in both performing critical system-related tasks and interacting with team members, they studied the interpersonal skills needed for teamwork. They proposed five sets of skills that were needed to interact effectively with other team members: emotional stability, that is, lack of anxiety and being calm and self-confident; extraversion, that is, to include team orientation, social perceptiveness, and expressivity, as well as the ability to subjugate desires for dominance; openness, that is, flexibility and openness to experience; agreeable- ness, which includes kindness, trust, and warmth; and finally conscientious- ness, to include achievement striving and dependability. “We assume,” they write, “ …that team members who possess these personality facets will be more effective under specified conditions than those who do not” (p. 265). Salas, Grossman, Hughes, and Coultas (2015) focused on the role of team cohesion, the extent to which team members want to work together, and team effectiveness. They found that team cohesion is a multi-dimensional trait that incorporates both the task and interpersonal elements of teamwork. They argue that cohesion is a critical element for team effectiveness. DeChurch and Mesmer-Magnus (2010) examined the role of shared mental models in team effectiveness, defining them as “knowledge structures held by members of a team that enable them to form accurate explanations and expectations for the task, and in turn, to coordinate their actions and adapt their behavior to demands of the task and other team members” (p. 2). They found that, regardless of the measurement technique used, the research demonstrates that shared mental models among team members predict the efficacy of team performance. Burke et al. (2006b) examined the role of adaptation (or adaptability) and its role in team effectiveness. They suggest that the ability of teams to adjust their actions according to situational needs, that is, dealing with performance obstacles through innovation and adopting new routines, underlies their effectiveness in adapting to the situation and thus engendering team effectiveness. Team Errors Operators in any complex system can commit errors, but certain errors can only be committed by operator teams. For example, Janis (1972) identified errors that teams of highly qualified individuals committed in several prominent historical events, such as the decision to invade the Bay of Pigs in 157 Cuba in 1961 and the failure of Admiral Husband Kimmell, the commander of U.S. forces in Pearl Harbor in 1941, to prepare for a Japanese assault.* Janis suggests that the cohesiveness of select groups and their subtle deference to respected leaders can lead to what he termed “groupthink.” Groups that succumb to groupthink have difficulty considering ideas or assessing situations that are contrary to their often unspoken norms. Groupthink has since become an accepted construct in psychology to explain certain types of group decision-making errors (e.g., Salas et al., 2005). Teams need time to develop the necessary cohesiveness and deference to the leader that groupthink requires. However, these are not characteristic of complex systems. Although severe consequences resulted from the group-think errors Janis cited, the environments in which the errors were committed were relatively static, and the team members had sufficient time to evaluate the costs and benefits of decision options. That is not the case in complex systems where teams face time pressure, uncertainty, and potentially severe consequences from errors. The literature on team performance, which identifies factors necessary for team effectiveness, has implied that the lack of such factors contributes to team errors. Investigators need to be able to identify unique team errors and their antecedents when describing operator errors in complex systems because most such systems employ operator teams within the systems. While it may take a single engineer, for example, to operate a locomotive, it takes dispatchers working with the engineers (and conductors in some railroads) to ensure that tracks are clear, signals are correct, and that crossovers or switches are properly aligned. DeChurch and Zaccaro (2010), as did Bienefeld and Grote (2014), looked at multi-team systems and system breakdowns. They suggest that the interdependence of different teams working together in a complex system can create difficulties that can lead to errors. As they note (p. 331), “systems fail more often because of between team breakdowns than because of within-team breakdowns,” and as teams become increasingly cohesive, the boundaries between teams may strengthen, potentially diminishing multi-team interdependence. Wilson, Salas, Priest, and Andrews (2007) studied the cause of a particular type of team error, fratricide in military environments, to develop a taxonomy of team breakdown causes. By examining one type of error, team breakdowns, they described how errors in communication, coordination, or in cooperation can lead to errors in team cognition that can lead to fratricide events. * Since Janis completed his work, historians have reexamined Admiral Kimmel’s role in the lack of effective preparations against the Pearl Harbor attack. A number believe that some in the U.S. government, while not knowing of the Pearl Harbor attack in advance, had critical intelligence of possible Japanese military strikes in the Pacific region, which they did not share with Admiral Kimmel. 158 Operator Team Errors It can be seen that the features of teams, team leaders, team members, and the environments in which they operate influence the likelihood of operator team errors. The roles of the operators, companies, equipment designers, and regulators, among others, in influencing operator error have previously been discussed. In this chapter, errors and antecedents of teams operating complex systems will be examined. In addition to the errors that any individual operator can commit, operator teams can, in turn, commit these types of errors: • Failing to notice or respond to another’s errors, • Excessively relying on others, • Inappropriately influencing the actions or decisions of others, and • Ineffectively delegating team duties and responsibilities These errors or breakdowns in team effectiveness, which have been described previously using the terms developed by the researchers themselves, have been adopted in this text to facilitate the ability of the investigator to apply the concepts from research to error investigations. Failing to Notice or Respond to Another’s Errors The most common type of error of operator teams is committed when operators fail to notice or respond to the errors of other team members, what Salas et al. (2005) refer to as mutual performance monitoring as well as backup behavior. This error may result from any number of antecedents, such as one operator not attending to or not monitoring the actions of the other. However, in some circumstances, operators notice the errors of others but fail to respond appropriately, a failure that may be due to cultural influences, as was discussed in Chapter 8. Such an error negates one of the critical advantages of the use of teams: catching or mitigating the effects of the errors of other operators. The National Transportation Safety Board (1994) studied errors in 37 accidents that occurred in the team environment of a complex system—the cockpit of an air transport aircraft. They found that one error, failing to monitor/challenge the performance/errors of another, was one of the two error types they noted that were specific to operator teams. The other, which the National Transportation Safety Board referred to as resource management, will be discussed shortly. Excessively Relying on Others This type of error can occur when operators possess different types or levels of expertise. It can lead to severe consequences when operators rely on other 159 team members to such an extent that they fail to perform their own tasks effectively. Junior operators, who typically work alongside those with more experience, seniority, authority, or status, occasionally commit this type of error. They may disregard their own knowledge and rely excessively on others to decide, act, or perform critical duties. A team error could result if the person being relied upon makes an error or if his or her skills or knowledge is inadequate for the task requirements. This error is highlighted in the case study of this chapter. Inappropriately Influencing the Actions or Decisions of Others Operators may not have sufficient time to effectively assess the situations they encounter, and in the occasionally stressful, uncertain environment that complex system operators may encounter, one operator could exert extraordinary influence on the situation awareness and subsequent actions of the others. In highly dynamic conditions, an operator who assesses a situation incorrectly could adversely affect another’s situation awareness, even if that person had initially assessed the situation accurately. The operator with the inaccurate situation assessment could then create an operator team error by interfering with the assessments of other team members. A 1989 Boeing 737-400 accident illustrates how, in ambiguous situations, one operator can inappropriately influence the other (Air Accidents Investigation Branch, 1990). About 13 minutes after takeoff, the pilots felt what investigators termed “moderate to severe vibration and a smell of fire.” The flight data recorder (FDR) showed that, at that time, the left engine was vibrating severely and exhibiting other anomalies. According to investigators, The commander took control of the aircraft and disengaged the autopilot. He later stated that he looked at the engine instruments but did not gain any clear indication of the source of the problem from them. He also later stated that he thought that the smoke and fumes were coming forward from the passenger cabin, which, from his appreciation of the aircraft air conditioning system, led him to suspect the No. 2 (right) engine. The first officer also said that he monitored the engine instruments and, when asked by the commander which engine was causing the trouble, he said, “It’s the le…It’s the right one,” to which the commander responded by saying, “Okay, throttle it back.” The first officer later said that he had no recollection of what it was he saw on the engine instruments that led him to make his assessment. The commander’s instruction to throttle back was given some 19 seconds after the onset of the vibration when, according to the FDR, the No. 2 engine was operating with steady engine indications. (p. 5) Forty-three seconds after the onset of the vibrations, the commander ordered the first officer to “shut it down,” referring to the right engine. 160 Investigators found that, although the left engine of the two-engine air- the plane had sustained substantial internal damage, damage that had caused the vibrations that the pilots observed, they incorrectly shut down the right engine in the mistaken belief that it was the one that was causing the difficulties. That engine was later found to have been undamaged before the accident. Rather, the left engine, the one pilots believed to have been operating effectively, was found to have been damaged. The pilots recognized this only moments before the accident when it was too late to restart the right engine and avoid the impact. The aircraft crashed short of the runway, striking a motorway. Although no one on the ground was injured, 47 passengers were killed, and 74 passengers and crew were seriously injured in the accident. It is possible, if not likely, that had the first officer said nothing, with the captain’s experience, he would have correctly identified and responded correctly to the engine that had failed. Failing to Delegate Team Duties and Responsibilities Operators must attend to ongoing system operations when responding to emergencies. These can create considerable demands on their attention and can lead to errors in either the emergency response or in system operations. In situations such as these, operators and teams can effectively respond to different operational requirements, responding to emergencies and managing system operations, provided team leaders delegate responsibility to operators to both operate the system and respond to anomalies in these situations. Failing to delegate tasks to team members in nonroutine situations can lead to a team error as the response to either the anomaly, the system operation, or both may be erroneous. A team of three pilots committed this type of error in a 1972 accident involving a Lockheed L-1011 that crashed in the Florida Everglades, a vast national park in South Florida (National Transportation Safety Board, 1973). The three had put the airplane into a hold over the Everglades while they attempted to determine the cause of an indicator failure. The indicator, which had failed to illuminate, signified the status of the landing gear, whether extended or retracted. The three pilots attended to the indicator light but not to the airplane’s flight path, and as a result, they did not notice that the mechanism that controlled the airplane’s altitude had disengaged. The airplane slowly lost altitude until it struck the ground. Researchers at the National Aeronautics and Space Administration later studied this type of error. Using a Boeing 747 flight simulator, they examined the pilots' response to a system anomaly (Ruffell-Smith, 1979). Using actors as cabin crewmembers, they presented pilots with a scenario that included an anomaly and then tried to distract the pilots with nonessential questions from the “cabin crewmembers.” Several pilots responded to the “cabin crewmembers,” became distracted, and committed errors that exacerbated the severity of the situation. As in the Everglades accident, the pilots in the 161 simulators allowed an anomaly to become a serious event by failing to ensure that team members were monitoring the system and by not ignoring non-critical distracters to enable them to focus on more critical tasks during the high workload periods being observed. In response to these findings and to those of several accident investigations, airlines, and the research community developed crew resource management (or CRM) to help crewmembers contribute effectively to both routine and nonroutine system operations. The programs stressed the need for clear, unambiguous delineation and assignment of operator duties and responsibilities in response to nonroutine situations (e.g., Foushee and Helmreich, 1988; Helmreich and Foushee, 1993; Helmreich and Merritt, 1998). Today, cockpit resource management is widely accepted in aviation, marine, and rail operations, as well as other systems where operator teams are used to control the systems. It has evolved to where it no longer merely strives to improve team performance in general but to enhance operator teams’ abilities to mitigate error. As Salas, Burke, Bowers, and Wilson (2001) write, cockpit resource management represents an awareness that human error is inevitable and can provide a great deal of information. cockpit resource management is now being used as a way to try to manage these (human) errors by focusing on training teamwork skills that will promote (a) error avoidance, (b) early detection of errors, and (c) minimization of consequences resulting from cockpit resource management errors. (p. 642) Unfortunately, the research findings on the safety effects of cockpit resource management have not been consistent. Helmreich, Merritt, and Wilhelm (1999), in observing actual flights, found that cockpit resource management training improved the quality of crew performance. However, reviews of the efficacy of cockpit resource management programs have been uncertain. Salas et al. (2001), Salas, Wilson, Burke, and Wightman (2006), and O’Connor et al. (2008), respectively, conducted mega-analyses of research on cockpit resource management to determine the consensus of research on the efficacy of CRM. The findings of each study were consistent in that cockpit resource management training changed operator attitudes regarding teamwork and team effectiveness. However, with regard to changing behaviors and improving safety, the results were mixed. Operator Team: Antecedents to Error Antecedents that lead to individual operator errors can also lead to team errors. In addition, antecedents unique to operator teams can lead to team errors. Antecedent to individual operator errors can harm team effectiveness by degrading the performance of a member of an operator team, thereby leading to team errors. Antecedents that degrade team performance are unique to multiple operators, but the effects may be the same in terms of their adverse influence on team effectiveness. 162 Equipment As discussed in Chapter 4, features of information presentation and control design affect operator performance. Those that apply to single-operator systems apply to operator teams as well, with some additions. These pertain to an operator’s ability to (1) interact with other team members, (2) access the information presented to other team members, and (3) control the system for other team members. Equipment designed for multiple operators enables team members to communicate with each other when needed, access critical information, and maintain system control. However, design features of some systems may interfere with team performance (e.g., Bowers, Oser, Salas, and Cannon-Bowers, 1996; Paris, Salas, and Cannon-Bowers, 2000). For example, some designs prevent operators from learning of other team members’ control inputs and the system information they receive. Actions on keyboards or touchscreens, for example, are not as salient to other team members as are lever movements. Replacing levers with touchscreens can decrease the ability of team members to learn of their colleagues’ control inputs, thereby degrading both individual and team situation awareness. Operator Physiological and behavioral antecedents that lead to errors in single-operational systems can affect operator teams as well. The influence of these antecedents on operator performance in the single-operator or operator-team systems is comparable. Company Companies have a substantial influence on the quality of the teams they employ, as discussed in Chapter 6. Companies evaluate candidates’ interpersonal skills, in addition to their technical expertise, when selecting candidates for operator team positions. Those who are unable to interact effectively with other team members can adversely affect the quality of their team’s performance and companies should screen applicants to assure that those it hires can interact effectively with team members. Foushee (1984) described an incident on an air transport aircraft in which a captain demeaned a first officer and expressly discouraged him from providing input to the conduct of the flight. The captain’s actions degraded the quality of team interactions by belittling a team member and thus discouraging him from contributing to team effectiveness. Because of the captain’s behavior, the first officer was less likely to speak up in response to an error of the captain or even may have been unwilling to mitigate the effects of that error. Since then, operators in many cultures have developed little tolerance 163 for such actions by individuals in positions of responsibility in safety-critical systems. Their behavior reflects on the company’s selection criteria, training, and oversight as much as on them as individuals. The quality of a company’s procedures can also affect the quality of team member interaction and serve as an antecedent to operator team errors. For example, companies can require operators to challenge and respond to each other so that one verifies that another has performed a task or one confirms that he or she received information from the other. Procedures can increase the level of operator contribution to team tasks, encourage operators to observe and participate in aspects of each other’s performance, and reduce antecedents to error among team members. Number of Operators The number of operators performing a given task can influence the quality of the task. An excessive number can degrade communications within a group and lower individual workload to the point that operators become bored, adversely affecting system monitoring and other aspects of performance (O’Hanlon, 1981). However, because of financial concerns, most organiza- tions are more likely to have too few rather than too many operators, and as a result, this will not be considered further. Situations in which the available number of operators is insufficient for the tasks to be performed occasionally occur, especially during nonroutine situ- ations. An insufficient number of operators can increase operator workload, increase individual team member stress, and reduce levels of operational safety (Paris et al., 2000). Yet, the dynamic nature of complex systems can make it difficult to plan for a constant workload. Operating cycles, with differing operator workload requirements, need different numbers of operators. A team that has a suf- ficient number of operators for one operating phase may have an insufficient number for another, and a team that is insufficient for nonroutine opera- tions may be excessive for routine conditions. The adequacy of the number of operators assigned to a task will vary according to the operating phase, its complexity, and the level of operator workload. Team Structure Operators in teams work best when each team member understands his or her tasks, and contributes to the work of the other team members without interfering with their tasks (Paris, Salas, and Cannon-Bowers, 1999). Teams in which members are uncertain of their roles and responsibilities are said to have poor structures. However, as with team size, a team structure that is effective for routine operations may be ineffective for nonroutine situations. As seen in the 1972 accident involving the Lockheed L-1011 that crashed 164 in the Florida Everglades, a team structure effective for routine operations could break down in nonroutine circumstances. Despite their response to what turned out to have been a relatively benign situation, a visual alert that did not illuminate as expected, the team members failed to monitor a critical element of system operations, the airplane’s altitude. Some have found that operators’ roles within their teams can affect their situation awareness and other critical performance elements. For example, in commercial aviation one pilot typically performs the flying duties and the other monitors the subsystem performance and supports the “flying” pilot, although the captain remains in command throughout. On subse- quent flights they generally alternate duties as pilot flying and pilot not flying. Jentsch, Barnett, Bowers, and Salas (1999) reviewed over 400 anony- mous reports that pilots had filed describing their own errors to an anony- mous self-reporting system. They found that captains were more likely to lose situation awareness when they were flying the airplane, that is, actively engaged in system control, and when the subordinate pilots, the first offi- cers, were monitoring the captains’ performance. Captains were less likely to lose situation awareness when the first officers were performing the flying duties and they were monitoring the others’ performance. The findings con- tradict a common belief that active engagement in system control enhances situation assessment. The researchers suggest that monitoring gave the cap- tains the ability to observe system parameters and obtain situation aware- ness better than would have been true had they been flying the aircraft themselves. In addition, the superior–subordinate positions of captains and first officers, which made the latter somewhat reluctant to alert the captains to their errors when they were the flying pilots, may have also contributed to the captains’ reduced situation awareness when they were flying. Team Stability Team stability, the extent to which team members remain together as a work- ing team, can also affect the quality of team performance. Working together allows team members to learn about each other’s performance and work styles, and to develop reasonably accurate expectations of other’s near-term performance, as often occurs with members of athletic teams who have played together over a period of time. The players and the team members learn subtle aspects of each other’s performance over time that enable them to reliably predict each other’s actions, facilitating communications and enhancing performance. In emergency operations, when operators may face intense workload and have little available time, stability can lead to enhanced communications as the operators accurately anticipate each other’s actions without articulating them. However, in some systems long-term stability may not be possible. Contractual obligations and prevailing customs may dictate different 165 work schedules among team members with different levels of seniority. Several airlines, for example, employ thousands of pilots, many of whom fly with pilots they had neither flown with nor even met previously. In systems such as these, the consistent application of standard operating procedures can compensate for the lack of team stability. Well-defined and practiced procedures enable operators to anticipate their fellow operators’ actions in each operating phase, during both routine and nonroutine situ- ations, regardless of the length of time they had been teamed with the other operators. Companies can also use operator selection to counteract the potentially adverse effects of team instability. Paris et al. (2000) suggest that the most critical determinant of the effects of instability on team performance is the skill level of the operator leaving the team. “As a general rule,” they note, “there is little disruption of team performance from turnover, as long as only one team member is replaced at a time and that replacement is as skilled as the person he replaced” (p. 1060). Leadership Quality Leadership has been discussed previously in this chapter. Team leader qual- ity can affect team performance quality, particularly during critical situa- tions. The research is consistent in that team leaders in complex systems contribute to the climate in which the group operates, whether autocratic, democratic, or something in between. Leaders implement rewards and pun- ishments, and assign tasks. In these and other daily interactions, leadership quality affects team performance quality. Military organizations, where adherence to a superior’s orders is required, recognize that effective lead- ers elicit superior team member performance rather than compel it. As a result, leaders are encouraged to obtain voluntary cooperation from their subordinates rather than demand what can become reluctant or grudging cooperation. In commercial aviation early cockpit resource management programs addressed leadership quality as a critical element for successful interaction between superior and subor- dinate pilots. Good leaders attend to both operating tasks and subordinate concerns. Later cockpit resource management programs addressed additional elements of team per- formance and broadened the scope of team membership to include other operators in the system. Cultural Factors Cultural factors and their effects on system performance are discussed extensively in Chapter 8. Suffice to say that different cultures respect and defer to leaders, rules, procedures, and teams differently, and their values can affect the quality of operating team performance. 166 Case Study The relationship of operator team antecedents to errors can been seen in the collision of two commercial aircraft, a McDonnell Douglas DC-9 and a Boeing 727, in heavy fog at Detroit Metropolitan Airport in December 1990 (National Transportation Safety Board, 1991). The DC-9 was destroyed and eight of the 44 people onboard were killed in the accident, although no one on the Boeing 727 was injured. During severely limited visual conditions, the DC-9 pilots mistakenly taxied their aircraft onto an active runway and into the path of the Boeing 727 as it was taking off. The Boeing 727 pilots were unable to see the DC-9 in time to prevent the collision. Heavy fog places substantial burdens on both pilots and controllers at air- ports that lack ground radar, as was the case at the Detroit airport at the time of the accident. If visibility is sufficiently limited, pilots are unable to see beyond a short distance in front of their airplanes, and they would be prohibited from taking off or landing. Conditions at the time of this accident approached, but did not exceed the visibility limits, but Detroit air traffic controllers were unable to see taxiing aircraft from the control tower, and pilots had difficulty establishing their positions at the airport. In these conditions—when planes could still operate but visibility is quite limited—both controllers and pilots rely on each other for airplane location information. Controllers depend on the pilots to inform them of their positions at the airport, and pilots depend on the controllers to separate them from other aircraft. The limited visibility added to the workload of both pilots and controllers. Controllers were unable to verify airplane positions and pilots lacked many of the visual cues needed to verify their positions on the airport. Markings that had been painted on runways and taxiways and served as guides to pilots were also not visible because a thin layer of snow had obscured them. The operator team on the DC-9 consisted of two pilots, a captain, the superior, who was making his first unsupervised air transport flight after a 6-year hiatus, following his recovery from a medical condition that was unrelated to his aviation duties, and a subordinate, the first officer. In the 6-year interval between medical disqualification and his return to flying, the airline ownership had changed, and the airline that had employed him had been purchased by another airline. When he returned to flying the captain had to not only requalify to operate the DC-9 but learn his new employer’s operating procedures as well. The DC-9 first officer had retired from the U.S. Air Force, where he had been a pilot in command of large bomber aircraft. At the time of the acci- dent he was within his probationary first year period with the airline. The airline’s personnel rules allowed it to terminate the employment of pilots in their probationary periods without cause. In the 6 months since he joined the airline, he had flown into and out of Detroit 22 times, only one or two of them, according to his estimates, were in restricted visibility conditions. 167 Cockpit voice recorder data revealed that the first officer exaggerated attri- butes of his background to the captain. Unsolicited, he told the captain that he had retired from the air force at a rank that was higher than the rank that he had actually attained. He claimed to have experienced an event when fly- ing combat operations, before joining the airline, that he had not experienced. During the taxi from the gate he committed several errors, while ostensibly assisting the captain. Even when uncertain in the restricted visibility that was prevailing, he unhesitatingly gave their location to the captain, even though he was not certain of all the locations, and he continued to do so after misdirecting the captain on the airport surface, thereby requiring the air traffic controllers to give them a new taxi clearance to the active runway. Although in this type of airplane captains steer the airplane while taxi- ing, both pilots work together using airport charts and external visual infor- mation to verify that the taxi route they follow corresponds to the assigned route. Both also simultaneously monitor air traffic control communications for pertinent information, and they monitor the aircraft state. Early in their taxi the first officer told the captain, “Guess we turn left here.” The captain responded, “Left turn or right turn”? The first officer answered by describing what he believed to be their position. The captain then answered, “So a left turn,” and the first officer agreed. Ten seconds later he directed the captain, “Go that way” and the captain complied. This type of exchange between the captain and first officer continued for about 2 minutes, until the first officer, in response to an air traffic controller’s question about their loca- tion answered, “Okay, I think we might have missed oscar six,” the name of the taxiway to which they had been assigned. By misdirecting the captain to a wrong turn on the airport he had endangered the safety of the flight, but neither pilot had apparently recognized the significance of that error. Yet, even after being misdirected, the captain continued to accept the first officer’s guidance. For the next 5 minutes the captain continued to ask the first officer, “What’s he want us to do here,” “This a right turn here Jim,” and “When I cross this [runway] which way do I go, right”? and other similar questions. The first officer continued to direct the captain until they crossed onto the active runway and encroached upon the path of the departing Boeing 727. By the time of the accident, the first officer had provided all taxi instructions to the captain, which the captain followed without hesitation. The captain made a key operator team error by over-relying on the first officer. His error is understandable given his return to active flying after the long hiatus, and his likely belief in the first officer’s superior airport knowl- edge gained from more recent experience operating at Detroit. The first offi- cer’s seeming confidence in his knowledge of the airport routing appears to have exacerbated the captain’s preexisting tendency to rely on him while navigating on the Detroit airport surface. The interaction of an overly asser- tive subordinate, with a tendency to exaggerate his accomplishments and knowledge, albeit a tendency the captain could not have been aware of, and a superior relatively inexperienced in the circumstances that existed at the 168 time, combined to create unique operator team errors. Had the captain relied less on the first officer and been more attentive to information on their air- port position, the accident may have been avoided. Summary Complex systems often require operator teams, two or more operators work- ing toward a common goal or objective. They can enhance team performance by helping to prevent errors and mitigate the effects of errors that have been committed. Multiple operators can reduce individual workload, and assure that necessary tasks are performed during nonroutine or emergency situa- tions. Teams depend upon the effective work of each team member and good leadership qualities of the team leader. Operator teams in complex systems can also commit errors unique to teams. These include failing to notice or to respond to another’s error, rely- ing excessively on others, incorrectly influencing the situation assessment of others, and failing to ensure that duties and responsibilities are delegated. Antecedents to these errors may lie within the culture or the company, or result from other factors specific to operator systems. Antecedents of error in both single-operator and operator team systems include those discussed in previous chapters, such as equipment design, operator factors, company and regulator factors, as well as several that are specific to operator teams. These include the shortcomings in the number of operators for the task, team structure, team stability, leadership quality, and cultural factors that can degrade team performance. DOCUMENTING ANTECEDENTS TO OPERATOR TEAM ERRORS GENERAL • Determine the critical errors that are believed to have led to the event and identify the team members who likely committed those errors. • Determine the number of tasks that operators attempted to perform, the amount of time available to perform those tasks, and the actions and decisions of each team member by inter- viewing operators, examining recorded data, and referring to operating manuals and other documents. • Document pertinent antecedents to single-operator type errors (such as those resulting from performance or procedural deficiencies, discussed in previous chapters) and examine potentially relevant equipment, operator, and company factors if the error appears to be an operator type error. OPERATOR TEAM ANTECEDENTS • Document the number of operators called for and the number of operators involved in system operation at the time of the event. • Assess the adequacy of the number of operators available to perform the tasks in the allotted time. • Identify the duties of each team member and determine the extent to which each team member understood his or her duties, and performed them. • Determine the length of time that the team members had worked together as a team. • Describe communications among the team members, and supervisor/subordinate communications. • Examine the ease with which the equipment used enabled team members to recognize and become aware of the informa- tion received by their fellow team members and their actions with regard to the system. • Document company training, guidelines, and procedures that relate to team performance, and assess the extent to which these encourage team integration and team performance. • Assess the proportion of training, guidelines, and procedures devoted to team performance and the extent to which they call for team, as opposed to individual, operator tasks. • Document interpersonal skills of operator applicants and lead- ership skills of supervisor applicants by examining company selection criteria and history, and interviewing supervisors, subordinates, and colleagues. • Assess the extent to which the training, guidelines, and proce- dures pertain to team structure, team member responsibilities, and leadership qualities. 10 Electronic Data The telltale recorder, known as a Sensing and Diagnostic Module or S.D.M., was one of six million quietly put into various models of General Motors [G.M.] cars since 1990. A newly developed model being installed in hundreds of thousands of G.M. cars this year records not only the force of collisions and the air bag’s performance, but also captures five seconds of data before impact. It can determine, for example, whether the driver applied the brakes in the fifth second, third second or last sec- ond. It also records the last five seconds of vehicle speed, engine speed, gas pedal position and whether the driver was wearing a seat belt. Wald, 1999 New York Times Devices that record system parameters are found in many complex systems, providing valuable investigative data. Traditionally associated with commer- cial aircraft, these devices are increasingly found in other systems, including railroad locomotives, marine vessels, and, as noted, automobiles. Types of Recorders In general, two types of devices have been used to capture data in complex systems, audio/video recorders and system-state recorders, although on occasion devices intended for other purposes may provide helpful informa- tion as well. Security cameras, for example, which are proliferating across many domains as their cost declines, can provide valuable data to both acci- dent investigators and criminal investigators. More recently, the decreasing cost of capturing and recording video data has enabled many companies who would otherwise not have done so to place video recorders in opera- tor consoles to capture images of operators during system operations. Each device, whether a camera or direct system recorder, collects information that could give investigators insight into the state of the operating system, its components and subsystems, the operating environment, as well as operator actions. 176 Audio/Video Recorders Because of their prominence in aircraft accident investigations, cockpit voice recorders, often referred to as “black boxes,” are among the most well-known recorders that investigators use. These record aircraft cockpit sounds in a flight’s last 2 hours of operation. Audio recorders are also found in other systems. Air traffic control facili- ties record communication between pilots and controllers, and electronically transmitted voice communications among controllers. Marine vessel traffic centers capture communications between vessel operators and ground sta- tion personnel, and railroad control facilities record voice communications between dispatchers and train crews. Video recorders are not extensively used in complex systems at present, pri- marily because of both technical and legal reasons. Until recently, the costs of rewiring systems to employ video recorders and store the recorded data were prohibitive, and the size of recording equipment interfered with sys- tem operations. However, technical improvements have lessened the scope of these shortcomings and video records of system operations are becoming increasingly available to investigators. The use of video recorders in accident investigations has also raised legal issues that have limited their use (Fenwick, 1999). Concerns such as operator privacy, post-event litigation, and unauthorized release of video data have yet to be resolved, and many potential users are reluctant to use them until these issues are resolved to their satisfaction. However, many investigators have called for the installation and use of video recorders to enhance safety (e.g., National Transportation Safety Board, 2000). As these calls increase and as technical advances continue, video recorder use in complex systems will almost certainly increase. Video recordings, whether still or motion, can provide critical information on the actions of the operator before the acci- dent. Investigators can use this information to determine how closely those actions matched other information about the accident, and whether the oper- ator performed as appropriate for the particular circumstances at the time. System-State Recorders System-state recorders are found in many systems. In air transport aircraft they continuously record several hundred flight parameters over a 25-hour period. The International Maritime Organization has required internation- ally operating marine vessels to be equipped with voyage data recorders, devices that record the ship’s position, speed, heading, echo sounder, main alarms, rudder order and response, hull stresses, and wind speed and direction, for 12 continuous hours (Brown, 1999). The U.S. Federal Railroad Administration requires trains that can exceed 30 miles per hour be equipped with event recorders that record speed, direction, time, distance, throttle position, brake application, and, in some cases cab signals, for 48 continuous hours (Dobranetski and Case, 1999). 177 The value of the data that system recorders capture was evident in the investigation of a 1997 passenger train derailment. The accident occurred after a flash flood had weakened the underlying support of a bridge that the train was traversing (National Transportation Safety Board, 1998a). According to investigators, All four locomotive units were equipped with GE Integrated Function computer event recorders … The data from the lead locomotive indi- cate that the train was traveling approximately 89 to 90 mph, with the throttle in position 3 (with a change to 4 and then 1), when the brake pipe pressure decreased from approximately 110 to 0 psi, and the emer- gency parameter changed from NONE to TLEM [Train Line Induced Emergency]. Within the next 2 seconds, the pneumatic control switch (PCS) parameter changed from CLOSED to OPEN. Between 2 and 4 sec- onds after the PCS OPEN indication, the position of the air brake han- dle changed from RELEASED to EMERGENCY, and the EIE [Engineer Induced Emergency] parameter changed from OFF to ON. (p. 39) Investigators recognized from these data that the emergency brakes had been applied before the derailment, information that was critical to under- standing the engineer’s performance. Thus the engineer had attempted to stop the train before the derailment, but was unable to do so in time. Recorders need not necessarily be physically located within a system to capture data. For example, large airports are equipped with detectors that record weather data such as ceiling level, visibility, wind direction and velocity, barometric setting, and precipitation amount and duration. Some electrical generating facility smokestacks are equipped with detectors that measure and record wind direction and velocity, and some bridges have the ability to capture and record the water levels underneath them. Other Electronic Data Investigators can often obtain recorded data from a variety of sources, some of which may have been implemented for purposes other than accident investigation. For example, government agencies, companies, and individu- approach light system place security cameras in and around buildings, equipment, yards, and other facilities, equipment that could provide information on the actions of critical people, as well as changes in lighting, weather, and equipment condi- tion. Computers, smart phones or other data storage devices that operators, supervisors, and others use may also contain valuable data. The value of data from these recorders that were not part of the system was apparent in the investigation of a September 1989 accident involving a DHC-6, an airplane that was not equipped with recorders at the time (National Transportation Safety Board, 1991). Eight passengers and the two pilots were killed in the accident. Investigators obtained a video recording from a passenger video camera used during the flight. Because there was 178 no barrier between the airplane’s cockpit and the cabin, passengers had an unobstructed view of the pilots. The video showed the pilots’ arm and hand movements during the accident sequence, information that demonstrated that they had difficulty controlling the airplane during the landing, and had attempted to stop the landing to try again. However, in attempting to reject the landing each pilot tried to operate the same controls at the same time. Their arm motions interfered with each other’s actions, and they rapidly lost control of the airplane. The information was invaluable; without it investiga- tors would have had substantial difficulty determining the accident’s cause. Investigators of a marine accident made a particularly innovative use of security camera recordings to determine the angle at which the vessel heeled, or turned on its longitudinal axis, during a turn after the operator mistak- enly turned the vessel in a series of increasingly greater turns to counter what had initially been mildly excessive steering commands by the vessel’s integrated navigation system (National Transportation Safety Board, 2008). Because of limitations in the instrumentation used to measure and record certain data, the vessel’s voyage data recorder showed the vessel heeling to 15°, the maximum angle the recorder would read. By contrast evidence from passenger injuries and damage to objects throughout the vessel suggested a greater heeling angle. Video cameras, for example, recorded passengers being thrown out of the pool as the pool water moved in increasingly greater motion, consistent with increasing heel angles. As can be seen in Figure 10.1, by noting the time stamped onto the image of a security camera that captured part of the external side of the vessel, and noting the sun’s angle on the horizon in the photo, and measuring the differ- ence between the “angle of the shadow created by the vessel on a reference point on the images and the angle that would have been created by the ship’s orientation to the sun at that time, given the sun’s angle over the horizon and the ship’s orientation” (p. 20), investigators determined that the actual heel- ing angle was 24°, an angle well-beyond what cruise vessel passengers could reasonably expect to encounter on a vacation cruise. By using data from a security camera, investigators were able to determine the actual vessel heel- ing angle more accurately than was measured by the instrument installed on the vessel to do so. As they described in the text accompanying Figure 10.1, Image of the Crown Princess taken by a ship’s video camera at the maximum angle of heel, with reference lines added by investigators. Stamped time corresponds to 1525:02 eastern daylight time. The apparent bending of the horizon is an artifact of the wide-angle camera lens, which causes straight lines to appear curved and bow outward from the image center. (p. 21) System Recorder Information Audio Recorders Audio recorders can provide real-time information on both the operator and the equipment. The operator. Audio recordings reveal operators’ verbal interactions in oper- ator teams. For example, in airline operations pilots perform procedures in strict order, established on checklists that are specific to the different operat- ing phases. Generally, one pilot identifies the checklist item and the other performs and articulates the action taken in response, or describes the sta- tus of a particular component. Recordings of pilot statements or comments can help investigators determine whether they completed the required tasks, and the sequence in which they performed the tasks. This information was particularly helpful in the investigation of an August 1987 MD-80 accident in Detroit, Michigan (National Transportation Safety Board, 1988). The pilots were following the checklist while they taxied the airplane from the terminal to the runway. The checklist included a step that called for one pilot to extend the flaps and slats for takeoff, and the other pilot to verify that this had been accomplished, a critical action because tak- ing off with the flaps and slats retracted jeopardize the safety of flight. Audio recorder data revealed that the pilots’ checklist review was inter- rupted when an air traffic controller requested information from them. The pilots responded to the controller and resumed the checklist tasks but at the wrong checklist location, inadvertently omitting several required steps, including verifying the flap and slat extension. They attempted to takeoff but the airplane was unable to climb. It crashed shortly after the start of the takeoff, killing all but one of the more than 150 passengers and crew onboard. Cockpit voice recorder data enabled investigators to learn not only 180 the nature of the operators’ error, but the context in which they committed the error as well, giving investigators a fairly comprehensive perspective on the pilots’ error. Audio recorder information can also complement other operator-related data. For example, after an extensive inquiry, investigators of a September 1994 accident involving a Boeing 737 that crashed near Pittsburgh, Pennsylvania, determined that the rudder had abruptly moved to one side just before the accident (National Transportation Safety Board, 1999). This caused the airplane to turn left and dive abruptly to the ground. Investigators had to determine whether the airplane’s turn had been initiated by pilot action or by the rudder itself, because the flight recorder data showed the turn but not its source. Investigators used different techniques to understand the cause of the turn. They analyzed sounds that the pilots made during the accident sequence and compared them to the sounds that they had made during routine por- tions of the flight. By examining elements of pilot sounds, including voice pitch, amplitude, speaking rate, and breathing patterns, investigators deter- mined that, The first officer emitted straining and grunting sounds early in the upset period, which speech and communication experts stated were consis- tent with applying substantial physical loads; the cockpit voice recorder [cockpit voice recorder] did not record any such sounds on the captain’s microphone channel until just before ground impact. After about 1903:18 (about 5 seconds before ground impact) … the captain’s breathing and speed pat- terns recorded by the cockpit voice recorder indicated that he might have been exerting strong force on the controls. (pp. 247–248) These sounds, with other information, convinced investigators that the pilots did not initiate the turn and subsequent dive. The straining and grunt- ing sounds heard on the recording were characteristic of those made during utmost physical exertion. Pilots would make these sounds when forcefully attempting to counteract a maneuver, not when initiating one that would have taken little physical effort. Audio recorder data can also reveal operators’ perceptions of the events they are encountering, giving investigators critical information about their decision making. For example, in the January 1982 accident of a Boeing 737 that crashed in Washington, D.C., cockpit voice recorder information showed that neither pilot understood the meaning of engine performance display data (National Transportation Safety Board, 1982). The flight had been delayed during a snowstorm. To speed their departure from the gate, the captain inappropriately applied reverse thrust, designed to redirect jet engine thrust forward to slow the airplane on landing. On some aircraft, reverse thrust was permitted for exiting the gate area. However, on airplanes with wing-mounted engines, such as the Boeing 737, the engines are close to the ground and the use of reverse thrust in the terminal area could redirect debris into the front of the engines and damage them. 181 The pilot’s use of reverse thrust at the gate caused snow and ice to block critical engine probes in the front of the engines, invalidating the data that several of the five engine displays presented. Four gauges, which displayed data from internal engine functions, presented accurate information. With two engines on the Boeing 737, five engine-related displays were presented in each of two columns, one for each engine, a total of 10 gauges in all. The two accurate displays were located in the topmost of the five rows (Figure 10.2), the ones that measured engine RPM and were not dependent on the blocked engine probes, as were the gauges in the remaining four rows. The analog gauges presented conflicting information that digital displays in modern aircraft would likely display as well (because of regulator requirements on engine data to be displayed), but with associated warnings on other displays indicating the discrepancies between the presentations. After he applied takeoff thrust, the first officer recognized that the engine instruments were providing unexpected information. Yet, neither pilot could understand the nature of the unfamiliar data, or the significance of the presented information, a diagnosis they attempted to achieve while the airplane was rolling for takeoff and thus, just seconds before a deci- sion needed to be made as to whether to continue the takeoff or stop the airplane on the remaining runway while it was still safe to do so. Neither pilot appeared to have encountered the data previously, either in training or during an actual flight. The first officer asked the captain, “That don’t seem right, does it?” Three seconds later he again said, “Ah that’s not right.” The captain responded, “Yes it is, there’s eighty [knots].” Almost immediately, the first officer answered, “Nah, I don’t think that’s right.” Nine seconds later he again expressed uncertainty, “Ah, maybe it is,” he said. Four seconds later, after the captain declared that the airplane’s speed had reached 120 knots, the first officer said simply, “I don’t know.” They continued with the takeoff, and the accident occurred 38 seconds later. The pilots’ comments, with other data, showed investigators that • The pilots were unable to interpret the displayed engine data in the time available to make an informed go/no-go takeoff decision • The captain misinterpreted the displayed data • The first officer was uneasy with the captain’s interpretation, and • He nevertheless acceded to it This information allowed investigators to understand the nature of the crew’s decision making and suggest strategies to improve pilot performance in similar situations. Recorded audio data can also allow investigators to compare changes in operator vocalizations, potentially revealing much about operator perfor- mance. For example, investigators of the 1989 grounding of the oil tanker Exxon Valdez, in Alaska’s Prince William Sound, compared changes in the 182 tanker master’s voice during communications with the U.S. Coast Guard’s Port of Valdez vessel traffic center 33 hours before, 1 hour before, immediately after, 1 hour after, and 9 hours after the grounding (National Transportation Safety Board, 1990). His speech rate significantly slowed, and other vocal characteristics, such as articulation errors, were found that were consistent with the effects of alcohol consumption. With other evidence, the recorded audio information supported investigators’ conclusions that the master was impaired at the time of the grounding, and that his alcohol-related impair- ment contributed to the accident. The Equipment Recorded data can disclose critical features of aurally presented information such as alerts, their sound characteristics, time of onset and of cessation, and operator statements in response to these sounds. Investigators used this infor- mation in their investigation of a 1996 Houston, Texas, accident in which the pilots of a DC-9 failed to extend the landing gear before landing, causing sub- stantial damages to the airplane (National Transportation Safety Board, 1997a). Airplanes are required to have alerts that sound if the pilots do not extend the landing gear before landing. Investigators sought to determine whether the warnings alerted, and if so, the nature of the pilots’ response. Cockpit voice recorder data revealed that the pilots had omitted a critical step on the pre-landing checklist, which called for one pilot to engage the hydraulic system, the mechanism that powers the flaps and the landing gear, and the other to verify that the system had been engaged. However, because they had omitted this step and did not engage the hydraulic system, they were unable to extend the flaps and landing gear. Although they knew that they could not lower the flaps, the cockpit voice recorder indicated that they did not realize that they had not extended the landing gear. Cockpit voice recorder information revealed that an audible alert, indicat- ing a retracted landing gear, sounded before landing. Concurrently another more prominent alert, the ground proximity warning system alert, was also heard. The simultaneous sound of the two alerts (a result of a single phe- nomenon, the retracted gear), interfered with the pilots’ ability to determine the cause of the alerts. Instead, they focused on maintaining a safe landing profile and did not recognize that the gear had not been extended. Audio recorders may, on occasion, document information that they had not been designed to capture. For example, in the Washington, DC, Boeing 737 accident discussed previously, the cockpit voice recorder recorded changes in the engine pitch, corresponding to increases in engine thrust for the takeoff. Investigators analyzed these sounds to measure the approximate amount of thrust that the engines generated; a parameter that flight data recorders capture today but did not at that time. The analysis showed that the amount of thrust actually generated was con- siderably less than the amount the pilots had attempted to establish, and less than what they believed the engines had been generating. As shown in Figure 10.2, the amount actually generated was consistent with data that the top two rows of the 10 engine-related gauges displayed, the gauges on which the cap- tain was primarily focusing, but inconsistent with data that the other gauges displayed. The discrepancy between the amount of engine thrust actually 184 generated and the amount the pilots expected proved critical to understand- ing the accident. The thrust actually generated was insufficient to overcome other adverse weather-related characteristics of the flight. However, because the pilots focused primarily on the two gauges that displayed the engine RPMs, believing that it would indirectly show the amount of thrust actually generated, they were unable to understand or resolve the discrepancy. System-State Recorders System-state recorders can provide data captured in the period leading up to and through the event that give extraordinary insights into operator actions and system responses. In railroad operations for example, event recorder data describe several aspects of system responses to engineer actions, data that alone would be quite valuable, but when combined with other data, such as obstructions to visibility, track curvature, grade, and bank angle, the information could enable investigators to identify antecedents to operator errors and understand their effects on operator performance. The value of system-state recorder information was evident in the inves- tigation of the January 1997 crash of an Embraer Brasilia, in Michigan (National Transportation Safety Board, 1998b). The flight data recorder cap- tured 99 parameters of airplane performance, information that, combined with other recorded data from the cockpit voice recorder, air traffic control radar and communications, and meteorological sources, gave investigators a comprehensive understanding of the state of the airplane and of the operator actions up to the accident. These data showed that the pilots had slowed the airplane to a speed that would ordinarily have been acceptable for safe flight. However, analysis of the airplane’s flight path suggested that it had likely passed through an area of icing just before the accident, leading to ice accumulation that investiga- tors determined was likely imperceptible. Its flight characteristics were con- sistent with those of an aircraft adversely affected by ice accumulation on its wings. Although the airspeed would otherwise have been adequate, the ice accretion caused a control loss at the particular airspeed that the pilots had established in those meteorological conditions because ice contamination on an airplane’s airfoil or wing increases the speed at which the airplane will stall. What had been an acceptable speed for safe flight became an insuffi- cient speed because of the ice contamination. Integrating Information from Multiple Recorders When combining data recorded in different recorders, applying a common standard or metric to align and match the data helps to clarify the often diverse information. Because many recorders capture elapsed time, the use of a standard time common to the various recorded data allows investiga- tors to compare data from multiple recorders. For example, this process 185 allows one to compare operator statements obtained from audio recorders to parameters obtained from system recorders, to assess changes in operator statements that may relate to changes in other system features. Investigators of the May 1996, DC-9 accident in the Florida Everglades, plotted the data from the flight data recorders, cockpit voice recorder, and air traffic control radar on one diagram to create a three-dimensional plot of the airplane’s flight path, displayed in Figure 10.3 (National Transportation Safety Board, 1997b). By comparing data from the three sources of recorded information, investigators found that, The flight was normal until 1410:03, when an unidentified sound was recorded on the cockpit voice recorder. At 1412:58, after about 30 sec- onds at 7,400 feet mean sea level altitude with a gradual heading change to 192°, the radar indicates an increasing turn rate from the southerly direction to the east and a large increase in the rate of descent. Flight 592 descended 6,400 feet (from 7,400 feet to 1,000 feet) in 32 seconds. Computations of airspeed, based on radar data, indicate that the airspeed of flight 592 was more than 400 KIAS and increasing at the time of ground impact, which occurred about 1413:40. (pp. 55, 58) The constructed plot, Figure 10.3, shows the flight path, altitude, and posi- tion of the airplane, selected background sounds, and pilot statements to air traffic controllers. The plot presents a readily interpretable picture of the airplane’s path, as the pilots gave controllers increasingly urgent accounts of the smoke and fire in the airplane. Assessing the Value of Recorded Data Audio Recorder Data The quality of the recording components and the level of ambient noise affect the quality of audio recorder data. Defects in microphones, recording media, and drive speed, can degrade the recorded sound quality and detract from the ability to identify and interpret the sounds. The distance of the microphone from the operators or system sounds also affects sound quality, unless microphones that are designed to detect sounds at great distances are used. In general, the greater the distance between the microphone and the soun ds that are being recorded, the lower the quality of the recorded data. System-State Recorder Data The quality of system-state recorders, though relatively immune to many of the features that could degrade audio recorder data, is primarily influ- enced by two factors, the frequency with which the data are sampled, and the number of system parameters that are recorded. Because at any one point complex systems measure a potentially unlimited number of parameters, the more parameters that are sampled and recorded, the more comprehensive the subsequent portrait of the system. Recorders that capture hundreds of system parameters provide a more comprehensive, and hence more valu- able, description of the system and its operating environment than those that record only a few parameters. Similarly, because of the dynamic nature of many complex systems, the more often system recorders obtain and record the data, the more accurate the view of the system that is obtained. A device that captures data every second gives a more complete, and hence more accurate, account of system operations than one that captures data every third second. Summary Many systems are equipped with equipment that records critical informa- tion about system equipment, components, operating environments, and 187 operator actions. Because of technological innovations and other factors, relatively inexpensive video cameras are often found in or near accident sites, thus potentially providing valuable information about a system in the moments before an accident. Images from video recordings can be applied in innovative ways to enhance investigators’ understanding of accident causation. Audio recorders chronicle operator comments and other sounds heard in operating stations, and system-state recorders record key system parameters. INTERPRETING RECORDED DATA • Match pertinent data against a common metric, such as elapsed time, local time, or Universal Coordinated Time, also referred to as Greenwich Mean Time, when examining data derived from multiple recorders. • Select the parameters that best reflect the overall system state, the components of greatest benefit to the issues of the investi- gation, and that offer the most information on operator deci- sions and actions, if considerable recorded data are available. • Develop multiple data plots, or use multiple time intervals as the period of interest increases or decreases, when numerous system-state parameters have been recorded. • Determine an appropriate interval to be used when examining recorded data, taking into account the number of parameters, the proximity to the event, and the number of changes that the system is undergoing at the time.