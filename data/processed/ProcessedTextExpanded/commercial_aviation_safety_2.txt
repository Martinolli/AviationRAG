Title: Commercial Aviation Safety– Chapter 2 Author(s): Stephen K. Cusick; Antonio I. Cortes; Clarence C. Rodrigues Category: Aircraft, Certification, Regulations Tags: Regulations, Safety, Airworthiness, Certification, Accidents In the first chapter of the book we explored different safety philosophies and the long history of safety improvements that have advanced commercial aviation to where it is today. Now that the reader has a foundation in the basic concepts of safety from the first chapter, but before we explore what we can do to ensure that commercial aviation continues to get safer, we must tackle one topic head-on. We must explore exactly what we are trying to avoid through all the efforts, initiatives, and programs outlined in this book: accidents! Specifically, we must answer the pressing question of why accidents and serious incidents in the first place are there. As any military commander will tell you, understanding the enemy is a must before attempting to defeat him or her. In aviation safety, the enemy is the accident that could happen at your operation, and the more we understand how accidents and serious incidents occur then the better we can prevent them from happening. Figure 2-1 shows a floating Boeing 737 which was operating as Lion Air Flight 904 in Indonesia. The Lion Air crew decided to go-around from an approach too late and ended up contacting the water. Fortunately, all 101 passengers and seven crewmembers survived the accident, although survivors of such events often suffer great mental trauma and can have invisible scars that last a long time. Given the safety record of today's commercial aviation industry, it proves startling to think that during the early stages of scheduled transportation from 1 922 to 1 925, one pilot was killed for every 10,000 hours of flight (Lacagnina, Rosenkrans, & Werfelman, 2002). Such a figure is particularly striking when we contemplate how in these modern days U.S. Airlines carry 2 million passengers each day, according to the trade organization Airlines for America. In the early days of commercial aviation, bad weather was a common factor in most fatal accidents as pilots would depart blind to the weather ahead. If flying conditions at their location and a few other stops along their route were favourable, they would take the risk and make the trip. After all, "the mail must fly." Unfortunately, this attitude probably resulted in quite a few fatalities. Weather continues playing a fac­tor in aviation accidents today, but so do numerous other factors such as fatigue, traffic density, distraction, and a lack of proper training or procedures. Since the early days of aviation, safety concepts have continued to evolve and develop over the years as technology and thinking have become more sophisti­cated. Accident investigation traditionally focused on preventing accidents by concentrating on simple causation theories to determine what happened and why it happened after an accident had taken place. When we speak of preventing acci­dents by studying the causes of accidents, some air safety investigators refer to that as reactive safety. It was traditionally the approach that was used as the primary means to prevent future accidents. The main goal of accident investigations is to establish the probable causes of accidents and to recommend control measures. Because most aviation accidents involve a complex maze of diverse events and causes, classifying or categorizing these accidents by type or cause gets quite complicated and involved. Also, acci­dents that are similar may often require different preventive strategies, although at times a single solution can eliminate or reduce the rate of occurrence of a wide range of accidents. For example, ground-proximity warning devices addressed the wide range of issues involved with controlled flight into terrain accidents for jetlin­ers and helped reduce its occurrence rate. Figure 2-2 shows the field portion of an accident investigation, which can take a large number of specialists into remote parts of the world to seek answers to what led to a crash. The national transportation safety board classifies accidents by several methods, such as causes and factors, sequence of events, and phase of operation. While aircraft component failures and encounters with weather are easy to classify, failures due to human errors are harder to trace and to assign to discrete categories for classification. Accidents have multiple causes; hence developing causal categories is a difficult task. In a majority of the cases, each cause is independent of the others, and if one did not exist, the accident might not have occurred. This is known as the "chain of causation" and breaking one of the links in the chain through defense and control measures can frequently be sufficient to prevent the accident. The purpose of accident investigation is to uncover pervasive, unrecognized causal factors of accidents. This can help prevent similar accidents from occurring in the future. Some aviation safety efforts around the world unfortunately still rely exclusively on accident investigation to help prevent future accidents, but progress is being made elsewhere. Since the middle of the past century, the decrease in accident rates for portions of the world's airline industry has prompted leading thinkers in safety to propose new, innovative risk prevention recommendations. Such thinking is called proactive and predictive safety by some investigators and has become such a fundamental aspect of modern safety management in com­mercial aviation that the entire Chapter 7 in this book is dedicated to the topic. Proactive safety is part of an evolution in thinking that increasingly relies less and less on accident investigation and more on technology and voluntary reporting to detect hazards and control risks before accidents occur. Since commercial avia­tion accidents are relatively rare, other means for identifying short-term changes in safety are required. The goal of proactive safety is to use non-accident data for analysis and modeling to conduct a preemptive strike so that accidents are prevented by addressing root causes of hazards before they manifest themselves in accidents. While incidents and accidents provide after-the-fact evidence that safety was inadequate, accident modeling through data from non-accident sources assists with understanding how accidents happen so that measures such as policy decisions or changes in the aviation operating environment can be taken to prevent potential hazards from materializing. The ultimate expression of this evolution in thinking is predictive safety, which is discussed as part of the future of safety management in Chapter 14 of this book. We can see a depiction of this evolution of safety theory in Figure 2-3 (i.e., mature aviation safety management practice is moving from Reactive to Proactive to Predictive stage). Instead of reacting to accidents and punishing the guilty party for failure to act safely, modern safety thinking has become proactive and even predictive of where and when the next accident may occur if current trends continue. The international civil aviation organization Safety Management Manual has an excellent discussion on the evolution of safety thinking over the past 50 years. Together with the evolution of the philosophy on how to find hazards, as shown in Figure 2-3, the general areas of focus have also evolved over the past century. From after World War II until the 1970s, safety experts focused on "tech­nical factors" to solve aviation safety problems. As aircraft became more modern, the thinking shifted to human factors and resulted in the creation of crew resource management concepts to address aviation safety woes. Today the concepts of orga­nizational factors and safety culture have been embraced as important factors to consider using the latest safety management system tools. This evolution of avia­tion safety thinking is illustrated in Figure 2-4. At this point we should make a clarification. It is easy to feel like we are pick­ing on aviation as we discuss accidents and safety, but in fact, other fields such as medical and maritime operations have similarly complex interaction of events that result in accidents and incidents. Safety thinking in these other fields has evolved in parallel to what has been witnessed in aviation. A clear example can be seen in the maritime industry. Ship designers must consider increasing demands for fuel effi­ciency, engine improvements, and new hull types in order to increase the safety of ships in the waterways. The stakes are higher every day, and the serious implications of shipwrecks are just as grave as aircraft accidents. For example, if a container ship sinks or runs aground, the event can result in blocked shipping lanes, disruption of global trade, an environmental disaster due to leaking fuel or cargo, and bankrupt ship owners and insurance companies. To illustrate this, Figure 2-5 shows the 2012 capsiz­ing of the Costa Concordia off the coast of Italian island of Giglio after striking rocks and creating a 50-meter gash on the port (left) side of the ship. The accident resulted in 32 fatalities and cost $570 million in damage to the ship, plus another estimated $2 billion and 500 workers to salvage the wreckage. As you can see from Italian National Civil Protection Department) the example of this ship accident, it is not just aviation that deals with such com­plex events requiring constant safety vigilance. DETERMINING THE CAUSES OF ACCIDENTS Chapter 6 of this book will explore how accidents are investigated. This section explores the general aspects of accident causation and lays the foundation for understanding the contents that are to follow in the book. Aviation accident theories have been developed by the ICAO, the NTSB, academia, and many other safety organizations that have traditionally sought to answer three interrelated questions after an accident: "What exactly happened? " " Why did the accident happen? "How can we prevent future accidents?" Determining what happened takes effort but determining why a complex event such as an accident took place requires a great deal of skill and work. Once investigators determine why an accident occurred, which is always the result of various factors, only then we can craft accurate recommendations that improve air safety. The process of accident science is one of investigation and action. Every time a recommendation is crafted and implemented, we have added to safety. One can think of the process as building a safety net over which commercial aviation flies every day. Over the decades we have added many threads to this so-called safety net, making the weave of the net tighter and tighter, and thus, making for increas­ingly safe and reliable air transportation. Searching for the answer to why an accident or serious incident has occurred is part of the larger question of human inquisitiveness. We need to understand the "why" of nature. Records left by the earliest civilized societies reveal that humans have always been interested in causa­tion. Indeed, one can argue that the ability to reason about the causes of events is what enabled humans to create our modern civilization. Reasoning about causation is a challenging undertaking. Perhaps this fact explains a strain of "anti-intellectualism" sometimes found in our contemporary society and as it has characterized societies of the past as well. To the extent that we avert our eyes from the difficult problem of causality, we become a little less human, more spectator than participant in life and society. Perhaps we are discom­forted by what appears to the uninitiated as the elusiveness of cause and effect. Perhaps we somehow feel that explaining a mystery somehow diminishes it, that if we finally understand the cause of an event we will experience once again the let-down we felt as children when we finally saw through a magic trick or learned that Santa Claus and the Easter Bunny are figments of our parents' imaginations. However, we must avoid such inclinations in order to continue making progress as an enlightened civilization that relies on science and reason. For thinkers in early Western societies, the study of causation seems to have been largely a matter of classification and systematic explanations. Around 350 BC, the famous Greek philosopher Aristotle declared that "every action must be due to one or other of seven causes: chance, nature, compulsion, habit, reason, anger, or appetite." Our own world, in contrast to the classical Greek world, is not so straightforward. Today's highly advanced technologies present challenges to think­ing about causality which differ in vast degree, if not in kind, from philosophers of the past. Not until the rise of early Enlightenment thinkers, people such as Copernicus, Galileo, Descartes, and Newton, did we see the clear beginnings of empirical inquiry and the so-called "scientific method." In our contemporary world, under­standing the causes of unsafe acts in aviation requires analyses of highly complex and tightly coupled systems that involve complex interactions between humans and machines. Such analyses rarely result in simple explanations of the complex prob­lems which characterize aviation safety. In what follows, we discuss the implica­tions of this fact. Complex Problems Do Not HAVE SIMPLE Solutions U.K. lecturer and author Edzard Ernst, a noted authority on safety in the practice of medicine, was the University of Exeter's first professor of complementary medi­cine. Ernst became famous among his students for starting his course in Emergency and Operating Room Medicine with the observation, "for every complex problem there is a simple solution . . . and it is wrong! "Perhaps he was inspired by the 19th century Irish writer Oscar Wilde, one of whose dramatic characters in The Importance of Being Ernest observes that so-called pure and simple truths are "rarely pure and never simple." No doubt Professor Ernst wished to emphasize to his student that simplistic responses to complex circumstances are almost always lacking and can be inappro­priate, especially when human lives weigh in the balance, as often is the case when doctors treat patients in an emergency rooms or on the operating table. The same logic applies to those charged with investigating aircraft accidents to prevent future tragedies. Like emergency and operating room medicine, aviation is a profession where high reliability is required to safeguard human lives, and where the consequences of unsafe acts can be severe indeed. Professor Ernst would be the first to point out that seeking a simple and single reason for an aircraft accident usually involves the mistaken hope that a complex problem has a simple solution. Nevertheless, society and the media that supposedly represent its interests, and indeed some aviation professionals as well, often seek simplistic explanations or even a single, simple cause for the tangle of unsafe acts and conditions that charac­terize aviation accidents. The well-known aviation writer Peter Garrison weighed in on the complexities of determining causation in aircraft accidents: I have written about the philosophical difficulties involved in the whole notion of determining the cause' of any event as complex as an aircraft accident. Some great thinkers have held that the connection between cause and effect is an illu­sion, but even without detouring through an epistemological Neverland we can easily see that many causal threads may be teased out of the knot of an airplane wreck, just as blame for a murder can be placed on the shooter, the victim, the abusive parents of one or the other, an overdose of cold medicine or gin, or a chronic shortage of affordable housing. In a similar vein, Jerome Lederer, one of the great leaders of the aviation safety movement in the 20th century, observed that "a full discussion of causation analy­sis [in aviation accidents] could fill a book. The term 'cause' (or 'causes') is not well defined. There is an assumption that everyone knows what causes are. Wrong! There is little consensus. Causation analysis is highly emotional." An example of the complex nature of accident causation can be found in the Air France Flight 3 5 8 accident. Figure 2-6 shows investigators examining the wreckage of the Airbus 340 that overran a Toronto runway during landing after a flight from Paris in 2005. The investigating agency determined 14 findings as to cause, 12 findings as to risk, and 9 other factors which all formed part of the accident sequence. Edzard Ernst, Peter Garrison, and Jerome Lederer would likely point out that such a slew of factors are typical in most aircraft accidents, and any­one who focuses on just one element is doing a great disservice to the prevention of future accidents. Flight 358. (Source: Transportation Safety Board Canada) Recommendations to prevent future accidents are crafted around the causal findings in a report, so not properly identifying relevant factors limits the amount of recommendations that are written, and thus, reduces the ability of the report to prevent similar factors from fostering future accidents. Active Causes Vs. Root Causes In gardening there is an expression used to describe the process of loosening or removing the dirt that is around plant roots. "Teasing out the roots" refers to deli­cately pulling the roots free of the soil, often when transplanting the specimen or examining the full root structure in order to detect signs of disease or insect damage or problems involving caring for the plant. Treating a sick plant by just examining the visible portion of a plant that lies above the ground can often lead to misdiagnoses, and thus, a faulty treatment plan. By carefully examining the root structure of a plant, gardeners get down to root causes of plant pathology, and as a result can produce accurate diagnoses of a plant's ailment and initiate effective treatments to bring the plant back to health. The gardening process serves as a very apt metaphor for how safety investigators relying only on the active causes of accidents will likely find their corrective efforts ineffective if the underlying causes are not addressed. They must seek out the root causes of the accident. Anyone who wants to understand why accidents happen must learn the concept of root cause analysis and realize that there is usually much more going on than what meets the eye at first glance in an accident. CASE STUDY: WEST CARIBBEAN AIRWAYS ACCIDENT Let us entertain an example to drive home such an important point. Figure 2-7 shows an MD-82 belonging to West Caribbean Airways, a company based in Colombia. That same tail number, operating as Flight 708, crashed in Venezuela in 2005 and resulted in 1 60 fatalities. The jet in the accident was flying at 33,000 feet when it stalled aerodynamically and the crew never recovered control, continuing in a stall all the way down from 33,000 feet to ground impact in the mountainous area of Venezuela near the Colombian border. At first glance it would appear that this was simply a case of pilot error, but labeling it as such and moving on neglects the numerous root causes that led to the pilot errors. What may be some of the root causes for pilots not preventing and then not recovering from an aerodynamic stall? The airline had been undergoing significant financial stress, and the flight crew had not received regular paychecks in sev­eral months. In fact, the captain had been forced to work as a bartender just to make ends meet for his family. One can only imagine how the odd work schedule impacted the captain's fitness to fly and how the overall stress of dealing with the company's financial problems impacted the crew's ability to detect and react to the departure from controlled flight. However, the report did mention the poor deci­sion making and poor communication between the pilots. The very next day after the accident the airline was grounded by the Colombian government agency in charge of regulating civil aviation. By delving into the root causes of this accident, the investigators crafted a series of recommendations to address the root causes in order to not just prevent the same type of accident as West Caribbean Airways Flight 708, but to prevent other vaguely related types of accidents. Among the recommendations proffered included the following: • Ensure flight crews are trained in the proper use of performance tables for calcu­lating the maximum operating altitude of an aircraft at a given weight and with different atmospheric conditions. • Train airline flight dispatchers on how to calculate maximum operating altitude for different phases of flight. • Require the training of flight crews on how to recover from stalls at high alti­tudes, versus just learning to recover from stalls in the traffic pattern environment as is typical in-flight training. • Regulating agencies should continue to assess the financial health of an airline after the initial operating certificate has been granted in order to ensure the maintenance and operational reliability of the certificate holder. • Require flight crews of MD-80 type aircraft to review the auto-throttle operation modes tied to the auto-flight system. The recommendations of the report were written to address not just the active causes of the accident but also the root causes. The active cause may have been the pilot maneuvering the aircraft outside of its airspeed envelope. However, if a safety investigator cites only this cause, very little can be done to prevent a recurrence of the situation. In contrast, if the investigator discovers the root causes behind the pilot's actions, a long-lasting intervention may be created. Perhaps the pilot was never trained on the specifics of how the performance ceiling is affected by fuel weight or by the use of anti-icing systems. Perhaps no quick reference material was available in the cockpit to allow for determining the boundaries of the airspeed envelop. Of course, a good accident investigator would also seek the reasons for those causes. At this point the reader may be asking, what exactly does root cause analysis mean? For that matter, what exactly is a cause? Before delving into the different types of cause we see in aviation, let us explore what exactly is a "cause." Although academia, government, and industry have wrestled with defining causation, the U.S. Air Force has produced excellent guidance on causation theory and has unfor­tunately a very long history of experience in accident investigation. Accordingly, an accident finding can be considered a "cause" if it is, 1 - an act or condition that singly, or in combination with other causes, resulted in the damage or injury that occurred, 2 - a deficiency that, if corrected or eliminated or avoided, would have likely prevented or mitigated the accident damage or significant injuries, or 3 - an act, an omission, a condition, or a circumstance that either starts or sustains an accident sequence. This discussion paves the way for us to exclude the following items from being a "cause": • When a person's performance was reasonable given the circumstances (some­ thing we call the reasonable person concept) • If it was a natural or reasonable outcome of the situation • If entering the hazardous situation could not be reasonably avoided If the definition of a cause is examined carefully, it can be argued that some causes are more obviously linked to an event than others; yet all remain causes of an event regardless of how close they appeared to be to the event. This linkage is called the event chain or the error chain. Over the past few decades, investigators have shown that accidents always have more than one cause, and that some causes are often outside of the direct control of the pilots involved in an accident. Accident investigators aware of the multicausal nature of accidents seek to uncover all the major errors that led to the mishap. Many of the errors are usu­ally found at the pilot level, but not all. A pilot's behavior is partly the result of the training invested in him or her, the procedures that have been created to follow, and the safety protocols built into the system that supports the operation of the aircraft. For example, the error chain for a wind-shear accident may look some­thing like this: Un-forecast weather + Inadequate wind-shear detection + Insufficient wind-shear training + No hint of wind shear on the airport information system (ATIS) + No warning from air traffic control + Crew complacency = Accident An experienced investigator can pick apart each of these factors and ask all the "whys" of each until a comprehensive picture of all the failures is seen and cor­rective actions can be recommended. Each link in the sequence by itself may not bring down an aircraft, but the likelihood of an accident increases with each "link" added to the chain. Figure 2-8 shows several accident investigators discussing the wreckage of a UPS aircraft that crashed in 2014 when the crew failed to monitor altitude during an approach and impacted terrain approximately 3,300 feet short of the runway threshold in Birmingham, Alabama. Such investigators must methodically and patiently reconstruct the links in the chain of events that produced the accident. In the case of this accident, several such links proved to be ( 1 ) the failure of the pilots to properly program the flight management computer, (2) a breakdown in communications between the pilots, (3) a mental bias about the expected weather, ( 4) reduced situation awareness from one of the pilots not making the required callouts during the approach, and ( 5 ) human performance deficiencies that prompted the crew errors in the first place. Investigators then had to dive into each of those active causes to determine why they had been present in the first place. In other words, they had to perform a root cause analysis. How do investigators distinguish active causes from root causes? When do they know that their root causal analysis has penetrated sufficiently back in time to extract the underlying issues that helped create the accident? We must distinguish between causes that are within the immediate control of a pilot or other frontline operator, and those that lead frontline operators to make a mistake in the first place. Simplistically speaking, active causes are obvious, and root causes are hidden. Active causes are sometimes termed proximate or apparent. Alternative terms for root causes are enabling and latent. Most important, though different segments of society use different terms for obvious and hidden causes, all actionable causes come from those individuals who, whether they acted on the flight deck or from afar as support workers or managers, had an opportunity to do something to prevent the accident. Unsafe acts performed by someone who had a chance to prevent so an accident through direct action, people such as dispatchers, air traffic controllers, aviation maintenance technicians, and pilots, are commonly associated with active causes. If someone who could have intervened to prevent an unsafe act or situation fails to perform, such as people in management or support functions such as a chief pilots, dispatch directors, air traffic control managers, or techni­cal manual writers, their actions or failure to act constitutes a root, enabling, or latent cause. In other words, root causes are usually conditions that facilitate errors by frontline operators but which are outside of the direct control of frontliners. Some like to say that root causes "set operators up for failure," that is, present operators with the opportunity to perform unsafe acts. This distinction, valid though it is, must not distract our attention from the notion that frontline operators are always directly responsible for safety, regardless of the support that they may be given or denied. Of course, the reality of the matter is that all aviation professionals share in the responsibility to provide reliable service, which means that all are on the hook to promote efficiency and safety. A safety investigator often starts with active causes and must work backwards to discover the root causes underlying each active cause. The process continues until organizational fixes can be recommended to prevent similar or related mishaps from occurring. It can be tricky for investigators to cite root causes in for­mal accident reports, since there may be only a tenuous or even speculative link between the root causes and the active causes that are engendered by them. Since root causes often result from management breakdowns, it becomes particularly delicate to formally establish root causes without some type of firm proof. In the world of causation, such proof can be very challenging to establish. Here are some key points about root cause to consider when differentiating them from active causes: • Almost all accidents are "multicausal," meaning that more than one cause pro­duced the event. If we only focus on a single cause, then it will usually involve the pilot, who might be dead and cannot do anything to prevent a future accident. • Effective investigations are those that provide recommendations to deal with the root causes, since those are the recommendations that can best prevent other accidents. Recommendations crafted around active causes usually often just deal with the crew and thus often will not prevent future accidents. • Since accidents result from more than one cause, it is often suggested that we should not prioritize the causes. Nevertheless, people often want to know what the "primary" or "trigger" cause was for an accident. Avoid using such terms because often, if we point to a "primary cause," that is where the recommenda­tions and funding will go to prevent future similar accidents. However, since accidents are multicausal, removal of any of the causes will have the effect of preventing future accidents. CASE STUDY: SKID AIRWAYS HYPOTHETICAL To illustrate our discussion of active and root causes, what follows are the "findings, causes, and recommendations" arranged in chronological order for a hypo­thetical accident sequence involving a made-up airline named " Skid Airways" operating a 400 Series Boeing 737 during the summer of 2016: Finding 1 . In January 2006, the federal aviation administration issued a B-73 7-400 Airworthiness Directive (AD) requiring weekly inspection of electrical wiring associated with the warning circuits for the forward cargo fire detector. Finding 2. The last time the evacuation slides were inspected for the accident aircraft was by the aircraft's previous operator in 2011 Finding 3 (ROOT CAUSE). As of March 2015, Skid Airways had not implemented a maintenance procedure for complying with the AD. Finding 4 (ROOT CAUSE). As of March 2015, the Skid Airways aircraft maintenance training program did not teach the time intervals for inspecting aircraft evacuation slides. Finding 5 (ROOT CAUSE). As of March 2015, the Skid Airways inflight training department did not teach flight attendants to ensure each slide has inflated prior to evacuating passengers. Finding 6 (ACTIVE CAUSE). Skid Airways mechanics never accomplished the required inspection of the electrical wiring associated with the fire detectors. Finding 7 (ACTIVE CAUSE). Skid Airways mechanics failed to inspect the air­craft evacuation slide at the required interval. Finding 8. At some point prior to the accident flight on June 11, 2016, an electrical short occurred in the warning circuits for the forward cargo fire detector. Finding 9. On June 11, 2016, a Skid Airways B-737-400 departed on a FAR Part 121 passenger flight. Finding 10. Shortly after becoming airborne the aircraft's forward cargo fire warning light activated, although no fire was present in the forward cargo bay. Finding 11. The pilots assumed the fire warning was accurate and correctly performed emergency checklists for the cargo fire but the warning persisted. Finding 12. The pilots coordinated with dispatch, ATC, and the cabin crew for an emergency return to landing. Finding 13. The aircraft landed over maximum landing weight and the pilots applied maximum braking to attempt to stop within the runway remaining. Finding 14. The aircraft overran the available runway, the pilot stopped the aircraft in a grass field past the end of the runway and directed an emergency evacuation of passengers. Finding 15. (ACTIVE CAUSE). One of the aircraft evacuation slides failed to inflate. Finding 16 (ACTIVE CAUSE). The flight attendants failed to notice that the slide did not inflate. Finding 17 (normal result of Finding 16). The flight attendants did not direct evacuating passengers away from the failed slide. Finding 18. A passenger was fatally injured during the ground egress by falling off the slide that did not inflate. Finding 19. A brake fire commenced in the left gear well due to heavy braking action during the landing. Finding 20. The aircraft wing fuel tank exploded due to the brake fire. Finding 21. The aircraft sustained severe damage due to the ensuing fire. Recommendation 1. federal aviation administration Principal Maintenance Inspectors (PMis) will ensure all air carriers operating B-73 7-400 are in compliance with the AD. Recommendation 2. federal aviation administration Principal Operations Inspectors (POls) will ensure all air carrier flight attendant training programs teach slide inspections as part of evacuation procedures. Recommendation 3. federal aviation administration PMis will ensure all air carrier maintenance programs teach how to inspect slides and respect inspection intervals. This hypothetical example makes the point that an improperly performed root cause investigation could have called the pilots causal for landing overweight when there was no actual fire and also causal for the injury stemming from the unneces­sary evacuation, and the flight attendant’s causal for not ensuring slide deployment. If an improper investigation had taken place, all those misplaced causes would do very little to prevent future accidents, which we must remember is the whole reason for performing an accident investigation in the first place. Instead, the hypo­thetical example depicts a properly conducted accident investigation, to include a root cause analysis, and recommendations that will go a long way toward prevent­ing future accidents. As discussed earlier, recommendations are crafted around root causes so that we can prevent future accidents. In our hypothetical example, calling the pilots' decision to land overweight "causal" would be nonsense, since there was no way for them to know that the warning was erroneous. If we called the pilots causal for that, you can see that a recommendation written around that cause would be of no value and, in fact, could actually work against preventive safety because it was based on an erroneous conclusion. USING MODELS TO UNDERSTAND ACCIDENT THEORY The concepts exposed previously referring to complexity, causation, and root cause analysis are fundamental building blocks for understanding accident theory. The field of accident investigation, to include its theories, has sometimes been called the accidentology. The term is meant to connote that accident investigation is a scien­tific discipline that relies on concepts drawn from forensics, human performance, and data analysis. Although used in some countries, the term accidentology is not common in the parlance of investigators in the United States. Scientific theories are confirmed explanations of how nature works. Accident theory is an amalgam of concepts that have gained acceptance by accident inves­tigators and educators and which generalize our understandings of how accidents happen. Such a topic should not be taken lightly, since it entails the interaction of complicated variables to produce what is often great loss of life. Accident theory uses models to simplify complex concepts, and thus, make the concepts under­standable for study and research. Figure 2-9 shows what remains of an aircraft following a ground evacuation and fire. Without resorting to models for understanding how such events take place it would prove extremely difficult to organize one's thinking in order to properly conduct an investigation of what occurred. Throughout this chapter we refer to the relationship between complexity and understanding. As concepts become increasingly complex it is common to resort to models as a way of helping to understand how the concepts interrelate. They help us grasp "the big picture" so we can try to make sense of it all. We call the process "conceptual modeling." Such modeling helps make sense of very intricate factors and helps show how the factors interrelate. Without modeling, the number of different variables and their complex interrelates would leave many of us confused, if not downright lost. Since models are inherently attempts to simplify, they unfortunately come with a price. The price of simplification is that models can sacrifice knowledge of the nuances that are sometimes critical to getting the full picture of all the types of factors involved in an accident. What we have just described is also a fitting expla­nation of models: a knowledge construct that simplifies complexity. This chapter makes mention of popular aviation safety models, such as the " Swiss Cheese" and 5-Factor models. To learn about accident theory we not only use conceptual models but we often arrange such models into visual representations to help us grasp their meaning more intuitively. Such a process is not just used to learn accident theory, as we use visual conceptual models all the time, particularly when attempting to learn new material composed of different interrelated factors. For example, many of us remember learning about matter in chemistry by referencing a visual model of the atoms that depicted orbiting electrons, or we may remember learning about nutrition by referencing the visual model of the food pyramid that represented the optimal number of servings to be eaten every day from each of the basic food groups. Or perhaps we remember learning about a specific process by using an if-then style flowchart that guided us in different direc­tions depending on how we answered certain questions. All those models are based on initially complex concepts that have been reduced down to primary elemental components and then visually depicted to understand how the concepts interrelate. Aircraft accidents are extremely complex events caused by numerous interacting factors. Thus, it proves highly desirable to refer to visual conceptual models in order to understand how and why accidents take place. Such accident models: Help explain the relationship between hazards and accidents • Assist with understanding and explaining reality • airport information desk in visualizing things that cannot be directly observed • Approximate conditions that exist in reality to be useful There are several accident models discussed in the literature. Three models that have been most frequently associated with aviation are discussed next. REASON'S "SWISS CHEESE" MODEL Dr. James T. Reason started his career as a research psychologist with the Royal Air Force Institute of Aviation Medicine in the United Kingdom and with the U.S. Naval Aerospace Medical Institute in Florida. He later became a professor of psy­chology at the University of Manchester in the United Kingdom. It was during his time as a professor that he developed a visual conceptual model of accidents that has made a profound impact on accident theory. James Reason's accident causation model was published in 1990 as a way to illustrate how human factors at various levels of an organization, such as an airline, can lead to accidents. The model is based on the concept that accidents have root causes that are often based on faulty actions or lack of actions at the management levels of an organization. Reason's model of accident causation focuses on understanding incidents and accidents and their contributing factors. Reason's model is widely used in the aviation industry and has been recommended by various organizations, such as the FAA, for use in investigating the role of management policies and procedures in aircraft accidents. Reason's model traces the root causes of accidents to errors that occur in the higher management levels of an organization. These errors are also referred to as latent errors. Reason contends that models are grossly inadequate if they attribute accidents solely to individual operator performance. Reason also proposes that human error is the end result rather than the cause of incidents or accidents. Today's technological systems involve complex and multiple interacting factors that are distant in time and proximity from the imme­diate circumstance of an accident. A simplified depiction of the model is seen in Figure 2-10, and, upon visual inspection, many will instantly recognize why its visual appearance has led to it earning the nickname of the "Swiss Cheese" model. The holes in the layers of defenses make each layer look like a slice of Swiss cheese! A more detailed alter­nate depiction is provided in Figure 2-11 and shows bullet ideas of what may be considered when assessing how a particular defensive layer failed prior to an accident. Reason hypothesized that most accidents can be seen to have one or more of four different levels of failure: at the organizational level, at the supervisory level, at preconditions that set humans up for unsafe acts, and the unsafe acts themselves. This model is a good representation of the complex relationship between the indi­vidual and the organization. Reason explained that before an active human failure occurs, there are certain latent conditions in the organization which are the result of management action or inaction. He also stated that human error is the active "end result" rather than the root cause of accidents. Some of the important features of Reason's model are the following: “Systems are protected by multiple layers of defenses that are designed to prevent hazards or system failures from cascading into accidents. • Each layer of protection, however, can develop "holes" or flaws through safety deficiencies, resembling Swiss cheese. • As the number and size of these holes in the defenses increase, the chances of accidents also increase. • When the holes in each of the layers of defenses line up, an accident occurs. The model recommends focusing on events beyond the active failures of front­line employees to latent preexisting conditions that result from fallible decisions made by high-level decision makers. It is these failures that permit active failures to occur. Management should build defenses by creating an organizational culture in which precursor events are detected and promptly corrected. Examples of real world problems using Reason's Swiss Cheese model would include the following: Organizational Influences • Rapid expansion • Lack of regulation • Management "lip service" to safety, where safety is said to be important but actions do not match the stated importance Unsafe Supervision • Risks and hazards neglected • Poor work scheduling-fatigue • Insufficient training Preconditions for Unsafe Acts • High workload • Time pressure to perform tasks • Ignorance of the system Unsafe Acts • Aircraft warning system disabled • Omission of critical checklist item • Overreliance on automation Another way to depict the complex relationship of the organization and human factor is provided in the international civil aviation organization Safety Management Manual. Consistent with Reason's model, various "screens" or defenses can be set up to plug the holes in the " Swiss cheese" and thus prevent the accident. These defenses are controls built into the system by management to protect against the inevitable human error that cannot be completely avoided. Figure 2-12 shows that organizational factors could be either weaknesses (holes in the cheese) or strengths (preventative screens) that could serve as defenses or "safety nets" to prevent an accident situation. Still another helpful model depiction to illustrate the importance of the orga­nization and the dichotomy between latent conditions and active failures is provided in Figure 2-13. The top block represents the organizational processes which are under the control of management such as policy making, communication, and resources. These must be continually monitored and enhanced to prevent the orga­nizational accident from occurring. Existing latent conditions can breach aviation system defense screens if not sufficient in the areas of regulations, training and technology. Mitigation strategies should be developed to reinforce defenses to human errors. After the latent conditions and defenses are bolstered, the organiza­tion should shift its focus to improving workplace conditions and thus contain the active "human errors" that always occur in any complex aviation scenario. software hardware environment liveware Model Another widely used visual conceptual tool in aviation accident theory is the software hardware environment liveware model. This model can be traced back to work performed in 1972 by Professor Elwyn Edwards in the United Kingdom and a subsequent creation of a diagram by Captain Frank Hawkins in 1 975. As indicated by ICAO, the components of this model as identified in Figure 2-14 are as follows: • S = Software (such as procedures, checklists, and training) • H = Hardware (machines and equipment) • E = Environment (operating conditions) • L = Liveware (human interface to S, H, and E above) • L = Liveware (again, i.e., human to human interface) To properly understand this model, it is important to note that the L (Liveware or Human Person) is always in the center of the diagram interacting with the other " SHELL'' components. Since humans are inconsistent and do not interact perfectly with the other components, we need to consider four important factors affecting human performance (the so-called "4 Ps" of human performance): • Physical factors (strength, height) • Physiological factors (health, stress, etc.) • Psychological factors (motivation, judgment, etc.) • Psychosocial factors (personal issues or tension, etc.) The software hardware environment liveware interfaces are in constant interaction with each other and should be matched closely to the human element (Liveware) in the center of the system: • Liveware to Software. This is the relationship between the human and supporting systems found in the workplace. Not just computer programs, these include user-friendly issues in regulations, manuals, and checklists. • Liveware to Hardware. This is the relationship between man and machine. Although humans adapt well to poor interfaces, they can easily cause safety haz­ards if not well designed. • Liveware to Liveware. This is the relationship between the human and other people in the workplace. Communication styles and techniques are important here. Crew Resource Management (CRM) training has made great strides in this area. • Liveware to Environment. This is the relationship between the human and the internal and external environments. Sleep patterns and fatigue are examples of important considerations here. 5-FACTOR MODEL Another visual conceptual model is used to depict the major categories of factors that interact to create a safety error chain or an accident. This 5-Factor model has become very popular in teaching accident theory and can prove helpful when studying the factors that contributed to any given accident. The human, machine, medium, mission, and management factors represent another valuable visual con­ceptual model for examining the nature of accidents, as represented by Figure 2-15. That is, when one seeks causal factors or preventive or remedial action, the diagram of the intertwined circles becomes a meaningful checklist for fact-finding and analysis to ensure that all factors are considered. The five factors are closely interrelated and interact in numerous ways, although management plays the overall predominant role and is thus depicted as if hovering over the other factors. Mission is located as the central target or objective to emphasize that effective mission accomplishment is implicit in professional sys­tem (aviation) safety work. Using this model brings to light a few issues that stem from the elements that comprise the 5-Factor model. First, there are internal and external factors that contribute to accidents. Internal and external issues are the two large categories of hazards, as there are things both outside and within the control of a person in the error chain. Second, there is a difference between technical and soft skills. Technical skills are teachable skill sets and professional knowledge that can easily be quanti­fied, while soft skills relate to interpersonal skills and how people interact with one another. As we examine this model, you will see how these two large categories of skills come into play. HuMAN. For several decades the model used to be called the "5-M" model because the word man was used instead of human. This edition of the book introduces the change in terms and therefore introduces the name "5-Factor" model instead of "5-M" model. The literature of aviation safety is peppered with references to the percentage of aircraft accidents that result from so-called "human error," that is, unsafe acts committed by humans. Some studies show the percentage as 50%, some 75 %, some as high as 80%. We believe even the highest of these percentages is too low. The figure may actually be very close to 100% for most aviation accidents. If no unsafe act attributable to a human is apparent along the sequence of events leading to an accident or serious incident, then we may not have looked hard enough in the right places. Perhaps, for example, we have overlooked an error of omission committed by support personnel. While some may see the pilot as the only human in the system, others rightfully include all persons directly involved with the operation of aircraft-cabin crewmembers, dispatchers, ramp agents, gate agents, air traffic controllers, meteorologists, etc. In its widest sense, the concept should include all human involvement in aviation, such as in the design, assembly, maintenance, operation, and management of aircraft. Accident prevention must aim at all hazards, regardless of their origin. As a result of refinements in technology and mechanical reliability over the years, the percentage of accidents caused by the category of machine has declined, while those caused by humans have risen proportionately. Because of this signifi­cant shift in the relationship between human and machine causes, a consensus has now emerged that accident prevention activities should be mainly directed toward the human and the organization in which the humans work. New flight deck tech­nologies, for example, do not so much result in new ways to commit unsafe acts as to provide an opportunity for unsafe acts to experience a new way of expression. The unsafe acts remain the same while the interface and feedback loops provided by the technologies merely make their manifestations appear different. Figure 2-1 6 show the results of what can happen when such human-automation interaction go awry. The picture shows the debris field of a Boeing 777 that crashed into a seawall during landing at San Francisco in 2013 when the flight crew misused the autopilot and autothrottle during the approach. People are naturally reluctant to admit to their limitations for a variety of reasons, such as loss of face among peers, self-incrimination, fear of job loss, or considerations of blame and liability. When our personal performance does not meet our expectations, we are presented with an opportunity for improvement. However, such a situation requires a singular strength to capitalize on an oppor­tunity to learn from our missteps. Seizing such opportunities constitutes what has been called embracing our blunders. Similarly, when we avoid blunders by learning from the missteps of others who have preceded us, we are embracing the blunders of others. Some people simply dismiss missteps as examples of human fallibility, or take the cowardly position of covering up their actions or redirecting blame instead of learning from their embarrassing missteps. It takes courage to actively seek out and embrace shortfalls to foster improvement. It is not surprising, therefore, that information on the human-factor aspects of accidents or incidents is not readily forthcoming. This is unfortunate since it is often these areas that hold the key to the "why" of a person's actions or inactions. Perhaps it is only human to repeat foolish and dangerous behaviors, but it is certainly not inevitable. Sadly, when erring humans are air transport profession­als, they subject not only themselves but also the traveling public to dangerous situations. In the past, the view that the human component of the 5-Factor model involved only the pilot led to the inappropriate use of the term pilot error as a cause of accidents, often to the exclusion of other human-factor causes. As a con­sequence, any other hazards revealed by an investigation were often not addressed. Further, since the term tended to describe only what happened rather than why, it was of little value as a basis for preventive action. Fortunately, the term is now increasingly in disuse by investigation authorities. MAcHINE. This component of the 5-Factor model refers to aviation technology and has made substantial advances over the years. There are still quite a few occasions when hazards are found in the design, manufacture, or maintenance of aircraft. In fact, a number of accidents can be traced to errors in the conception, design, and development phases of an aircraft. Modern aircraft design, therefore, attempts to minimize the effect of any one hazard. For instance, good design should seek not only to make system failure unlikely but also to ensure that should it occur nevertheless, a single failure will not result in an accident. This goal is usually accomplished by so-called fail-safe features and redundancy in critical components or systems. A designer must also attempt to minimize the possibility of a person using or working on the equipment committing errors or mistakes in accordance with the inevitability of Murphy's Law: "If something can go wrong, it will." To meet these aims, some form of a system safety program is often used during the development of a new aircraft type. Modern design must also take into account the limitations inherent in humans. Therefore, it includes systems that make the human's task more efficient and that aim to prevent mistakes and errors. The ground-proximity warning system (GPWS) is an example of such a system. It has significantly reduced the number of accidents in which airworthy aircraft collide with the ground or water while under the control of the pilot. The level of safety of an aircraft and its equipment is initially set by the airwor­thiness standards to which it is designed and built. Maintenance is then performed to ensure that an acceptable level of safety is achieved throughout the life of the aircraft. Manufacturing, maintenance, and repair errors can negate design safety features and introduce new hazards that may not be immediately apparent. As the service experience with a particular aircraft type increases, the main­tenance program needs to be monitored and its contents developed and updated where necessary to maintain the required levels of safety. Some form of reporting system is required to ensure that component or system malfunctions and defects are assessed and corrected in a timely manner. The reliability of a component is an expression of the likelihood that it will perform to certain specifications for a defined length of time under prescribed conditions. Various methods can be used to express reliability. A common method for electronic components is the mean time between failures (MTBF), and the reliability of aircraft power plants is usually expressed as the number of shutdowns per 100,000 operating hours. Failures normally arise in three distinct phases in the life of a component. Initial failures, caused by inadequate design or manufacture, usually occur early in its life. Modifications to the component or its use usually reduce these to a mini­mum during the main or useful life period. Random failures may occur during this period. Near the end of the life of a component, increased failures occur as the result of its wearing out. Graphic representation of this failure pattern gives rise to the typical "bathtub-shaped" curve, as shown in Figure 2-17. The evolution of the machine component in the 5-Factor model has proved quite interesting over the past half century. In the period from 1970 to 1 990, three generations of wide-body airliners appeared. The first generation, introduced around 1970, was the wide-body, long-range airliner. Examples are the Boeing 74 7, the Lockheed L-1 0 1 1 , and the Douglas DC-10. These wide-body airliners were equipped with three to four high bypass-ratio engines, inertial navigation systems (INSs), and an automatic landing system (ALS). The flight decks of these airlin­ers were equipped with many electromechanical instruments. These aircraft were flown by a flight crew of two pilots and one flight engineer. The second generation, introduced around 1980, was medium to long range, wide-body airliners with a new digital avionics system. Examples are the Airbus 310 and the Boeing 757/767. These new wide-body airliners are equipped with an electronic flight instrument system (EFIS), a flight management system (FMS), and either an Engine Indicating Crew Alerting System (EICAS for Boeing) or an Electronic Centralized Aircraft Monitor (ECAM for Airbus). In greater detail, the EFIS, FMS, and EICAS/ECAM provide the following functions: The EFIS primary flight display (PFD) provides a combined presentation of attitude, flight director, instrument landing system (ILS) deviation, flight mode annunciation, and speed and altitude information on a single cathode-ray tube (CRT) display, thus reducing the scanning cycle required by pilots monitoring instrumentation. • The EFIS multifunction display (MFD) or navigation display (ND) provides integrated map, horizontal flight path, weather radar, heading, and wind vector information, largely reducing the navigation task (in combination with the FMS) and improving the positional awareness of the pilot. • The flight management system provides integrated navigation and fuel management information, as well as a host of performance and navigation information, largely increasing the pilot's flight management and navigation capabilities. • The EICAS/ECAM provides the aircraft crew with engine and other system instruments and warning announcements that also may depict the remedial action required. The "glass" cockpit is equipped with six-color CRT graphics display for the EFIS, as well as two alphanumeric monochrome control display units (CDUs) for the FMS; apart from the CRTs, a number of electromechanical instruments are still used to enable a safe continuation of flight in case all CRTs should fail. The introduction of the EFIS, FMS, and EICAS/ECAM allowed the elimination of the flight engineer from the flight deck, providing a significant cost reduction for the operations with this type of airliner. The third-generation airliner, introduced around 1 990, is a medium to long range type of aircraft with a revolutionary new digital flight control system, no longer using mechanical links between the pilot's control yoke and the hydraulic actuators of the flight control surfaces. This fly-by-wire (FBW) technology allows for new flight control concepts and aerodynamic envelope protection systems. Examples of these new FBW airliners are the Airbus 320/330/340 and the Boeing 777. The engines of this new generation of airliners are controlled by full-authority digital engine control (FADEC) systems. On the flight deck, the CRTs are larger, and the number of electromechanical instruments has substantially decreased. Aircraft used in modern commercial aviation have allowed the airline industry to develop into a reliable and economical all-weather transport system. Through the use of ever-improving aerodynamic designs and engine technology, as well as the increasing use of lightweight composite materials since 1 970, the fuel consump­tion per passenger-mile has been reduced by more than 30%. Radio navigation and approach systems, inertial navigation systems, weather radar, and ATC, in combination with ever-improving training and standardized procedures, allow safe flight, also in reduced-visibility conditions. The accident rate for the newer generation of airplanes, such as the Boeing 7571767 and Airbus 3 1 0/320/330, is considerably better than that for earlier designs. It is reasonable to expect that the current new models, such as the Boeing 787 and Airbus 350/3 80, will be safer as a result of more sophisticated design and applied technology. New technology will be available to the flight crews and controllers during the next decade, prompting further enhancements in the machine component of the 5-Factor model through the following developments: • Better weather detection systems will provide information to airline dispatchers and pilots, allowing more efficient and safe flight around weather systems, both en route and near the airport. • Global Positioning Systems (GPSs) are widely being used now but will become the primary source for navigation and surveillance information, replacing ground-based, line-of-sight-limited navigation facilities and radar facilities. GPS will also be the primary means of guidance for precision landings and departures at our nation's airports under the new Next Generation (NextGen) Air Traffic Control concept. • Improved air traffic control tools are already being installed in federal aviation administration facilities to give the controller more reliable and efficient means to see and communicate with the airplanes under his or her control. Improved collision avoidance will be provided by the new Automatic Dependent Surveillance Broadcast (ADS-B) System. • Flight decks will continue to improve, with added redundancy and integrated avionics giving the pilot more options and greater situation awareness. • Data link will allow clearances, weather, and traffic information to be provided on the flight deck in a fast, error-free, digital form. One of the big advantages of data link will be the elimination of "read-back" errors between the pilot and controller. • Human factors will be a major consideration from the onset of airplane design to ensure that the airplane can be operated and maintained easily within human limits. Our aviation system has evolved over the past decades to serve a vital role in the economy and our way of life. The system is complex, built on international standards with rigid quality control in all areas from the cockpit to the mainte­nance hangar to the air traffic control facility. MEDIUM. The medium (environment) in which aircraft operations take place, equipment is used, and personnel work directly affects safety. From the accident prevention viewpoint, this discussion considers the environment to comprise two parts: the natural environment and the artificial environment. Weather, topography, and other natural phenomena are elements of the natural environment. Their manifestations, in forms such as temperature, wind, rain, ice, lightning, mountains, volcanic eruptions, and wildlife, with some exceptions are all beyond the control of humans. These manifestations may be hazardous, and since they cannot be eliminated, they must be avoided or allowances must be made for them. Wildlife poses a major threat to safe flight operations. For example, if a jet engine ingests a piece of a bird or a plane strikes a deer, it can lead to a fatal crash. To protect our skies, 50 years ago the federal aviation administration began adopting a biological-ecological approach by partnering with the U.S. Department of Agriculture to develop wild­life management strategies. Such measures include keeping grasses at a certain level, trap and relocation efforts of animals, and eliminating standing water. Much of this effort is centered on airports and nearby areas since 70% of bird strikes occur at or below 500 ft above sea level, and many of these birds are species feder­ally protected under the Migratory Bird Treaty Act. Furthermore, airports and air­planes can report strikes to help the federal aviation administration determine what kind of wildlife is posing threats. Since we cannot eliminate the environment and its inhabitants, we must work around them. Another environmental menace that is lesser known is volcanic ash. When ingested by an aircraft engine, the security and hazardous materials safety can form glass in the hot sections of the engine, block the cooling holes, prevent air flow, and cause damage to the com­pressor blades. If severe enough, it can cause the engine to lose power. Due to these concerns, manufacturers of aircraft engines all agree that under no circum­stance should planes fly through a volcanic security and hazardous materials safety cloud due to the potential hazards. Unfortunately, there is no standard for measuring security and hazardous materials safety concentration in the air, and hazards may exist over 1,000 miles away. The eruption of Iceland's volcano in 2010 is a great example of how volcanic security and hazardous materials safety can paralyze the commer­cial aviation sector. As a result of this eruption, there were 1 7,000 cancellations a day, which resulted in $200 million loss a day, totaling $2 billion in all. However, this financial toll must be measured against what would have happened if the industry had lost an airliner to the ash. The artificial portion of the environment can be further divided into physical and nonphysical parts. The physical portion includes those artificial objects that form part of the aviation environment. Air traffic control, airports, navigation aids, landing aids, and airfield lighting are examples of the artificial physical environment. The artificial nonphysical environment, sometimes called system software, includes those procedural components that determine how a system should or will function. This part of the environment includes national and federal legislation, associated orders and regulations, standard operating procedures, training syllabi, and so forth. Many hazards continue to exist in the environment because the people respon­sible do not want to become involved in change, consider that nothing can be done, or are insufficiently motivated to take the necessary actions. Obstructions near runways, malfunctioning or nonexistent airport equipment, errors or omissions on aeronautical charts, faulty procedures, and so forth are examples of artificial envi­ronmental hazards that can have a direct effect on aviation safety. One important point should be made. Many accidents that seem unpreventable due to factors in the medium category of the 5-Factor model actually are prevent­able, and others that occur because of a calculated risk can be reduced in number or severity by implementing appropriate risk-mitigating actions. In modern aviation operations, each individual has a unique opportunity to break the accident chain of events, and passing up the chance may have seri­ous consequences. Complacency comes in many forms, but it always reflects an unprofessional attitude that fosters the growth of accident chains. A strong sense of professionalism creates the proper culture and motivation for appropriate action. Instead of remaining silent, true aviation professionals take responsibility for avia­tion safety through prompt reporting of hazardous situations. The responsibility to support safety by positive actions must be clearly understood by each member of the organization; it must be part and parcel of each member's sense of what it means to be aviation professionals. MISSION. Notwithstanding the man-machine-medium concept, some safety experts consider the type of mission, or the purpose of the operation, to be equally impor­tant. Obviously the risks associated with different types of operation vary consid­erably. A small regional airline operating out of many small airports during the winter months in the New England area has a completely different mission than an all-cargo carrier flying extensive overwater flights to underdeveloped countries or a major carrier flying from New York to Los Angeles. Each category of opera­tion (mission) has certain intrinsic hazards that have to be accepted. This fact is reflected in the accident rates of the different categories of operation and is the rea­son why such rates are usually calculated separately. MANAGEMENT. The responsibility for safety and, thus, accident prevention in any orga­nization ultimately rests with management, because only management controls the allocation of resources. For example, airline management selects the type of aircraft to be purchased, the personnel to fly and maintain them, the routes over which they operate, and the training and operating procedures used. Federal authorities promulgate airworthiness standards and personnel licensing criteria and provide air traffic and other services. Manufacturers are responsible for the design and manufacture of aircraft, components, and power plants as well as monitoring their airworthiness. The slogan " Safety is everybody's business" means that all persons should be aware of the consequences of their mistakes and strive to avoid them. Unfortunately, not everyone realizes this, even though most people want to do a good job and do it safely. Therefore, management is responsible for fostering this basic motivation so that each employee develops an awareness of safety. To do this, management must provide the proper working environment, adequate training and supervision, and the right facilities and equipment. Management's involvement and the resources it allocates have a profound effect on the quality of the organization's accident prevention program. Sometimes, because of financial responsibilities, management is reluctant to spend money to improve safety. However, it can usually be shown that not only are accident pre­vention activities cost-effective, but also they tend to improve the performance of people, reduce waste, and increase the overall efficiency of the organization. Management's responsibilities for safety go well beyond financial provisions. Encouragement and active support of accident prevention programs must be clearly visible to all staff, if such programs are to be effective. For example, in addi­tion to determining who was responsible for an accident or incident, management's investigation must also delve into the underlying factors that induced the human error. Such an investigation may well indicate faults in management's own policies and latent organizational procedures. Complacency or a false sense of security should not be allowed to develop as a result of long periods without an accident or serious incident. An organization with a good safety record is not necessarily a safe organization. Good fortune rather than good management practices may be responsible for what appears to be a safe operation. On the whole, management attitudes and behavior have a profound effect on staff. For example, if management is willing to accept a lower standard of maintenance, then the lower standard can easily become the norm. Or, if the company is in serious financial difficulties, staff may be tempted or pressured into lowering their margins of safety by "cutting corners" as a gesture of loyalty to the com­pany or even self-interest in retaining their jobs. Consequently, such practices can and often do lead to the introduction of hazards. Morale within an organization also affects safety. Low morale may develop for many reasons but nearly always leads to loss of pride in one's work, an erosion of self-discipline, and other hazard creating conditions. THE ELEMENT OF LUCK There is an old expression humorously used by aviators when referring to the role of chance in the outcome of flight operations: "It is better to be lucky than good! " The expression means that, despite an aviator's expert skills and knowledge, sometimes just plain and simple good luck saves the day. Of course, the opposite can also be true in the sense that bad luck can overcome the efforts of everyone contributing positively to a safety value chain and result in an undesirable outcome. At least that is what can appear to be the case at first glance, although more detailed inspection often reveals that bad luck is actually comprised of variables that could have been acted on by a human, at one time or another, in order to prevent the undesirable outcome. The element of luck is important to study in more depth. We often hear motivation sayings that discount the role of luck in life. One explanation of luck as a positive force states that it is preparation meeting oppor­tunity. Certainly the more prepared we are, the more likely we will be to produce a good outcome to an unexpected situation. Equally so, opportunities present themselves often and can couple nicely with preparation, as the quote implies. One should notice that the term luck is often interpreted as being synonymous with good outcomes, whereas in reality luck can refer to influences that lead to a good outcome or a bad outcome. Luck, otherwise known as chance, has no pur­pose, is unpredictable, and uncontrollable, but yet can determine the outcome of an event both favorably and unfavorably. What remains after our exhaustive attempts at controlling variables that impact aviation safety can be considered luck. The element of luck is rarely exam­ined in traditional aviation safety literature. One possible explanation for such an absence of discussion about luck is that, by definition, we can do nothing to impact how luck affects the safety error chain, so some argue that any time devoted to studying luck is a waste of time. The opposing argument is that safety professionals view the element of luck as producing a need to expect the unexpected and that we must therefore plan for the unexpected, whenever possible. Such safety professionals usually hear talk of helplessness at controlling luck and counter by saying, " Safety is about making your own luck!" For those desiring an example of how luck plays a role in commercial avia­tion safety several cases can be found by canvassing accident and incident reports. A clear example is U.S. Airways Flight 1549 in 2009 which is popularly known as "The Miracle on the Hudson." It was bad luck that Captain Sully Sullenberger and First Officer Jeff Skiles hit several large birds with their Airbus 320 during their climbout from New York City. The impacts resulted in the two aviators having to ditch their Airbus in the Hudson River. It was particularly bad luck when one considers that the difference of just a few seconds in their takeoff time would have resulted in the flight missing the birds altogether. However, it was good luck that the aircraft hit the birds during the daytime and while in visual meteorological conditions, since doing so allowed the pilots to visually acquire the river and line the jet up for a safe ditching. Another example of luck, also from the year 2009, is Emirates Flight 407 dur­ing its departure from Melbourne, Australia. It was certainly not luck but human error when the flight crew of the Airbus 340 programmed incorrect data into the flight deck automation, resulting in lower than necessary engine thrust for takeoff. When the aircraft was unable to climb it was arguably excellent luck when the flight subsequently only hit the strobe lights and localizer antenna at the end of the runway, cleared a building by only 20 inches, and then safely returned the aircraft for landing! The conceptual models discussed in this chapter do their best to incorporate the large categories of factors that combine to create an accident sequence, but do not fully address the role of luck in the sequence and subsequent outcomes. CASE STUDY: AIR FRANCE FLIGHT 4590 Figure 2-18 shows the stunning profile of a Concorde aircraft in flight as it used to be operated by Air France. On July 25, 2000, during takeoff on a flight from Paris to New York City, an Air France Concorde's tire ran over a strip of metal that had fallen off another aircraft. As a result, debris was thrown against the Concorde's wing structure and caused a fuel tank to rupture. Shortly after, a fire ensued and was fueled by the leak in the tank. The crew shut down engine number two, which was operating near idle power and noticed that the landing gear would not retract. For around a minute the aircraft was able to fly but was unable to gain height or speed. Engine number 1 eventually lost thrust, as did engines 3 and 4. The aircraft subsequently crashed into a hotel, killing 113 members on board plus 4 employees of a hotel on the ground. The French Bureau Enquires Accidents (BEA) was the government agency that conducted the accident investigation. This case study is meant to illustrate the highly complex nature of accident causation to include the myriad factors that combine to produce a fatal sequence of events culminating in tragedy for all aboard an aircraft and even to some on the ground. As such we are all stakeholders in commercial aviation safety, since even if we do not fly, aircraft do fly over our heads, and history is filled with examples of how safety problems aloft can take a direct toll on the safety of those who feel that they are safely on the ground. This case study provides the findings, causes, and recommendations contained in the accident report, along with the mention of some of the processes used during the investigation. The reader is urged to think about the previously exposed visual conceptual models contained in this chapter while reading through the case study. It bears noting that another airline played a role in the sequence of events, which further illustrates how a safety error chain often extends beyond a single operator's purview and onto other domains such as other airlines, air traffic control, airfield operations, and meteorology. Figure 2-19 shows the appearance of part of the flight deck instrument panel as part of the wreckage of the Concorde. FINDINGS AND CAUSES The following is a collection of noteworthy findings from the BEA investigation, showing within curly brackets whether the finding was also deemed causal in the accident sequence. Please pay close attention to which findings are considered causal and which findings are not considered causal in order to prepare to under­stand the contents presented in Chapter 6 of this book. • A metallic strip from the thrust reverser cowl door of engine number 3 on a Continental Airlines DC-10 had been replaced in Tel Aviv in June 2000 during the aircraft's "C" check, then again in Houston on July 9. • The strip installed in Houston had neither been manufactured nor installed in accordance with the procedures as defined by the manufacturer. • The metallic strip fell from the Continental Airlines DC-10 onto the runway dur­ing takeoff 5 minutes before the Concorde departure without detection by the DC-1 0 crew, the airfield manager, air traffic control, or the Concorde crew. • {Causal} A tire on the Concorde struck and continuing airworthines management exposition apart due to striking the metal­lic strip, expelling portions of the tire. Figure 2-20 shows how investigators analyzed the potential consequences of running over the metallic strip with a Concorde tire. • {Causal} Portions of the Concorde tire ruptured one of the Concorde fuel tanks. A part of the underside of tank 5 was found at the accident site and had a punc­ture 10 millimeters wide and 40 millimeters long. • {Causal} The fuel leaking from the punctured tank caught fire from the electric airworthiness review certificate in a landing gear bay or from contact with hot parts of an engine. • The fuel that was leaking ignited; a flame and large quantities of smoke appeared behind and to the left of the aircraft. A large kerosene mark was found on the runway, immediately after the piece of the tank. • Around 10 meters after the unburned kerosene mark, some soot marks on the runway and then some traces of burnt grass on the left edge of the runway were noted over a distance of 1,300 meters. • {Causal} After the Concorde passed over the metallic strip, the rupture of fuel tank number 5, and the ignition of the leak, engines 1 and 2 suffered simulta­neous surges leading to slight loss of thrust on engine 1 and a severe loss on engine 2. • The surge on engine 1 was most likely caused by ingestion of hot gases or solid debris, probably pieces of tire, that on engine 2 resulting from ingestion of hot gases due to the fire. • Because of the incomplete opening of the left main landing gear door or the absence of detection of opening of these doors, the crew was unable to retract the landing gear. • Because of the lack of thrust and the impossibility of retracting the landing gear, the aircraft was in a flight configuration which made it impossible to climb or to gain speed. • Many pieces of the aircraft found along the track indicate that severe damage to the aircraft's structure was caused in flight by the fire. • Even with the engines operating normally, the significant damage caused to the aircraft's structure would have led to the loss of the aircraft. RECOMMENDATIONS In an effort to prevent similar accidents, the BEA published the following recommendations: • Suspend the airworthiness of the Concorde until measures have been taken to guarantee a satisfactory level of safety associated with the destruction of tires. • Air France should verify that emergency procedures in the section of Concorde utilization in the Operations Manual be in accordance with the Flight Manual. • An audit should be conducted to analyze the operational and maintenance conditions of the Concorde within Air France. • Aviation authorities should study the regulatory requirements and conform with requirements for aviation tires. • Ensure a rapid implementation of a program for the management of debris on runways. • The federal aviation administration should audit Continental Airlines maintenance practices both in the United States and in foreign locations. INVESTIGATION To conduct the accident investigation, multiple parties were involved. The team consisted of BAE Systems, Rolls Royce, FAA, NTSB, the German Federal Bureau of Aircraft Accident Investigation, Air France, and France's aviation accident inves­tigation bureau (BEA). The head investigator established seven working groups to find and collect the information needed for the investigation. The investigation was divided into the following areas: site and wreckage, air­craft/systems/engines, preparation and conduct of flight, flight recorders, aircraft performance, witness testimony, and examination of previous events. The results from these efforts allowed the BEA to publish a preliminary report of the accident. Further analysis was then conducted on the wreckage, the conduct of the flight and aircraft performance, previous events/certifications/regulations, and techni­cal teardowns. A final report was then released detailing the findings, causes, and recommendations for the event. Figure 2-21 shows the field portion of the aircraft/ systems/engines portion of the investigation, where personnel can be seen examin­ing what is left of the upper nozzles of one of the engines. It should be noted that the previously depicted findings and causes for this accident did not clearly distinguish between the root causes and the active causes of the accident. Such a distinction may not be evident in an accident investigation report unless the full report is read to include the background analyses and inter­views that were performed. In the case of the Concorde accident, a careful exami­nation of the proffered recommendations will reveal that they address several root causes of the tragedy. When reading through the findings and causes of this accident, we can see the multi-causality "Swiss Cheese" principle quite clearly. The multi-causality principle states that accidents result from numerous factors combining to create an accident sequence. To begin, the metallic strip that fell off the Continental Airlines DC-10 had not been installed per the manufacturer's specifications. It is probable that the improper installation led to the part detaching from the plane. This event combined with the airport management's inability to detect that there was a foreign object on the runway. The DC-1 0 pilots could not be expected to detect when a small part such as the metallic strip fell off their aircraft, and the Concorde pilots certainly could not see such a small part as they rolled down the runway with their focus on the other aspects of takeoff, such as monitoring airspeed and engine performance. The multi­causality principle in this accident showcases the role of other personnel in the sequence of events, such as the Continental Airlines aviation maintenance techni­cians, the Paris airfield managers, and even Air France for not taking precautions to prevent what it turns out was an already noted hazard of having tire debris from the blown tires puncture fuel tanks. One aspect that makes this tragic accident particularly interesting is that two aircraft were involved as part of two different events, separated by time, but then one event had a direct impact on the other when the dropped part of one aircraft caused damage on the second aircraft. Such a combination illustrates the complex nature of the accident. When such special complexity is introduced, the size of the investigation increases since there are more factors involved worthy of analysis. Investigators need to examine not only the safety breakdown of both aircraft indi­vidually, but also how safety degraded between the two aircraft as a coupled sys­tem. Such an intricate dance of variables helps us understand the previously stated concept that complex problems do not have simple solutions. It is also worth noting the temptation to determine the active causes of the accident without discerning the critical root causes. Investigators of the Concorde accident correctly dug deeper into the causes to extricate the root issues that contributed to the accident. For example, let us consider the finding that the metal strip had been installed incorrectly on the DC-1 0. We could write the fac­tor off as maintenance error, but doing so and going no further would not achieve our goal of permanently fixing problems to improve safety. In the Concorde case, investigators found out what had happened and correctly kept investigating in order to find out all the reasons why the accident happened by studying why the metal strip was installed incorrectly. Was it a case of the maintenance team performing a shift change and not providing proper work continuity? Perhaps one or several aviation maintenance technicians were fatigued or dehydrated due to scheduling practices or lack of proper facilities for work? What if the guidance provided to aviation mainte­nance technicians was wanting? Was the training of such specialists insufficient? To figure out the answer to these possibilities investigators have to trace prob­lems back to operations management and external support. Depending only on the active causes of accidents will leave the underlying issues unaddressed and, thus, accidents related to the unaddressed factors will continue to occur. We can't just look at the superficial level in which causes occur; we must always seek out the root causes. Lastly, the example of the metal strip on the runway relates back to the medium component of the 5-M model. In this case, the environment for flight was jeopardized because of a hazard on the runway. The strip was an artificial portion of the environment that should not have been naturally present. Only once we are able to address each and every component of the 5-Factor model can we hope to detect the key components of a safety error chain. CONCLUSION This chapter has explored some of the fundamental concepts underpinning acci­dent theory. Understanding the theory is aided by the use of models, some with highly creative names such as the "Swiss cheese," SHELL, and 5-Factor models. All models have one common element: the fact that accidents are caused by more than one factor, a core principle of accident theory called multi-causality. Yet in spite of using such depictions to portray the complexity of accident theory, a popular but flawed idea is still held by the media and general public that most accidents or inci­dents can be traced to a single human failure somewhere, often mischaracterized simply as "pilot error." The reality of the matter is that human failure is very much present, but should be viewed as extending far beyond the immediate and active acts of those who are closest in time to an accident. An aviation maintenance technician who improperly replaced a hydraulic pump or an air traffic controller who erroneously cleared an aircraft to land on an occupied runway may only represent active causes of an acci­dent, whereas accident theory tells us that such active causes have deep roots that must be investigated to prevent future incidents and accidents. Machines are designed, built, and operated by humans. Thus, a failure of a machine is really a failure of one or more humans who designed the machine. Likewise, humans may not avoid or eliminate known environmental hazards, or they may create additional hazards. Thus, these could all be considered failures of humans rather than environmental failures. This interpretation, therefore, accounts for the wide discrepancy in the percentages of accidents attributed to human failure reported by different sources. The visual conceptual models discussed in this chapter clearly show that many aviation hazards are brought about by problems at the interface between technol­ogy, human, and organizational factors. A combination of these elements can be found in the error chain, as accidents generally have many contributing factors. Such an idea of multi-causality at different levels of an organization, as pioneered by James Reason, underpins accident theory and prompt all members of the safety value chain to be aware of his or her role in accident prevention. If investigators neglect one piece of the accident puzzle, that factor may show up as a cause of yet another accident. It must be noted that in aviation, it is practically impossible to attain an envi­ronment devoid of threats to safety. Safety has been defined as the freedom from risk or danger, but whenever people are working with objects that move very fast under human control and have high potential energy, there will always be some sort of risk present. As is obvious by the concepts in this chapter, the human element is critical to the safety value chain. Humans engender the idea for an aircraft or other piece of aviation equipment, then assemble components and the overall aircraft, and finally also train professionals and operate the equipment. There are many ways that humans can commit unsafe acts or underperform due to human limitations during any of those phases. Therefore, the next chapter will explore the challenges pre­sented to commercial aviation safety by the human tendency to commit errors and to fail at tasks that demand high reliability. The next chapter will also delve into the changing nature of expertise in aviation and other human tendencies that can combine to create error or less than optimal performance. We will also look at the relationship between professionalism and safety and explore the intimate relationship between humans and automation on the modern flight deck. KEY TERMS "4 Ps" of Human Performance 5-Factor Model Accidentology or Accident Theory Active or Proximate or Apparent Cause Causation Cause Complexity Error Chain Human Factors Multi-causality Predictive Safety Proactive Safety Professionalism Reactive Safety Reason's "Swiss Cheese" Model Reasonable Person Concept Root Cause Analysis Root or Enabling or Latent Cause software hardware environment liveware Model Unsafe Acts Visual Conceptual Model REVIEW QUESTIONS 1. Which area do you think safety analysts should focus on the most today: technical factors, human factors, or organizational factors? 2. How do the recommendations stemming from West Caribbean Airways Flight 708 illustrate the need for root cause analyses to prevent future accidents in commercial aviation? 3. Explain the difference between active causes and root causes. 4. Explain the difference between findings, causes, and recommendations. 5. Why do we use models, such as the software hardware environment liveware and 5-Factor models, to learn accident theory? 6. Do you think it is possible to develop simple solutions to complex aviation problems? 7. What are some logical fallacies that directly relate to accident theory? 8. Do all problems stem back to one or more root causes, or is it possible that some causes are simply active and exist without roots? 9. Explain Reason's "Swiss Cheese" model of defensive layers to include the con­cept of latent and active failures. 10. Develop a fictional accident that is the result of two holes in the " Swiss Cheese" model. 11. Why is "Liveware" always in the center of the software hardware environment liveware model? 12. Are there any other elements that you think should be accounted for in the 5-Factor model? 13. The medium or environment includes two parts, the natural environment and the artificial environment. Compare and contrast the two parts. 14. How does the role of luck impact commercial aviation safety? How is luck fea­tured in accident models? 15. Write a short paragraph explaining how the case study of Air France Flight 4590 exhibits the major concepts of this chapter. 16. Produce a recommendation to prevent accidents based on the Air France Flight 4590 case study, then speculate as to reasons why such a recommendation may not have been part of the accident report.