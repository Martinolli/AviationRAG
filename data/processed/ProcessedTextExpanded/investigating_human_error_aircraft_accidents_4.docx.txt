Title: Investigating Human Error Incidents, Accidents, and Complex Systems – Chapter(s) 3 - 4 Author(s): Barry Strauch Category: Safety Tags: Human, Error, Investigation, Accidents, Incidents, System 3 Analyzing the Data As is so often the case when we begin to learn the complexities of a situation, some of the issues that had seemed very clear at the outset have become more confusing. Only much later would we fully understand the extent to which oversimplification obfuscates and complexity brings understanding. Vaughan, 1996 The Challenger Launch Decision: Risking Technology, Culture, and Deviance at national aeronautics and space administration Introduction Most of us routinely make judgments from available data, perhaps without recognizing that we have done so. We examine the behavior of our friends, acquaintances, and political leaders and infer motives from their behavior to explain them. This process—examining an action and explaining it—is the foundation of the human error investigator’s work. Differences between this type of informal analysis and the more formal one used in error investigations result less from differences in the process than in the application. Unlike the informal process applied to everyday situations, investigative analysis is applied systematically and methodically. This chapter examines the principles of investigative analysis, the process in which error investigators identify relationships between operator errors and their antecedents. Investigative Methodology Accident investigation methodology and scientific methods have similar objectives in explaining observed phenomena or events by using formal methods of data collection and analysis. The objectives of scientific research correspond to those of accident investigations, “[the] systematic, controlled, 40 empirical, and critical investigation of hypothetical propositions about the presumed relations among natural phenomena” (Kerlinger, 1973, p. 11). Although control groups are not used in accident investigations and the process is not empirical, accident investigators apply a systematic and critical methodology to study the relationships between antecedents and errors, and the relationships among those errors, to determine the extent of the relationships, if any, between those errors and the incidents and accidents that the errors may have caused. Ex Post Facto Designs Investigators collect and analyze data after the fact, that is, after an accident has occurred, using a method that is similar to “ex post facto” research designs. Here, investigators work backward after the event has occurred, and the data have been collected to identify and explain the nature of the variables that led to the event. Ex post facto analytical techniques allow investigators to effectively explain the nature of the relationships underlying the data and apply them well beyond the immediate circumstances of the event under investigation. Well-conducted investigation analyses fall within Vicente’s (1997) observation that “science…encompass(es) naturalistic observation, qualitative description and categorization, inductive leaps of faith, and axioms that can never be empirically tested” (p. 325). However, researchers have recognized that this method, although providing critical insights into event causation, can lead to analytical inaccuracy. Because data are gathered after the fact, researchers and investigators can select from and apply a favored explanation to account for the obtained results rather than be compelled to accept the explanation that the data offer from experimental design techniques developed before the fact (e.g., Kerlinger, 1973). Dekker (2002, p. 374) and others refer to this as hindsight bias, a tendency in accident investigations to lead investigators to, as he writes, make “tangled histories” of what operators were dealing with at the time of an accident “by cherry-picking and re-grouping evidence” to fit their view of what transpired in the accident. However, knowledge of an operator’s error and the accident that occurred, as a result, need not necessarily lead to highlight bias. In fact, investigators, as a matter of course, recognize that their job calls on them to explain errors from the perspective of the person who committed them because doing so allows a proper analysis to be conducted of the system flaw that led to the error. Nonetheless, error investigators compensate for this potential limitation because they typically obtain data on many measures, data that had been continuously collected throughout the event, unlike researchers who generally collect data on only a few parameters, often only at selected intervals and under highly controlled conditions. Further, investigators examine real-world behavior under conditions that could not reasonably be examined in controlled settings. Thus, by collecting considerable data about an event, subjecting the data to objective and systematic analysis, and being sensitive to the possibility of hindsight bias, investigators can avoid allowing hindsight bias to affect their analyses. Imprecision The logic of error investigations assumes a direct relationship between one or more system deficiencies or shortcomings and the critical error or errors that led to an accident. The previous chapter described the basic model that this text follows, that is, antecedent leading to error, which then leads to an accident; subsequent chapters will describe the particular antecedents that investigators need to examine and their potential influence on operator performance. Although the investigative process is systematic, it is still affected by the skills and experience of the particular investigator. For this and other reasons, some have shied away from definitive identifications of accident “causes.” As noted in Chapter 2, “there is no absolute cause” of an accident because imprecision is an inherent part of error investigations. Absolute certainty in establishing the errors leading to an event is an impossibility. Klein, Rasmussen, Lin, Hoffman, and Cast (2014) referred to the explanation of behavior as “indeterminate causation,” which, as they write, “is involved in the anticipation or explanation of human belief and activity” (p. 1381). Moreover, they note that when dealing with explanations of events involving human behavior, for example, why a sports team lost, …no amount of analysis can establish the “actual” cause or single cause or “root” cause. There are no single or uniquely correct answers to such questions, and no amount of research would uncover the one “real” cause or the “objective” cause because there is no such thing. (p. 1381) As a result, some investigative agencies use the term “probable cause” of an accident rather than the more succinct and absolute “cause,” acknowledging that, despite their best investigative and analytical efforts, the influence of an unidentified variable remains a possibility. Some agencies do not use the term “cause” at all in their investigations but list findings instead, as does the Australian Transport Safety Bureau (2007). Some have criticized the use of any type of cause in an investigation. Miller (2000), for example, suggests that this Relates back to a subject pursued for the past quarter century or so— that detestable preoccupation most people seem to have with “cause.” If investigative processes and classifications of accident findings continue to be hung up on “cause” instead of pursuing the implementation phase [of remediation strategies and techniques] further, we are going to be static at best in prevention efforts. (p. 16) 42 Yet, differences in the results of incident and accident investigations between organizations that determine a cause and those that do not suggest little difference between them. Whether an organization determines a probable cause or not appears to make little difference to the quality of the investigation or its proposed recommendations. Irrespective of a requirement to develop a cause for an event, the key focus for investigators should be on conducting a thorough and systematic investigation in order to reduce future opportunities for error. Doing so will result in effective investigations, regardless of the nature of the “cause” or “findings” that are determined. As Klein et al. (2014) note, “Regardless of which causes are invoked, an explanation has to adopt a format or argument structure for characterizing these causes” (p. 1381). An Illustration A hypothetical accident illustrates the process. Assume that a train failed to stop at a stop signal (also referred to as an “aspect”) and struck another train that had been standing on the same track. The locomotive engineer had an unobstructed view of the signal. The engineer claimed that he observed a stop signal and applied the brakes, but the brakes failed. If he is correct, investigators will have to identify a mechanical malfunction as the cause of the accident; otherwise, they would unfairly fault an operator who performed well and, worse, from a safety consideration, fail to address hazards that led to the accident in the first place. However, before they could accept the engineer’s explanation as the most likely cause of the accident, investigators would have to test and accept the viability of several possible conclusions that are necessary to accept a failed brakes explanation. These are: 1. The brakes were defective at the time the engineer claims to have applied them 2. Brakes with this defect would be unable to stop a comparable train traveling at the same speed, in the same distance, on the same track section 3. Other possible malfunctions that could also have failed to stop a comparable train traveling at the same speed, in the same distance, and on the same track section were not identified. Thus, investigators are faced with only two possible alternatives to the cause of the accident, assuming that signals, track, and other train systems were not involved. Either the engineer failed to properly apply the brakes, or he applied them correctly, but a mechanical malfunction prevented the brakes from stopping the train. To determine which of these conclusions is supported, investigators would need to collect a variety of system data. If the data supported these conclusions, they could be reasonably confident that 43 defective brakes caused the accident. If not, other explanations would need to be proposed, and the data would need to be reexamined and reanalyzed. The data would either support or refute the proposed explanations. Analysis Objectives As discussed in Chapter 2, investigators bring their own perspectives to the analysis, depending upon their employer, their values, and the like. The investigation objective that is endorsed in this text is to identify the errors and their antecedents that led to the occurrence being investigated so that future opportunities for error can be reduced or eliminated. Investigators should examine the collected data to meet this objective until they are confident that the identified relationships conform to the criteria that will be discussed shortly. During an investigation, it is likely that investigators will collect different types of data of varying quality. Before analyzing the data, they evaluate the collected data to assess their value in the investigation. Not all data are of equal value, and some types of data should be given more consideration than other types. Assessing the Quality of the Data Some of the data that investigators collect pertain to the investigation objective, while other data may not; some data sources will be complete, and others will not. Including incomplete data and data that do not address the antecedents of error in the analysis will lead to an analysis that contributes little to understanding the origin of the particular errors, or worse, is incorrect. Determining the quality of data is critical because the effectiveness of an investigation largely depends on the quality of the data that investigators collect. “Garbage in-garbage out” applies to the analysis of errors in incidents and accidents as it does to other types of analysis. Two standards of quality are used to assess data value: internal consistency and sequential consistency. Internal Consistency Anderson and Twining (1991), describing legal analysis, believe that internally consistent data should converge into one conclusion. Converging data, they argue, even if derived from different sources and collected at different times, support the same conclusion. For example, if an operator’s performance history reveals deficiencies and those deficiencies are similar to characteristics of the operator’s performance at the time of the occurrence, the data converge. In that instance, one could reasonably conclude that the operator’s performance during the event was consistent with his 44 performance in previous similar circumstances and not an aberration. In complex systems, internally consistent data converge by depicting different aspects of the same event similarly at the same points in time. If they do not, the data will not be internally consistent. In the hypothetical railroad accident in which defective brakes are suspected of having caused the collision, one can assume that at a minimum, investigators will collect data regarding • The operator’s train orders and his or her interpretation of them • The operator’s speed, power, and brake application commands • The actual train speed, power, and brake settings • Pertinent operating rules, procedures, and operating limitations • The operator’s training and performance record • Toxicological analysis of specimens of the operator • The operator’s sleep/wake history before the accident • The operator’s medical history and medication use • The commanded and displayed signals • Lights, flags, or markings at the aft end of the standing train • Company oversight of its operations • The regulator’s history overseeing the railroad. If the brakes had been defective and investigators determined that the defect caused the accident, internally consistent data should reveal the effects of the defect among a variety of types of data. All data, except those pertaining to the brakes and those independent of the sequence of antecedents and errors/flaws leading to the event, should be consistent. However, if the data showed defects in other components that could have altered the sequence of occurrences, or if the brakes were found to have been defect-free, the data would be inconsistent, and the discrepancy would need to be resolved. Inconsistencies could be caused by deficiencies either in the data or in the proposed theory or explanation of the cause of the event. Deficiencies in the equipment-related data could result from flaws in the recording devices, measuring instruments, or, with eyewitnesses, in their perceptions and recall of the event. Inconsistencies in operator-related data could be caused by several factors, which will be discussed shortly. Otherwise, inconsistent data indicate the need to revise the theory or explanation of the cause of the accident, reexamine the data, or collect additional data. These are likely sources of inconsistent data. Inconsistencies among the data, though rare, are most often found among eyewitness accounts and operator-related information. Substantial differences among eyewitness accounts are infrequent, but, as investigators found in the explosion of the Boeing 747 off the 45 coast of Long Island, occur occasionally (National Transportation Safety Board, 2000a). Inconsistencies in eyewitness data largely result from perceptual and memory factors, as well as differences in interviewer techniques, topics that will be discussed in Chapter 11. Several factors may explain differences in operator-related information. For one, people interact differently with operators than they do with others, based on their relationships with them. Colleagues, acquaintances, and supervisors have different perceptions of the operator than his or her family members, and these perceptions will affect the information they give interviewers. In addition, as discussed in Chapter 14, changes that occur over time in such parameters as measures of operator performance and health may also lead to inconsistent data. Investigators can safely discard inconsistent data if the inconsistency is not a result of deficiencies in the way the data were collected and if it can be safely attributed to factors related to investigation shortcomings or to the event itself. Investigators of the 1999 collapse of logs being prepared for a bonfire at Texas A&M University that resulted in 12 deaths discarded numerous eyewitness reports that were not supported by the physical evidence or were otherwise irrelevant (Packer Engineering, 2000; Special Commission, 2000). As investigators, who used the term Bonfire to refer to the stack of logs, describe, A large number of interview summaries prepared by Kroll [the organization that conducted the interviews] contained information which was either not in agreement with the physical evidence or not directly related to the Bonfire collapse. These summaries were not included with Packer’s [the organization that conducted the physical examination of the logs and the] analysis. Of the remaining summaries, those containing information from witnesses who were physically on the Bonfire at the time of the collapse were considered most accurate, while those of witnesses at the Bonfire but not on the actual stacks were also considered highly accurate. (Packer Engineering, p. 25) Because the physical evidence contradicted many of the eyewitness accounts and because the inconsistencies between the eyewitness reports and the other data did not result from factors related to the event or investigation shortcomings, investigators could confidently discard the inconsistent eyewitness data without affecting the quality of the subsequent analysis and the strength of the findings and conclusions. Sequential Consistency Investigative data should consistently match the sequence of occurrences and the period of time in which they occurred. The sequential relationships between antecedents and errors are invariant; antecedents will always precede errors, and errors will always precede the event. 46 In the railroad accident example used earlier, if a signal commands a stop, locomotive event recorders would be expected to show, in order, power reduction first and then brake application, corresponding to the order of the expected operator actions. The data should also match the passage of time corresponding to the occurrence in the actual period in which the train approached the signal and struck the standing train. Regardless of the rate at which actions occur and the system state changes, the two should correspond. Specific operator actions must still occur in certain orders and within specific periods of time after certain events have taken place. Further, specific operator actions should precipitate specific equipment responses. Sequentially inconsistent data may be the result of inaccurate data records, defective measuring devices, or deficiencies within the data. If the inconsistencies cannot be resolved satisfactorily, investigators may need to collect additional data or reexamine the data selection and collection methods to resolve the inconsistencies. Data Value Data vary in their value and contribution to the investigation. Depending on the event and the data, investigators may rely on some data to understand what happened and why and ignore other data. The greater the reliability, accuracy, and objectivity of the data, the greater their value to, and influence upon, the analysis. Reliable and objective data from different sources should describe the same phenomenon in the same way, albeit from different perspectives, regardless of their sources. In general, “hard” data, data obtained directly by the system, contribute substantially to the investigation because of their high reliability, objectivity, and accuracy. By contrast, the value of “soft data,” such as eyewitness accounts and interview data, is less because the data can change as a function of the person collecting the data, the time of day the data are obtained, and the skill of the interviewer or person collecting the data, among other factors. Relevance Anderson and Twining (1991), referring to legal analyses, consider a statement relevant if it tends to make the hypothesis to be proven more likely to be supported than would otherwise be the case. Data that can help explain conclusions regarding the cause of the event, the critical errors, and the antecedents of the errors are analogous to data that can support the hypothesis and are considered relevant to the investigation. Most investigators routinely gather data that may not necessarily relate to their investigations but are needed to rule out potential explanations or 47 factors. If it is determined that an operator did not commit an error, one can exclude data from the analysis that pertains to the operator’s performance history without degrading the quality of the analysis or the investigation unless the data relates to other critical issues. On the other hand, if operator error is believed to have led to the incident, almost all data concerning the operator would be considered relevant and, therefore, would be included in the analysis. Data relevance can change as more is learned about an event. For example, an initial focus on potential training deficiencies makes information pertinent to the development, implementation, and conduct of the training relevant to the investigation. If the data suggest that equipment design factors rather than training affected operator performance, operator training-related data would be less relevant. Quantity The more data obtained about a particular aspect of the system, the more confidence one can have in the value of the data and their contribution to the analysis. For example, in some systems, multiple recorders capture a variety of operator performance parameters, documenting the operator’s spoken words and any related sounds. These provide a considerable amount of data that describe, both directly and indirectly, what the operator did before and during the event. If there is little data available, other measures that can approximate the parameters of interest should be sought. If no data directly describes aspects of operator performance, investigators may need to learn about operator actions from other sources, such as system recorders. If there is insufficient data available to allow inferences about the parameters of interest, conclusions regarding the data of interest will have little factual support. Identifying the Errors After the data have been examined and evaluated, one can begin to propose relationships among antecedents, errors, and the causes of the event. The Sequence of Occurrences To begin developing the critical relationships, first establish the sequence of actions and occurrences in the event. The sequence will determine the order of actions and decisions and facilitate the task of identifying the critical relationships. Establish the sequence of occurrences in the event by working backward from the event itself until the errors that led to the event and the antecedents to those errors are reached—what Rasmussen, Pejtersen, and Goodstein (1994) refer to as the “stopping point.” Regardless of the event, whether an airplane accident, chemical refinery explosion, or vessel grounding, stop collecting data and analyzing the data at the point at which the sequence of occurrences that led to the incident or accident begins. Using the railroad accident discussed earlier, the sequence of occurrences begins with the collision. Working backward from the event, occurrences earlier in the sequence would likely include the engineer’s brake application and power reduction and progress to company brake maintenance practices, going as far back as brake manufacture and locomotive assembly. The sequence of occurrences includes major system elements. In this illustration, these would include the operator, the railroad, the regulator, and the brake system. However, a few issues should be ruled out early in the investigation. Data pertinent to those issues need to be collected to determine the role of each element in the event. For example, if it is learned that the locomotive engineer did not apply the brakes properly, then operator actions would be a focus of the investigation, and investigators would need to identify potential antecedents to those actions. Other issues to be investigated would likely include the railroad’s training and oversight of its operators and the regulator’s oversight of the railroad. Although each accident is unique with its own set of occurrences, the critical facts, in this instance, the collision and the record of inspections of the brakes and their manufacture, would not be in dispute. A list of an initial sequence of occurrences of the hypothetical railroad accident is illustrated below. The Sequence of Occurrences—Beginning with Collision 1. Collision 2. Locomotive operator brake application 3. Locomotive operator power reduction 4. Railroad signal system maintenance and inspection 5. Locomotive operator initial and refresher training 6. Railroad brake system maintenance and inspection 7. Railroad brake system maintenance personnel selection practices 8. Brake system manufacture and installation 9. Railroad signal system selection and acquisition 10. Signal system manufacture 11. Railroad signal system selection and installation 12. Railroad signal installer, maintenance, and inspection personnel training 13. Locomotive operator selection 14. Railroad brake system maintenance personnel selection practices 15. Railroad signal system installer, maintenance, and inspection per personnel selection practices 16. Regulator oversight of railroad signal system 17. Regulator oversight of brake system Let’s assume that in this example, after interviewing critical personnel and collecting and examining the data, investigators determine that the operator performed satisfactorily. In that case, data relating to operator performance history can be safely excluded from the sequence of occurrences and from subsequent data analysis. The results of a second iteration of a sequence of occurrences, after first discarding occurrences irrelevant to the issues of interest, can be seen in the list below. Events Excluded 1. Locomotive operator brake application 2. Locomotive operator power reduction 3. Locomotive operator initial and refresher training 4. Locomotive operator selection Events Retained 1. Collision 2. Railroad signal system maintenance and inspection 3. Railroad brake system maintenance and inspection 4. Railroad brake system maintenance personnel selection 5. Brake system manufacture and installation 6. Railroad signal system selection and acquisition 7. Signal system manufacture 8. Railroad signal system selection and installation 9. Railroad signal installer, maintenance, and inspection personnel training 10. Railroad brake system maintenance personnel selection practices 11. Railroad signal system installer, maintenance, and inspection per personnel selection practices 12. Regulator oversight of railroad signal system 13. Regulator oversight of brake system The Error or Errors After examining the data, assessing their relative value, and establishing the sequential order of occurrences, investigators can exclude from the analysis several additional factors that would no longer be considered relevant to the accident. For example, if tested and found to have been in acceptable condition at the time of the event, factors related to the signal system may now be considered irrelevant. The next step in the data analysis can now be conducted, identifying the errors that led to the event, which is perhaps the most critical step in the analysis. This step is distinct and separate from the formal or legal determination of the accident cause. The focus should be on the errors suspected of leading to the event. Assessing the Relationship of Antecedents to Errors After identifying the errors, the antecedents of those errors must be determined. The process is largely inferential, based on investigative logic regarding the relationship between the two. The evidence consists of the nature of the error, as well as information from written documentation, interviews, system recorders, equipment, and other sources. Inferring a Relationship A relationship between antecedent and error must be logical and unambiguous. Investigators must establish that the antecedent, either by itself or with others, influenced the operator’s performance so that he or she committed an error. To identify the antecedent, one should ask a counterfactual question: would the operator have committed the error if this (and other) antecedent(s) had not preceded it? If the answer is no, one could be confident that the antecedent led to the error. Counterfactual questions are central to analyzing error data in investigations. Assume that insufficient operator experience is one of several antecedents that affected the performance of an operator, and the operator misinterpreted system-related data as a result. A relationship between experience in operating a system and the error of misinterpreting data is logical; a more experienced operator is less likely to commit the same error than a less experienced one. This conclusion is supported by research findings and the determinations of previous accident investigations. This relationship between antecedent and error is clear and unambiguous, reached only after the necessary facts have been obtained and analyzed. Statistical Relationship The logic used to establish a relationship between antecedents and errors is analogous to multiple regression analysis, a statistical technique used to determine the relationship between one or more predictor variables and a single variable (e.g., Harris, 1975). Economists, for example, employ multiple regression analysis to predict the combined effects of changes in variables such as the prime interest rate, unemployment, and government spending or changes in an outcome variable such as the inflation rate. The stronger the relationship between the predictor or influencing variables and the outcome variable, the higher the correlation between the two sets of variables. In relationships that have high positive correlations (say 0.60 or higher since correlations of plus or minus one are the limits of correlational strength), changes in the predictor variables are associated with corresponding changes in the outcome variables. As the value of predictor variables increases or decreases, the value of the outcome variable similarly increases or decreases. If the correlations are negative, predictor variable changes in one direction would be associated with outcome variable changes in the opposite direction. As the predictor variables increase or decrease in value, the outcome variable loses or gains value in the opposite direction. Multiple regression analyses also describe another facet of these relationships that can be stated statistically; when the correlation between the two sets of variables is high, the predictor variables account for much of the total variance in changes in the outcome variable. That is, the higher the correlation between the two, the more that changes in the predictor variables—and not some other variable or the effects of chance—are associated with changes in the outcome variable. The lower the correlation, the less that changes in the outcome variable can be attributed to changes in the predictor variables. In that case, changes in the outcome variable will more likely be associated with variables that had not been considered in the analysis. In investigations of error, the predictor variables correspond to the antecedents and the outcome variable to the critical error. Investigators assess the relationship between one or more antecedents and the operator’s error in the circumstances that prevailed at the time of the accident. The stronger the relationship between the antecedents and errors, the more the antecedents would account for “variance” about the errors, and the more the error can be attributed to those antecedents and not to other variables or antecedents not yet recognized. Relating Antecedents to Errors In short, and as mentioned, relationships between antecedents and errors need to meet three critical criteria: (1) they should be simple, (2) logical, and (3) superior to other potential relationships among the variables. These criteria are related; if a relationship meets one criterion, it will likely meet the others as well. The influence of an antecedent variable on the error should be as simple as possible. One should be directly related to the other, with as few assumptions 52 as possible needed to support it. A simple relationship should also be logical, one that makes sense to all concerned. It should require little analytical effort to understand the relationship between one and the other. In addition, it should be simpler and more logical than other alternative proposed relationships. Counterfactual Questions To determine with confidence that a proposed error has contributed to the cause of the event, ask a counterfactual question: would the accident have occurred if this error had not been committed? If the answer is no, the accident would not have occurred; one can be confident that the error caused or contributed to the cause of the accident. Using the train collision illustration, assume that (1) the brake defect resulted from a maintenance error and (2) the defect was sufficiently conspicuous that inspectors should have noticed it during routine inspections, but they did not. In addition to the errors of those involved in the brake maintenance, the investigation would also examine the inspectors’ errors and consider them contributory to the accident. In this accident, if neither error had been committed, the accident would not have occurred. Both errors are needed for the accident to occur, and each can be considered to have led to the accident. If the maintenance error has been identified, the list of relevant occurrences to be retained can be further narrowed, with a concurrent expansion of the list of those excluded, as illustrated below. This list includes the accident itself, the errors that directly led to it, as well as the antecedents that may have allowed the errors to occur. Events Excluded 1. Locomotive operator brake application 2. Locomotive operator power reduction 3. Railroad signal system maintenance and inspection 4. Locomotive operator initial and refresher training 5. Railroad signal system selection and acquisition 6. Signal system manufacture 7. Railroad signal system selection and installation 8. Railroad signal installer, maintenance, and inspection personnel training 9. Locomotive operator selection 10. Railroad signal system installer, maintenance, and inspection per personnel selection 11. Regulator oversight of railroad signal system Events Retained 1. Collision 2. Brake system manufacture and installation 3. Railroad brake system maintenance and inspection 4. Railroad brake system maintenance personnel training 5. Railroad brake system maintenance personnel selection 6. Regulator oversight of brake system Multiple Antecedents In complex systems, multiple antecedents often influence operator performance. Multiple antecedents can affect performance cumulatively by increasing each influence to bring a greater total influence on operator performance than would otherwise be the case, and they can interact with each other to differentially affect performance. Investigators should search for the presence of multiple antecedents, even if one antecedent appears to adequately explain the error. Cumulative Influence Multiple antecedents can increase each antecedent’s influence on operator performance so that their cumulative total influence is greater than would otherwise be true. For example, individual antecedents of fatigue can cumulatively influence performance beyond that of individual antecedents, as investigators found in a 1998 accident involving a commercial bus. The bus driver fell asleep while at the controls, and the bus ran off the road and struck a parked truck as a result (National Transportation Safety Board, 2000b). Investigators identified three antecedents of the driver’s fatigue. Individually, each may have been insufficient to have caused him to fall asleep while operating the vehicle, but combined, their effects were substantial. Toxicological analysis of a specimen from the driver’s body revealed the presence an over-the-counter sedating antihistamine that he had consumed earlier to treat a sinus condition. He had also worked at night for several consecutive days before the accident after having maintained a daytime awake/ nighttime asleep pattern, a schedule change that had disrupted his sleep patterns and caused a sleep deficit. Further, the accident occurred at 4:05 a.m., a time when he would ordinarily have been in his deepest phase of sleep. Those who stay awake at that time are especially prone to the effects of fatigue. Combined, the effects of the sedating antihistamine, disruptive 5schedule, and time of day were sufficiently powerful that the driver was unable to stay awake. Interacting Antecedents Interacting antecedents can differentially affect operator performance. That is, two or more antecedents together will affect performance differently than the antecedents would have if they were acting on their own. To illustrate, assume that the control rooms of two electrical power generating stations, designed 5 years apart, are identical in all respects except that one employs “older” analog gauges and the other “newer” digital displays to present system information. The same information is shown in both generating station operators, who have received identical training and use identical procedures. The operators of the two generating stations also have different levels of experience; one group has an average of ten years of experience, and the other 2 years. Thus, four different operator/equipment groups are possible: 1. Experienced operators with “old” analog displays 2. Inexperienced operators with “old” analog displays 3. Experienced operators with “new” digital displays 4. Inexperienced operators with “new” digital displays Further, in a certain nonroutine situation, the displays present information that requires the operators to respond. Only one of two responses is possible for that situation, either correct or incorrect. With no interaction, differences in operator response would be affected either by their experience or by the display type, or there would be little or no difference in their responses. Inexperienced operators might respond erroneously while experienced ones would not, or operators working with the “newer” displays could respond correctly though the others not. Alternatively, with no interaction all four groups could perform correctly or all could commit errors, in which case the effects of either operator experience or display type would lead to performance that is independent of the other. Figures 3.1 through 3.5 illustrate five of the possible outcomes. An interaction occurs when experience and display type interact to differentially affect operator performance. Operators committing the greatest number of errors could be the inexperienced ones who worked with the “older” displays. Alternatively, experienced operators working with the “newer” technology could commit the greatest number of errors, and the inexperienced operators working with analog displays, the fewest. The variety of human behavior, the diversity among procedures, training, and equipment, and the numerous component interactions within complex systems are such that the potential number of interacting antecedents that could affect performance is practically infinite. For example, training can interact with procedures or operating cycles so that certain types of training, say on-the-job training and classroom lectures, lead to different levels of performance according to the particular procedure and operating cycle. Oversight may interact with managerial experience so that certain types and levels of oversight lead to superior operator performance. Less experienced operators may perform best with extensive oversight, and experienced operators may perform best with little oversight. Some operators may perform effectively with certain types of controls but erroneously with others, according to the type of training they receive. Because of the possible presence of interacting antecedents, investigators should continue as long as reasonably possible to continue searching for error antecedents, after identifying one or two that appear to have played a role in the error in question. Concluding the Search for Antecedents Despite thorough evidence gathering and sound analysis, investigators may experience some uncertainty regarding the antecedents that were identified. “Did I overlook something?” is a question that investigators often ask themselves. Statistical and experimental design techniques airport information desk empirical researchers to reduce the role of unidentified variables, but even these techniques cannot exclude the possibility that something not identified influenced the obtained results. Researchers strive to control the variables they could identify, but because unidentified variables may always be present, absolute certainty is not possible. Rather, researchers rely on tests of statistical probability, in which the influence of randomly acting variables is measured and, if sufficiently low, acknowledged but considered sufficiently unlikely as to be absent. Accident investigators must also acknowledge the possibility that incidents that they had not identified contributed to the critical errors. Unidentified antecedents are always potential factors in investigations. Nevertheless, investigators can be confident that with methodical data gathering and thorough and objective analysis, they can minimize the possible effects of unidentified antecedents. Systematically and logically examining the effects of antecedents that are believed most likely to have influenced the probable errors, using investigative processes to determine the role of ante- cedents in error, and relying on empirical research and previous investigation findings to support the role of antecedents in error causation minimizes the likelihood that unidentified variables will be missed. Sound analytical techniques also enable investigators to recognize when they have reached the point at which the search for antecedents should be stopped. Earlier in this chapter, the “stopping point,” the point at which the search for antecedents should be ended, was discussed. For the pur- poses of this text, the stopping point is reached when investigators can no longer identify antecedents that can serve as the target of remedial action. Theoretically, the search for antecedents is infinite and investigators can never be cer- tain that they have identified all possible antecedents. Investigators should pursue all issues and seek to identify all potential errors and antecedents. However, at some point, the increase in precision needed to understand the origin of the errors or mechanical failures is not worth the expending of additional resources. When reaching the point at which logic dictates that little further activity will be worthwhile, further investigative activity becomes unproductive. For example, suppose investigators identify deficient regulator oversight as a factor in the defective brakes, used in the previously discussed example. They determine that with effective regulator surveillance, deficiencies in the railroad’s oversight would have been identified, the deficiencies corrected, and the defective brakes likely identified and repaired. However, the regulator could argue that it performed the best oversight it could with its limited resources. It could contend that it does not determine the number of its inspectors, rather, that Congress or Parliament makes that determination in its legislation. Of course, that is taking the search for antecedents to its ulti- mate conclusion. Pursuing the argument to that point is untenable if for no other reason than no agent could be identified that could implement effective remediation strategies. Before that point the investigation will have passed the point of diminishing returns, with little additional benefit gained from further activity. Recommendations After determining the relationships between errors and antecedents, identify the recommendations needed to mitigate future opportunities for error, the final step in the investigative analytical process. Many investigative agen- cies propose recommendations as the vehicle for strategies and techniques to correct system deficiencies that they have identified. Others use other means, but for the purpose of this text, the term “recommendations” will be used to describe proposed remediation strategies. Recommendations accomplish a major objective of error investigations, to address and mitigate the system deficiencies or antecedents that led to the operator errors identified in the investigation, to reduce future opportunities for error. Recommendations describe at least two separate, but related entities, (1) the system deficiency and its adverse effects on safety and (2) the proposed remediation strategy or technique to correct the deficiency and improve safety. Recommendations begin with an explanation of the deficiency and its adverse effects on safety. When referring to error, deficiencies are the ante- cedents to errors, but deficiencies can also be mechanical malfunctions, design failures, or other system defects. In general, three types of system deficiencies are the subject of recommendations; those that (1) led to the accident, (2) contributed to the cause of the accident, or, (3) were identi- fied as system safety deficiencies, but were not involved in the cause of the accident. 58 The example of the rail accident cited earlier, in which inspectors failed to detect a flaw in the system, can illustrate how to develop recommendations. Suppose that investigators identified these deficiencies regarding inspector performance in failing to recognize the defects in the brakes, 1. Inspector fatigue from abrupt scheduled shift changes 2. Inappropriate inspector expectancy from having inspected flawless components exclusively 3. Inadequate inspection station illumination 4. Inadequate inspection procedures 5. Defective equipment Recommendations can be proposed to address each of the safety deficiencies. Because the regulator and the company can correct each deficiency, the recommendations can be directed to either one. However, addressing recommendations to the regulator would, in effect, direct them to all organizations that the regulator oversees. If similar deficiencies are present at other companies, the regulator would implement or require corrective action with regard to those organizations as well in response to the recommendation. For the sake of simplicity, the recommendations used in the illustration will be directed to the regulator. Investigators can take many directions in proposing recommendations. They can suggest specific solutions or leave it to the recipient of the recom- mendation to develop its own strategies to address the deficiency. The latter method is often preferred since it gives the recipient the latitude to develop corrective actions that meet its own needs, so long as investigators are satisfied that the corrective actions will be effective and meet the intent of the recommendation. To develop a recommendation that addresses the first deficiency or ante- cedent, fatigue from an irregular work schedule, investigators can ask the regulator to revise its rules governing scheduling practices to prevent abrupt changes in shift schedules. Other recommendations, such as requiring companies to provide adequate rest periods before scheduling operators for night work, informing operators of the nature of fatigue and its effects, and providing information to both supervisors and operators to help them recognize operator fatigue, can also be made. The second deficiency, expectancies from dealing with flawless components, can be corrected by requiring companies to, randomly and without notice, include in the items to be inspected, brake systems with recognizable defects, to increase the likelihood of inspectors encountering defects, and thus reduce their expectations of flawless parts. This action would have the additional benefit of creating a mechanism for both companies and operators to identify potential inspection problems. 59 To address the third deficiency, inadequate illumination, investigators can recommend that the regulator require companies to install adequate lighting in inspection stations. A recommendation to address the fourth deficiency, inadequate company inspection procedures, could be corrected by requiring companies to review existing procedures, identify the inadequacies, and develop procedures that address them. The fifth deficiency, defective equipment, could be rectified by requiring companies to examine their inspection equipment and replace or repair those items found to be defective. The proposed recommendations address specific antecedents to acknowledged errors, by identifying the deficiencies and proposing either general or specific corrective actions to the proper recipient. Summary Analyzing error data in accident investigations is similar to conducting empirical research; both apply formal methods of inquiry to explain relation- ships within data. In a human error investigation, the relationships under study are those between errors that led to an occurrence and the antecedents that led to the errors. Human error investigators usually collect a substantial amount of data. However, only internally and sequentially consistent data should be included in an analysis. Data that do not meet these standards may have to be discarded, additional data obtained, and hypotheses revised to account for the inconsistencies. The sequence of occurrences of the event is determined by working backward from the event to identify critical errors and the antecedents that influenced the errors. Relationships between antecedents and errors should meet standards of simplicity, logic, and superiority to alternative relationships, and establish that without one the other would not have occurred. Investigators should then answer counterfactual questions to determine the role of the operator error or errors in an accident’s cause, and the role of antecedents in error causation. Investigators should also consider the potential presence of multiple antecedents after identifying key error antecedents. Multiple ante- cedents can cumulatively increase each other’s combined influence on opera- tor performance, or interact to differentially affect performance. After identifying the antecedents, investigators should develop recommendations to address safety-related deficiencies identified in the investigation. These will include the identified antecedents as well as safety deficiencies that were identified but which may not have been antecedents to the errors involved in the cause of the event. The recommendations should identify the deficiencies and suggest ways to mitigate them. 4 Equipment Designers go astray for several reasons. First, the reward structure of the design community tends to put aesthetics first. Design collections features prize-winning clocks that are unreadable, alarms that cannot easily be set, can openers that mystify. Second, designers are not typical users. They become so expert in using the object they have designed that they cannot believe that anyone else might have problems; only interac- tion and testing with actual users throughout the design process can forestall that. Third, designers must please their clients, and the clients may not be the users. Norman, 1988 The Design of Everyday Things Introduction A well-known accident involving a complex system, the March 1979 accident at the Three Mile Island nuclear generating plant (Kemeny, 1979), demonstrated the extent to which poorly designed equipment can adversely affect operator performance. Investigators found that the operators, confused by the many alarms and warnings signaling a malfunction, had difficulty interpreting the displayed data to understand the event. In World War II, the U.S. Army Air Corps and British Royal Air Force each recognized the importance of equipment design on the safety of pilots who were in training. Both changed aspects of cockpit features to enhance flight safety, based on their studies of pilot–aircraft interactions (Meister, 1999; Nickerson, 1999). Researchers have continued to study and apply human factors and ergonomics principles to the design of equipment in both simple and complex systems to improve system safety (e.g., Corlett and Clark, 1995; Karwowski and Marras, 1999; Wickens and Hollands, 2000). Research has shown that, although operators obtain much of the operating system information they need from system displays, they use other sources as well. Mumaw, Roth, Vicente, and Burns (2000) found that opera- tors actively acquire information from other operators, maintenance and 66 operating logs, and from their own observations of operating conditions. Today, it is recognized that experienced operators obtain system information from many sources, but still rely extensively on the equipment itself to understand the system state. This chapter will examine features of equipment design to understand their effects on operator performance. Visual Information Operators acquire and use system-related information to understand the current and near-term system states and the associated operating environment. Operators can obtain this information through any sensory modal- ity. Although most systems present system information visually and aurally, some use tactile cues as well, such as the stick shaker in high performance aircraft that signals an impending aerodynamic stall. Presenting information through different sensory modalities has unique advantages and disadvantages in terms of their effects on operator performance. Visual displays enable information with a high degree of precision to be presented. As a result, most system information is presented visually. But visually presented information must be displayed properly for operators to efficiently obtain critical information, and operators must be looking at the displays in order to access the information. Visual displays differ in the ease with which operators obtain and inter- pret system-related information, depending on different facets of their presentations. These features affect the quality of operator interpretation of visual information, • Number of displays • Organization and layout • Conspicuity • Interpretability • Trend portrayal The Number of Displays Visual information is presented primarily through either analog or digital displays. Analog displays are found in older systems, and generally show a one-to-one relationship between a component or subsystem and the cor- responding display of information. Systems with numerous components and subsystems may have hundreds of analog displays, each providing critical information about one component or subsystem. For example, the illustration of a Soviet era nuclear power plant in Figure 4.1 shows a display with dials too numerous for operators to readily monitor. Should one show information revealing an unusual or unexpected occurrence, the operator would be unlikely to notice the information without additional assistance. The operator would have to search the displays to identify and locate the needed information before even trying to comprehend the cause of the occurrence. During high workload periods, such as during anomalous operating conditions, numerous displays could interfere with an operator’s abil- ity to quickly locate and understand the critical data in the available time. Organization and Layout Display organization can influence an operator’s ability to access needed system data, especially in a system with numerous displays. Display groupings that do not conform to the logic that operators use to understand the system state can prolong the time they need to find and understand the needed data. The more readily the display organization allows operators access, the fewer the opportunities for operator error. Rasmussen and Vicente (1989) propose organizing information according to what they term “ecological interface design,” by matching the organization of the displays to the operator’s mental model of the system state. This will support an operator’s cognitive activities during interactions with the systems, and hopefully reduce opportunities for error. Poorly organized displays, “cluttered” displays, or displays that do not separate critical information from noncritical information will adversely affect operator performance. Wickens and Carswell (1995) refer to these adverse effects as the “information access cost” of display organization. The greater FIGURE 4.1 Soviet era nuclear power plant. Note the numerous dials and controls. (Copyright Gary Knight. Reprinted with permission.) 68 the cost, the more cognitive effort operators exert and the more time they will need to access and interpret critical information. Conspicuity The greater the contrast between a display feature and that of other displays, the more conspicuous the displayed data will be and hence, the lower the operator’s information access cost. Conspicuity is influenced by display size, contrast, and luminance relative to adjacent displays. The larger a display, and the relatively brighter it is compared to others and its surroundings, the greater it will stand out against the prevailing background, and the more likely the operator will notice it (e.g., Sarter, 2000). Interpretability The more interpretable the data, the more readily operators can use the information to understand the system state. Consider a gauge that displays an automobile’s coolant temperature. By itself, the temperature has little mean- ing to those who are unaware of the engine’s optimum temperature range in “normal” operating conditions. But a gauge that displays a picture of an engine as a face that smiles, with the smile changing to a frown and the face color becoming a deeper red as the temperature increases would be considerably more interpretable to drivers who may otherwise not understand the relevance of the temperature to the engine status. Designers have used different methods to increase operators’ ability to understand visually presented data. Abbott (2000) describes a method of presenting aircraft engine information that is considerably more interpretable than current displays of the same information, because the presentation more closely matches the needs of the operator. Aircraft engine-related data displays, and their effects on operator performance, will also be discussed in Chapter 10. Color can also readily convey information. Parsons, Seminara, and Wogalter (1999) found that in numerous countries and cultures, the color red indicates hazardous conditions. Similarly, green and yellow or amber signify normal and cautionary operating conditions, respectively. Designers have often placed colors behind a pointer or gauge on analog displays so that operators can quickly recognize the value of the component parameter as the pointer approaches the color. Automobile drivers use tachometer colors to determine when an engine “red lines” or approaches its maximum safe operating range to obtain maximum engine performance when changing gears. Digital displays allow substantial flexibility in presenting data. They can be designed to present pictures, smiles, or frowns, for example, to convey information. Some systems use flow diagrams to display the state of electrical, pneumatic, and other subsystems, enabling operators to quickly identify a flow anomaly and recognize its impact on the system as a whole. 69 Equipment Although digital displays offer flexibility in presenting information, the relationship of display flexibility to operator performance has not been demonstrated consistently. Miller and Penningroth (1997) conclude that digital displays may not necessarily result in superior operator performance relative to analog displays. By contrast, Abbott (2000) believes that properly designed digital displays can enhance operators’ ability to interpret data. Trend Portrayal Because of the dynamism of many complex systems, operators need to quickly detect and interpret the direction and rate in which component parameters change, in order to understand their effects on system state. Nonetheless, understanding the state of the system at any one given moment, depending on the system, may not be as critical as recognizing how quickly a system state is changing and the direction of its change. Analog displays have traditionally presented direction information by the clockwise or counterclockwise movement of an indicator or pointer, and rate of change by the rapidity of that movement. These features are often seen in airplane disaster movies, for example, in which the rapidly unwinding altimeter—the instrument that depicts an aircraft’s altitude—conveys the seriousness of the situation. Some analog displays use vertical or horizontal “tapes” or lines to convey trend information. The lines move up or down or left or right to convey the direc- tion and rapidity of system changes. Digital displays do not necessarily present trend information better than do analog displays. A digital format that presents system parameters in Arabic numerals gives the operator precise parameter information. However, in the event of a rapid change, the numerals corresponding to the parameter would also change rapidly, and operators may not be able to quickly interpret the direction of change, that is, whether the parameters are increasing or decreasing. Yet, properly designed digital displays can present trend infor- mation in at least a comparable, if not superior way, to analog displays. These generally depict the nature and rate of the change pictorially to minimize operators’ time spent interpreting trend data, as in the illustration of the face to portray engine coolant temperature. Aural Information Visually presented information has one major drawback; operators must look at the information to receive it. If they are looking at displays of non- critical information, or engaged in other tasks and focusing elsewhere, they will not receive the information. Designers compensate for this shortcoming by adding aurally presented information to the presented information. 70 Because of the salience of aurally presented information—even inatten- tive operators receive the information—designers have usually relied on aurally presented information to rapidly communicate critical informa- tion to operators (e.g., Patterson, 1990; Edworth, Loxley, and Dennis, 1991). However, aurally presented information also has limitations in that the con- veyed information is less precise than visually presented information, and it can quickly distract operators and hinder their performance (e.g., Banbury, Macken, Tremblay, and Jones, 2001). The quality of aurally presented information is primarily influenced by a number of factors, • Conspicuity • Distractibility • Uniqueness • Accuracy • Relative importance Conspicuity To perceive aurally presented information operators must distinguish the critical sound from other sounds. Designers generally use of one of two methods to increase the conspicuity of critical sounds relative to those of other sounds, increasing volume or varying such sound elements as pitch, frequency, and rhythm. Patterson (1990) suggests increasing the volume of critical sounds by at least 15 dB over the volume of background noises to make them clearly audible. In environments in which the ambient sounds are fairly loud, this could make the aurally presented information quite loud, even approaching dangerous levels over extended periods. Distractibility Once aural information has been presented, continuing to present the sounds adds little additional information, and can distract operators and degrade their performance. The longer aural information continues to be presented and the more conspicuous the sound, the more likely the information will interfere with and degrade operator performance. On the other hand, Banbury et al. (2001) point out that after about 20 minutes of expo- sure the distracting effects of sounds are reduced. Unfortunately, exposure to interfering sounds for as long as 20 minutes can substantially degrade operators’ ability to respond effectively in that interval. Aurally presented information should cease to be presented after opera- tors have received and understood it. However, many systems cannot rec- ognize when this has been accomplished. Too often, aural information first informs and then distracts operators. Equipment Aural information can also distract and interfere with the work of opera- tors who were not targets of the initial information, especially in small operating environments such as locomotive cabs, ship bridges, or aircraft cockpits. Allowing operators to silence alerts might negate these disadvantages. However, as will be discussed shortly, systems that allow operators to silence alerts have other disadvantages. Accuracy Aurally presented information that is inaccurate or inconsistently useful will lose its value overtime, eventually failing to elicit operator attention. Yet, designers generally consider the consequences of missed alerts, where aural information is presented but operators do not respond, to be more critical to system safety than those of false alarms, where alerts are sounded but a response is unnecessary. As a result, designers tend to favor providing more rather than fewer alarms in a system to ensure that operators are informed of potentially important systems-related information. Further, designers set the threshold in these systems sufficiently low to ensure that critical events will elicit alerts, even if this results in noncritical events eliciting alerts as well. Unfortunately, doing so with sufficient fre- quency can expose operators to repeated false alarms, which has been found to reduce operator sensitivity to the alerts, and as Sorkin (1988) found, on occasion can even lead to outright operator silencing them altogether. In a January 1987 rail accident near Baltimore, Maryland, the locomo- tive engineer and brakeman, who were operating two freight locomo- tives, silenced an alarm they had considered distracting, a shrill whistle that sounded when the head locomotive passed a stop signal (National Transportation Safety Board, 1988). Neither operator noticed or responded to the stop signal, and the train consequently entered a track section that was reserved for an approaching, high-speed, passenger train. The passenger train then struck the freight locomotives, killing its engineer and 16 passen- gers. Investigators concluded that the aural alert would have informed the freight locomotive engineer and brakeman of their impending entry onto a prohibited track section. Investigators also found that the two operators had smoked marijuana before the accident and were impaired at the time. Uniqueness Designers create distinct sounds that are associated with different system elements, system states, or desired operator responses. Uniqueness characterizes the degree to which a sound is associated with specific system-related information. Operators learn to associate certain sounds with their corre- sponding system states so that when the sounds are heard the operators can quickly recognize their meaning, and will be unlikely to confuse the sounds with others. For example, emergency vehicles use distinctive sirens to alert 72 drivers in order to increase the likelihood that drivers will quickly recognize and respond to them. Aurally presented information can take a variety of forms. “Traditional” sounds such as bells, whistles, horns, and sirens are found on older equip- ment. Each sound can be readily distinguished from others and, if loud enough, could be heard over ambient sounds. As with visually presented information, modern digital equipment usually offers more flexibility in presenting aural information than does older equip- ment. Synthesized or recorded human voices that articulate simple voice messages can be used, in addition to traditional sounds (Stern, Mullennix, Dyson, and Wilson, 1999). Belz, Robinson, and Casali (1999) proposed using auditory icons, such as screeching tires, sounds that can be distinctly asso- ciated with particular system states, to enhance operator recognition and response to the sounds. Today, digital capabilities have expanded to the point that many automo- biles are equipped with navigation capabilities that can guide drivers to their destinations, taking traffic flow into account as well as proximity to other vehicles, whether they are in front, behind, and alongside. Drivers, if using vehicles not so equipped, can use their smartphones to provide navigation and other capabilities, with the ability as well to select from a number of voices, male and female, for example, with different accents or different lan- guages to direct them, so that the simple instructions, for example, “turn left in 70 meters,” can be quickly understood. As will also be discussed in Chapter 10, vehicles equipped with electronic devices, can, if needed, pro- vide accident investigators with useful information not only about selected routes, but also about braking, lane changing, and other data that can describe driver performance before an accident. Relative Importance A single event can precipitate multiple system warnings or alerts, each reflecting the state of a single system parameter rather than the event that led to the parameter state. In some systems, certain phenomena can elicit so many sounds and alarms from the effects of an event, rather than the precipi- tating event itself, that a cacophony of sounds is produced. When this occurs, the operator’s ability to effectively evaluate the individual alerts in order to understand the phenomenon that led to the alerts, rather than the effects of the phenomenon on the system, is made considerably more difficult. Some systems inhibit both visual and aural alerts, without operator action, during critical operating cycles. This reduces the likelihood that noncritical alerts would distract operators during critical tasks, as occurred in the crash of a Boeing 757 off the coast of Lima, Peru, in October 1996. Investigators found that pitot-static tubes, critical components that are necessary to mea- sure airspeed, climb and descent speeds, and altitude, were blocked by a maintenance error, which led to the speed and altitude displays presenting 73 Equipment erroneous information to the pilots (Accident Investigation Commission, 1996). After takeoff, numerous airspeed and altitude warnings and alerts, including low terrain, low airspeed, impending stall (the “stick shaker”), and wind shear, sounded. The alerts began within 5 seconds of each other and continued until impact. Each signaled a specific hazardous situation, but there was no alert that corresponded to the failure that had caused the multiple alerts—the blocked, and hence inoperative pitot-static system. The pilots were unable to determine the cause of the alerts. More important, operating at night and over water they could not visually estimate the air- plane’s airspeed and altitude. The alerts distracted the pilots, hindered their communications, and interfered with their ability to effectively diagnose the anomaly. Multiple warnings or alerts that sound simultaneously or in quick succes- sion often require the highest level of operator performance. Yet, they are often presented when operator workload tends to already be high because operators must, (1) continue to operate the system, (2) diagnose and respond to the anomaly, and (3) avoid causing additional damage. These tasks are challenging in combination, but when multiple alerts sound simultaneously during periods of high workload they can degrade performance. Some years later, an accident occurred that shared many of the characteris- tics of the 1996 Boeing 757 accident, an Airbus A-330 crashed into the Atlantic after the pitot tubes became blocked. Investigators attributed the blocked pitot-static tubes to ice crystals that formed after the airplane entered an area of adverse weather while the flight was at cruise altitude (Bureau d’Enquêtes et d’Analyses pour la sécurité de l’aviation civile, 2012). The initial aural alert that the crew received pertained to the autopilot’s disengagement, not to the blocked pitot tubes. This alert, which serves to inform the crew that manual airplane control is needed, is critical to ensure that pilots recognize that the autopilot is no longer operating, valuable information to help pilots recog- nize that they must address the alert and manually control the airplane. However, the underlying cause of the disengagement, the rapid alteration in measured airplane speed caused by the pitot-tube blockage, was not pre- sented. As a result, investigators noted that, Since the salience of the speed anomaly was very low compared to that of the autopilot disconnection, the crew detected a problem with this disconnection, and not with the airspeed indications. The crew reacted with the normal, learned reflex action, which was to take over manual control … (Bureau d’Enquêtes et d’Analyses pour la Sécurité de l’AviationCivile, 2012, p. 173) The pilots’ failure to recognize that the airspeed they were perceiving was inaccurate led to their failure to recognize the cause of the problem that they encountered and their subsequent mismanaging of airplane control. The airplane stalled and crashed into the ocean 4 minutes and 23 seconds later, killing all 228 passengers and crew onboard. Kinesthetic/Tactile Alerts Some have proposed presenting information through sensory modalities other than visual and aural ones to compensate for the limitations of presenting information in these modalities (e.g., Sklar and Sarter, 1999; Sarter, 2000). Transport airplane designers use both kinesthetic and aural cues to simultaneously alert pilots to a critical event, an aerodynamic stall. A stall requires immediate pilot action or the airplane may crash. Just before reaching the airspeed that would precede an aerodynamic stall, pilots hear a particular alert and feel a distinctive control column motion, sensations that are very difficult to ignore. However, as with aurally presented information, constant presentation of kinesthetically or tactually presented information can distract operators and degrade their performance. Controls Operators use controls to modify system state and system operation. Control design characteristics can influence operator performance and the likeli- hood of error, as can displays. Controls can take many shapes and forms, move in a number of directions, and be placed in a variety of locations. Automobiles, for example, employ at least three primary controls to enable drivers to direct their vehicles. The accelerator controls forward motion, the brake pedal slows or stops the vehicle, and the steering wheel controls lateral motion. Vehicles equipped with standard transmissions have two additional controls, a clutch and gearshift lever, for changing transmission gears as vehicle speed and engine rotation rates change. Other controls enable driv- ers to maintain selected speeds, and control windshield wiper speed and headlight brightness, sound the horn, and engage turn signals, for example. Further controls allow passengers and drivers to change window height, audio and video system characteristics, and vehicle interior temperature or ventilation levels. Investigators generally apply these criteria to assess the quality of control design, • Accessibility and location • Direction of movement and function • Shape • Placement • Standardization Equipment The quality of keyboard and touchscreen and other digital type controls, which are increasingly used in complex systems, is evaluated according to other criteria that will be addressed subsequently in this chapter. Accessibility and Location Accessibility, the ease with which operators can reach and manipulate desired controls, can influence the quality of operator performance. In systems with relatively unlimited space, in which time to manipulate controls is not critical, accessibility will not substantially influence operator performance. However, in systems with space limitations, designers need to shape and locate controls so that operators can readily access them, irrespective of the operators’ physical characteristics such as arm length. Well-designed systems have controls that operators can reach and manipulate without moving far from their stations. Inaccessible, hidden, or obscured controls can delay operator response when time is critical and thus serve as antecedents to error. Large church or concert organs illustrate well-designed controls. Organists adjust their access to the controls by moving their seats, and use both their hands and feet to operate the controls, the keys, and the pedals. Direction of Movement and Function The direction in which a control moves should intuitively correspond to the direction of change in the corresponding component. Raising a control should increase an aspect of the system such as production rate, component height, or illumination level, while lowering a control should reduce it. Depressing a button should engage a component function while releasing the depressed button should disengage it. Controls that move in directions that are counterintuitive can become antecedents to error if operators actuate the control incorrectly after using similar controls that move in a “standard” direction. Mode Errors Systems with limited available space, as well as advanced electronic controls, often employ multifunction controls in which one device controls multiple system functions. Operators who are unfamiliar with or do not perceive the distinction among the various control functions may initiate a control action and an unanticipated system response, what has become known as a mode error (Norman, 1988). Multifunction controls can be designed to reduce opportunities for mode errors by giving operators unambiguous information or feedback regard- ing the system’s operating mode. The quality of the feedback is affected by 76 the same visual, aural, and kinesthetic factors discussed previously. Visually presented feedback should be sufficiently conspicuous to enable operators to receive the information. Aurally presented information is likely to be the least confusing, but operators will tend to ignore aural information if ­ presented repeatedly. Investigators concluded that the pilots of an Airbus A-320 that crashed short of the runway at Mont St. Odile, France, in 1992, committed a mode error while preparing to land (Commission of Investigation, 1993). A single control, a knob that turned clockwise or counterclockwise to increase or decrease the rate of change in the desired mode, also controlled both the airplane’s descent rate and its flight path angle. Pilots selected the mode by either depressing or pulling the knob and then turning it to establish the desired descent rate or descent angle. Incorrectly controlling the knob engaged the mode other than the one intended. Investigators concluded that the pilots had inadvertently selected the wrong mode, and established a descent rate that was triple the typical rate, believing that they had commanded a moderate descent angle. Because of the dual purpose of the control knob, and ambiguity in the information pre- sented regarding the descent rate that they had engaged, the pilots were not aware of their error and then failed to notice the rapid descent to the ground. Shape Controls can take a number of forms, designs, and shapes, such as knobs, buttons, wheels, switches, levers, or pedals. Designers may shape a control to resemble a distinctive task or function. In some systems, regulators have mandated specific design characteristics. For example, the lever that extends or retracts airplane landing gear is required to be circular to reduce the pos- sibility of confusion with an adjacent control. By shaping the lever to cor- respond to the shape of the controlled component, the aircraft wheels, pilots can recognize the control by touch alone, minimizing the possibility of con- trol confusion. Control shape can play an important role in operator performance. In high workload or stressful situations, operators may not have the time to visually identify a control before manipulating it. Rather, they may locate and select controls by touch alone, without visual verification. In these circumstances, operators may find similarly shaped controls to be undistinguishable, and select the wrong control. Placement Controls that actuate different subsystems or have different functions (e.g., go fast and go slow), should not be placed near each other, and if so, should be shaped differently so that in the event that operators must engage them quickly, they can identify them without having to visually verify that they have actuated the desired control to initiate the control operation desired. The effects of placing identically designed controls, with differing actuation results, adjacent to each other can be seen in the investigation of a marine accident (National Transportation Safety Board, 2011). In this accident, which was caused by a marine pilot’s late recognition of the need for a turn (influenced by his fatigue), the vessel he was piloting first collided into a vessel traveling in the opposite direction as his vessel, and then collided with a second, docked vessel. Just before the accident, the captain, seeing the impending collision, attempted to rapidly slow the ves- sel by actuating a control, a button that caused the engine to quickly slow. However, the button actuating that control was located adjacent to an iden- tical button that caused the engine to do the opposite of what the captain intended, speed up rapidly, the button that the captain actually depressed. Although investigators determined that at the time the captain actuated the control the accident could not be avoided, investigators faulted a design that was counter to the standards of good design (Figure 4.2). Standardization Operators have come to expect a certain configuration, shape, and direction of movement in the controls that they manipulate. Unfortunately, unless regulators establish rules governing the design of both displays and controls, designers may create designs that suit their own rather than the operators’ needs. This can lead to differences in the shape of similar controls on comparable equipment. Those who have driven cars at night that are different from their own, and had difficulty locating and engaging the windshield wipers or headlights because the controls were located in unexpected places, have witnessed the errors these control differences can create. So long as operators interact with only one type of equipment, nonstandard control shapes, locations, and directions of movement will not cre- ate antecedents to errors. However, operators interacting with comparable equipment that have different controls and displays could, out of habit, move a control incorrectly or direct the wrong control when alternating between equipment types. If operators repeatedly reach one location to access a con- trol, or move it in a certain direction to accomplish an action, they will likely continue these movements on different equipment, even if the movements produce unintended consequences. Some years ago, the National Transportation Safety Board found that the rate at which pilots failed to extend the landing gear before landing was higher among pilots of aircraft that had been designed and built by one manufacturer than with pilots of comparable aircraft of other manufacturers (National Transportation Safety Board, 1980). The national transportation safety board attributed this difference to the location of the landing gear and flap controls. Controls in the cockpits of the airplanes with the higher gear up accident rates were located in different locations than were controls on most other aircraft. Investigators concluded that pilots who had operated other aircraft would inadvertently reach for and select the “wrong” controls occasionally, actions that would have been appropriate on those aircraft. Unfortunately, there is no short-term solution for a lack of standardized controls and displays. Designers could reduce the role of this antecedent to error by adhering to a common control and display design standard. However, a transition period would be needed to implement a standard to prevent operators from being confused by what may be a new design. Equipment already in service will likely continue to remain in service until it is no longer economically feasible to do so. In order to standardize comparable controls and displays, the time needed to introduce new or rede- signed equipment into complex systems and to train operators to use the new designs may be considerable. Unless regulators require standardizing the controls and displays in the systems they oversee, standardization will be unlikely. Keyboard Controls In older systems, operators often needed to exert considerable physical force to manipulate controls. Today, however, systems use keyboard con- trols, either with the familiar QWERTY format derived from the typewriter keyboard, a variant, or graphic interfaces on screens to actuate system controls. Operators using keyboard controls are physically able to control the system without error, so long as they don’t inadvertently strike the wrong key. Without effective feedback from the system, operators may incorrectly 79 Equipment believe that they have actuated the correct keyboard controls even if they have not. Highly automated systems largely rely on keyboards with well- separated keys that minimize slips when operators manipulate them by touch alone, and place the keyboards in a location that minimizes fatigue over extended use. In addition, in contemporary systems graphic user interfaces and touch screens have increasingly been implemented as system controls. These are less likely to lead to inadvertent operator errors than are keyboards, as operators must visually determine the selections they make through a display on the screen. Other characteristics of automated systems and their effects on operator performance are discussed in more detail in Chapter 15. Summary The manner of presenting system-related information to operators can affect their understanding of the system state. Information that involves a high degree of precision is generally presented visually. The number of displays, their conspicuity, organization, and portrayal of trends in system performance influences operators’ ability to obtain and interpret system information. Information that is difficult to access and interpret can lead to misinterpretations and errors. Information that requires immediate attention, independent of opera- tors’ focus, is generally presented aurally. Volume, precision, and conspicuous- ity influence how well operators receive and comprehend the information. Continued presentation of aural information can distract and interfere with an operator’s ability to concentrate, perform other tasks, and perceive other aurally presented information. Sounds should be distinctive and associated with system states or required operator actions to continue to be meaningful. Sounds that are inconsistently associated with system information or operator response will lose their meaning over time. The design of controls that operators use to alter or modify system operations can affect their performance. Controls should be readily accessible and move in the direction that corresponds to the direction of change in the associated system parameter. Control shapes should be readily ­ distinguishable from one another, particularly if adjacent. Controls with different functions should be shaped differently, and placed away from each other to reduce the likelihood of operators inadvertently ­ actuating the wrong controls. Over the long term, standardization of control and display features will reduce the potential for confusion and errors among operators who work on comparable, but nonstandardized equipment. DOCUMENTING EQUIPMENT • Photograph, video record, or otherwise capture a record of displays and controls in the operating environment of the equipment involved in the event. If this is not possible, refer to equipment handbooks for operating station diagrams, as necessary. • Use comparable systems or a system simulator, noting differences between the two, if the equipment was excessively ­ damaged as a result of the event. • Interview designers to obtain information about the philosophy that guided the display and control design. • Interview designers, instructors, and operators, and refer to operating manuals, to obtain information on differences between designers’ and instructors’ intentions and operator practices. • Refer to ergonomics handbooks for guidance, if necessary, when evaluating display or control design features (e.g., Sanders and McCormick, 1993; Ivergard, 1999). DISPLAYS • Document the number of displays and their locations, and note the displays that operators use to understand the event, ­ compared to the total number of displays presented nearby. • Note how closely the logic of the organization corresponds to the way operators access displays or their associated controls. • Contrast the color, brightness, and data size in the display to comparable features in adjacent displays to determine display conspicuity. • Identify display colors, pictures, diagrams, design, or other features that affect data interpretability and if necessary, refer to operating manuals and handbooks to understand the meaning and relevance of the displayed data. • Determine the portrayal of direction and rate of changes in parameter trend information. AURALLY PRESENTED INFORMATION • Measure sound volume, duration after initial presentation, ­ volume of ambient sounds, and changes in features of the sounds of interest with changes in component status. • Document features of aurally presented information among sound elements such as volume, pitch, frequency, and rhythm.