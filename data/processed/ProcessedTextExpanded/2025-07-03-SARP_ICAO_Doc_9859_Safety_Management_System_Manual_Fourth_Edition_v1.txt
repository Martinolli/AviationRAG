Title: international civil aviation organization Doc 9859, Safety Management System Manual, Fourth Edition Author(s) International Civil Aviation Organization Category: Standard and Recommended Practice Tags: Safety, Manual, System, ICAO, Management GLOSSARY DEFINITIONS When the following terms are used in the manual, they have the meanings indicated below. Note.— Where an asterisk appears beside a term, the term has already been defined as such in Annexes and Procedures for Air Navigation Services (PANS). Acceptable level of safety performance (ALoSP). The level of safety performance agreed by State authorities to be achieved for the civil aviation system in a State, as defined in its State safety programme, expressed in terms of safety performance targets and safety performance indicators. Accountable executive. A single, identifiable person having responsibility for the effective and efficient performance of the service provider’s SMS. Change management. A formal process to manage changes within an organization in a systematic manner, so that changes which may impact identified hazards and risk mitigation strategies are accounted for, before the implementation of such changes. Defences. Specific mitigating actions, preventive controls or recovery measures put in place to prevent the realization of a hazard or its escalation into an undesirable consequence. Errors. An action or inaction by an operational person that leads to deviations from organizational, or the operational person’s, intentions or expectations. *Hazard. A condition or an object with the potential to cause or contribute to an aircraft incident or accident. Risk mitigation. The process of incorporating defences, preventive controls or recovery measures to lower the severity and/or likelihood of a hazard’s projected consequence. Safety. The state in which risks associated with aviation activities, related to, or in direct support of the operation of aircraft, are reduced and controlled to an acceptable level. *Safety data. A defined set of facts or set of safety values collected from various aviation-related sources, which is used to maintain or improve safety. Note.— Such safety data is collected from proactive or reactive safety-related activities, including but not limited to: a) accident or incident investigations; b) safety reporting; c) continuing airworthiness reporting; d) operational performance monitoring; e) inspections, audits, surveys; or f) safety studies and reviews. *Safety information. Safety data processed, organized or analysed in a given context so as to make it useful for safety management purposes. *Safety management system (SMS). A systematic approach to managing safety, including the necessary organizational structures, accountability, responsibilities, policies and procedures. Safety objective. A brief, high-level statement of safety achievement or desired outcome to be accomplished by the State safety programme or service provider’s safety management system. Note.— Safety objectives are developed from the organization’s top safety risks and should be taken into consideration during subsequent development of safety performance indicators and targets. *Safety oversight. A function performed by a State to ensure that individuals and organizations performing an aviation activity comply with safety-related national laws and regulations. *Safety performance. A State’s or service provider´s safety achievement as defined by its safety performance targets and safety performance indicators. *Safety performance indicator. A data-based parameter used for monitoring and assessing safety performance. *Safety performance target. The State or service provider’s planned or intended target for a safety performance indicator over a given period that aligns with the safety objectives. *Safety risk. The predicted probability and severity of the consequences or outcomes of a hazard. *State safety programme (SSP). An integrated set of regulations and activities aimed at improving safety. *Surveillance. The State activities through which the State proactively verifies through inspections and audits that aviation licence, certificate, authorization or approval holders continue to meet the established requirements and function at the level of competency and safety required by the State. System. An organized, purposeful structure that consists of interrelated and interdependent elements and components, and related policies, procedures and practices created to carry out a specific activity or solve a problem. Trigger. An established level or criteria value for a particular safety performance indicator that serves to initiate an action required, (e.g., an evaluation, adjustment or remedial action). ABBREVIATIONS AND ACRONYMS ADREP Accident/incident data reporting AIA Accident investigation authority ALoSP Acceptable level of safety performance air operator certificate Air operator certificate ATS Air traffic service(s) civil aviation authority Civil aviation authority cockpit voice recorder Cockpit voice recorder D3M Data-driven decision-making Doc Document ERP Emergency response plan FDA Flight data analysis flight data recorder Flight data recorder flight management system Financial management system FRMS Fatigue risk management systems GASP Global Aviation Safety Plan international civil aviation organization International Civil Aviation Organization iSTARS Integrated Safety Trend Analysis and Reporting System LOSA Line operations safety audit OHSMS Occupational health and safety management system OSHE Occupational safety, health and environment PIRG Planning and implementation regional group quality management system Quality management system RASG Regional aviation safety group RSOO Regional safety oversight organization SAG Safety action group standard and recommended practices Standards and Recommended Practices SD Standard deviation SDCPS Safety data collection and processing system SeMS Security management system SMM Safety management manual SMP Safety Management Panel safety management system Safety management system(s) SPI Safety performance indicator SPT Safety performance target SRB Safety review board SRBS Safety risk-based surveillance safety risk management Safety risk management SSO State safety oversight state safety program State safety programme STDEVP Population standard deviation TNA Training needs analysis universal safety oversight program Universal Safety Oversight Audit Programme PUBLICATIONS (referred to in this manual) The following documents are referred to in this manual or may provide additional guidance material. international civil aviation organization DOCUMENTS Annexes to the Convention on International Civil Aviation Annex 1 — Personnel Licensing Annex 6 — Operation of Aircraft Part I — International Commercial Air Transport — Aeroplanes Part II — International General Aviation — Aeroplanes Annex 8 — Airworthiness of Aircraft Annex 13 — Aircraft Accident and Incident Investigation Annex 14 — Aerodromes Volume I — Aerodrome Design and Operations Annex 18 — The Safe Transport of Dangerous Goods by Air Annex 19 — Safety Management PANS Procedures for Air Navigation Services (PANS) — Aerodromes (Doc 9981) Procedures for Air Navigation Services — Air Traffic Management (PANS-ATM, Doc 4444) Manuals Airport Services Manual (Doc 9137), Part 3 — Wildlife Control and Reduction Air Traffic Services Planning Manual (Doc 9426) Airworthiness Manual (Doc 9760) Aviation Security Manual (Doc 8973 — Restricted) Global Aviation Safety Plan (GASP) (Doc 10004) Manual of Aircraft Accident and Incident Investigation (Doc 9756) Part I — Organization and Planning Part II — Procedures and Checklists Part III — Investigation Part IV — Reporting Manual for the Oversight of Fatigue Management Approaches (Doc 9966) Manual on Laser Emitters and Flight Safety (Doc 9815) Manual on Remotely Piloted Aircraft Systems (RPAS) (Doc 10019) Manual on the Competencies of Civil Aviation Safety Inspectors (Doc 10070) Manual on the international civil aviation organization Bird Strike Information System (IBIS) (Doc 9332) Manual on Protection of Safety Information (Doc 10053) Part I — Protection of Accident and Incident Investigation Records Safety Oversight Manual (Doc 9734) Part A — The Establishment and Management of a State Safety Oversight System Part B — The Establishment and Management of a Regional Safety Oversight Organization Technical Instructions for the Safe Transport of Dangerous Goods by Air (Doc 9284) Chapter 1 INTRODUCTION 1.1 WHAT IS SAFETY MANAGEMENT? 1.1.1 Safety management seeks to proactively mitigate safety risks before they result in aviation accidents and incidents. Through the implementation of safety management, States can manage their safety activities in a more disciplined, integrative and focused manner. Possessing a clear understanding of its role and contribution to safe operations enables a State, and its aviation industry, to prioritize actions to address safety risks and more effectively manage its resources for the optimal benefit of aviation safety. 1.1.2 The effectiveness of a State’s safety management activities is strengthened when implemented in a formal and institutionalized way through a State safety programme (SSP) and through safety management systems (SMSs) for its service providers. A State’s safety programme, combined with the SMSs of its service providers, systematically addresses safety risks, improves the safety performance of each service provider, and collectively, improves the State’s safety performance. 1.1.3 The state safety program is developed and maintained by each State as a structured approach to assist in managing its aviation safety performance. The existing aviation safety record is achieved through a traditional compliance-based approach and should continue to be treated as the foundation of the SSP. As such, States should ensure they have effective safety oversight systems in place. More information on the state safety program may be found in Chapter 8. 1.1.4 A State shall require that an safety management system is developed and maintained by those service providers under its authority, as identified in Annex 19 — Safety Management, to continuously improve safety performance by identifying hazards, collecting and analysing data, and continuously assessing and managing safety risks (see paragraph 1.2 for details on safety management system applicability). More information on the implementation of safety management system may be found in Chapter 9. 1.1.5 The international civil aviation organization Global Aviation Safety Plan (GASP, Doc 10004) objectives call for States to put in place robust and sustainable safety oversight systems and to progressively evolve these into a more sophisticated means of managing safety performance. These objectives align with ICAO’s requirements for the implementation of SSPs by States and SMSs by service providers. 1.1.6 This performance-based approach to safety offers improvements as it focuses on achieving the desired outcome rather than concentrating solely on whether a State is compliant or not. It is important to note, however, that the implementation of a safety performance approach is collaborative as it requires effort on the part of the aviation industry to develop appropriate means to achieve the specified outcomes and, with respect to States, to evaluate each service provider’s approach. 1.1.7 BENEFITS OF SAFETY MANAGEMENT There are many benefits to implementing safety management, some of which include: a) Strengthened safety culture – An organization’s safety culture can be strengthened by making visible the commitment of management and actively involving personnel in the management of safety risk. When management actively endorses safety as a priority, it is typically well-received by personnel and becomes part of normal operations. b) Documented, process-based approach to assure safety – Establishes a clear and documented approach to achieving safe operations that is understandable by personnel and can be readily explained to others. In addition, clearly defining baseline performance allows controlled changes when continuously improving the safety programme/system, thereby helping the organization optimize resources required to implement change. c) Better understanding of safety-related interfaces and relationships – The process of documenting and defining safety management interfaces can benefit the organization’s understanding of the interprocess relationships, leading to an enhanced understanding of the end-to-end process and exposing opportunities for increased efficiencies. d) Enhanced early detection of safety hazards – Improves the State/service provider's ability to detect emerging safety issues, which can prevent accidents and incidents through the proactive identification of hazards and management of safety risks. e) Safety data-driven decision-making – Improves the State/service provider's ability to gather safety data for the purpose of safety analysis. With some strategic thinking to determine what questions need to be answered, the resulting safety information can airport information desk decision makers, in near real-time, to make better-informed, valid decisions. An important aspect of this decision-making is the allocation of resources to areas of greater concern or need. f) Enhanced communication of safety – Provides a common safety language throughout an organization and industry. A common safety language is a key enabler to the development of a common understanding of the organization’s safety goals and accomplishments. In particular, it provides an appreciation for the organization's safety objectives and its safety performance indicators (SPIs) and safety performance targets (SPTs), which provide the direction and motivation for safety. Personnel will be more aware of the organization’s performance and the progress being made toward achieving the defined safety objectives, as well as how they contribute to the organization’s success. The common safety language enables service providers with multiple aviation businesses to aggregate safety information across organizational entities. It is necessary to support the management of interfaces across the aviation system. g) Evidence that safety is a priority – Demonstrates how management supports and enables safety, how safety risks are identified and managed, and how safety performance is continually improved, resulting in increased confidence by the aviation community, internal and external to the organization. This also results in personnel who are confident about the organization’s safety performance, which can lead to the increased attraction and retention of high calibre staff. It also allows for States and regional safety oversight organizations (RSOOs) to develop confidence in the safety performance of service providers. h) Possible financial savings – May allow for some service providers to qualify for a discount on their insurance premiums and/or a reduction to their workers’ compensation premiums based on their safety management system results. i) Improved efficiencies – Possible reduction in the cost of operations by exposing inefficiencies in existing processes and systems. Integration with other internal or external management systems may also save on additional costs. j) Cost avoidance – Through the proactive identification of hazards and safety risk management (SRM), the cost incurred due to accidents and incidents can be avoided. In such cases, direct costs may include: injuries; property damage; equipment repairs; and schedule delays. Indirect costs may include: legal action; loss of business and damaged reputation; surplus spares; tools and training; increased insurance premiums; loss of staff productivity; equipment recovery and clean-up; loss of use of equipment leading to short-term replacement equipment; and internal investigations. 1.2 SAFETY MANAGEMENT APPLICABILITY State safety management responsibilities are outlined in Annex 19, Chapter 3, and include requiring service providers identified in the standard and recommended practices to implement SMS. Provisions related to the implementation of SMSs by service providers may be found in Chapter 4 and Appendix 2 of Annex 19. 1.2.1 safety management system applicability 1.2.1.1 The assessment to determine the applicability of safety management system for Amendment 1 to Annex 19 was based on a set of criteria. These same criteria are expected to be used periodically by international civil aviation organization and the Safety Management Panel (SMP) to reassess the need to extend the applicability to other aviation organizations. Total system safety approach 1.2.1.2 A total system safety approach considers the entire aviation industry as a system. All service providers, and their systems for the management of safety, are considered as sub-systems. This allows a State to consider the interactions, and cause and effect, throughout the whole system. It is often impossible or impractical to build all safety systems in the same way. Therefore, a primary concern for States and service providers is how to best manage the interfaces between dissimilar interacting systems. 1.2.1.3 When reviewing safety management system applicability, the link between service providers who already have an safety management system requirement under Annex 19 and other organizations conducting an aviation activity was considered. Application of safety management system should reduce the risk of safety gaps or overlaps, not increase safety risk through decreased interoperability. Subcontracting implications 1.2.1.4 For safety risk management to be effective across service providers it is important to clearly define the responsibilities for the identification of hazards and management of associated safety risks for the entire chain of services within the system, without gaps or overlaps. Where a service provider with an safety management system requirement contracts to an organization not subject to SMS, the hazards and safety risks potentially introduced by the contractor are addressed by the safety management system of the service provider. This places additional safety risk management responsibilities on the service provider to ensure they are knowledgeable about the safety risks induced by the activities of their contractor(s). For more information on SRM, see Chapter 2. Safety risk control through regulations 1.2.1.5 States should assess whether the existing legislation and regulations effectively address the hazards entailed by the activity. It could be that existing requirements provide sufficient safety risk mitigation and imposing a requirement for safety management system for those organizations not applicable under Annex 19 may not yield substantial safety benefit. 1.2.2 Extension of discretionary safety management system applicability 1.2.2.1 The applicability criteria outlined above may also serve as guidance for States when considering an extension of safety management system applicability beyond that defined in Annex 19 or the promotion of voluntary implementation. Application of discretionary safety management system applicability should be thoughtfully considered. The decision to extend the safety management system applicability to sectors or service providers should take into account the safety risks identified in the State and if the decision is taken, the safety management system implementation should be monitored as part of the SSP. Before requiring SMS, States are asked to consider whether: a) there are any other viable options for achieving the desired improvement in safety performance; and b) sufficient resources are available for the State and industry sector to implement and monitor the SMS. In particular, consideration needs to be given to the possible impact on staffing and the potential challenge of acquiring and integrating the necessary skills and knowledge. 1.2.2.2 Each State should consider the acceptable level of safety performance (ALoSP) across their industry and institute an safety management system applicability scheme that is most likely to achieve their State’s safety objectives. The safety management system applicability scheme applied will likely evolve in continual alignment with the State’s ALoSP. 1.2.3 Safety management responsibility No provision of Annex 19 is intended to transfer to the State the responsibilities of the aviation service provider or operator. States possess many tools to manage safety within their system. As part of its SSP, each State should consider the best options for the oversight of aviation activities that may not fall within current international civil aviation organization Annexes or that of new or emerging activities. 1.2.4 Applicability for State-owned or military service providers 1.2.4.1 In some States, the service provider function is provided by the State civil service or military. Some civilian service providers provide contracted services to the military, and some military organizations provide civilian service. Regardless of the arrangement, the service provider for the civilian service in the State should be required to address all the applicable international civil aviation organization SARPs, including the Annex 19 safety management system requirements without regard to the specific nature of such organization. The State’s or service provider’s system description should have regard for the functions of these organizations and their relationship to each other. The accountable executive of the service provider, whether civil or military, should be capable of explaining the arrangements and how safety risks are managed. Put simply, service providers should manage safety regardless of the organizational arrangements. 1.2.4.2 Where the State operates as a service provider there should be a clear separation between its functions as the service provider and that of the State regulatory authority. This is accomplished by having clearly defined roles and responsibilities for State authority and service provider personnel to avoid any conflicts of interest. 1.2.5 Occupational safety, health and environment versus aviation safety Occupational safety, health and environment (OSHE) (also referred as occupational health and safety (OHS) or workplace health and safety (WHS)) is a field concerned with the safety, health, and welfare of people at work. The primary difference between aviation safety management and OSHE systems is the intent. In many States employers have a legal duty to take reasonable care of the health and safety of their employees. The intention of OSHE programmes is to meet the legal and ethical obligations of employers by fostering a safe and healthy work environment. These issues are normally addressed under a different government body from the one that handles aviation matters. As such, Annex 19, Chapter 2, Applicability, intentionally focuses on “safety management functions related to, or in direct support of, the safe operation of aircraft”. 1.3 IMPLEMENTING SAFETY MANAGEMENT 1.3.1 Establishing a solid foundation is essential to achieving effective safety management implementation. The following aspects should be addressed as the first steps in implementing state safety program or safety management system requirements: a) Senior management commitment: It is essential that senior management of all State aviation agencies is committed to effective safety management implementation. b) Compliance with prescriptive requirements: The State should ensure that a mature safety oversight system is in place for the licensing, certification, authorization and approval of individuals and organizations performing aviation activities in their State, including qualified technical personnel. Service providers should ensure that they have processes in place to ensure continued compliance with the established prescriptive requirements. c) Enforcement regime: The State should establish an enforcement policy and frameworks to enable parties to manage and resolve deviations and minor violations. d) Safety information protection: It is essential that States put in place a protective legal framework to ensure the continued availability of safety data and safety information. 1.3.2 System description The system description is a summary of the organization’s (State or service provider) processes, activities and interfaces that need to be assessed for hazard identification and safety risk assessment that is covered by their safety system. It describes the aviation system, within which the organization functions, and the various entities and authorities involved. It includes interfaces within the organization, as well as interfaces with external organizations that contribute to the safe delivery of services. The system description provides a starting point to implement the SSP/SMS. More information on the system description for States and service providers may be found in Chapters 8 and 9, respectively. 1.3.3 Interfaces 1.3.3.1 When States and service providers are considering implementing safety management it is important to consider the safety risks induced by interfacing entities. Interfaces can be internal (e.g. between operations and maintenance, or finance, human resources or legal departments), or they can be external (e.g. other State, service providers or contracted services). States and service providers have greater control over any related safety risks when interfaces are identified and managed. Interfaces are defined as part of the system description. Interface safety impact assessment 1.3.3.2 Once a State or service provider has identified its interfaces, the safety risk posed by each interface is assessed using the organization’s existing safety risk assessment processes (see Chapter 2 for details). Based on the safety risks identified, the State or service provider may consider working with other organizations to determine an appropriate safety risk control strategy. Organizations working collaboratively may be able to identify more interface hazards; assessing any related safety risks and determining mutually appropriate controls. Collaboration is highly desirable because the safety risk perception may vary between organizations. 1.3.3.3 It is also important to recognize that each organization involved is responsible for identifying and managing any identified hazards that affect its organization. The criticality of the interface may differ for each organization. Each organization might reasonably apply different safety risk classifications and have different safety risk priorities (in terms of safety performance, resources, time). Monitoring and management of interfaces 1.3.3.4 States and service providers are responsible for ongoing monitoring and management of their interfaces to ensure the safe provision of services. An effective approach to interface safety risk management is to establish formal agreements between interfacing organizations with clearly defined monitoring and management responsibilities. Documenting and sharing all interface safety issues, safety reports and lessons learned, as well as safety risks between interfacing organizations will ensure clear understanding. Sharing enables transfer of knowledge and working practices that could improve the safety effectiveness of each organization. 1.3.4 Implementation planning 1.3.4.1 Performing a gap analysis before embarking on the implementation of SSP/SMS will allow an organization to identify the gap between the current organizational structures and processes, and those required for effective state safety program or safety management system operation. For SSP, it is important to include a review of the Universal Safety Oversight Audit Programme (USOAP) protocol questions which are considered as the foundation of the SSP. 1.3.4.2 The state safety program or safety management system implementation plan is, as the name implies, a plan for SSP/SMS implementation. It provides a clear description of the resources, tasks and processes required, and an indicative timing and sequencing of key tasks and responsibilities. More information on the implementation of safety management for States and service providers may be found in Chapters 8 and 9, respectively. Maturity assessment 1.3.4.3 Soon after the key components and elements of the state safety program or safety management system are implemented, periodic assessments should be conducted to monitor how effectively it is working. As the system matures, the organization should seek assurance that it is operating as intended and is effective at achieving its stated safety objectives and targets. Safety management takes time to mature and the aim should be to maintain or continuously improve the safety performance of the organization. 1.3.5 Size and complexity considerations 1.3.5.1 Each State and each service provider is different. SSPs and SMSs are designed to be tailored to meet the specific needs of each State or service provider. All components and all elements of SSP/SMS are interconnected and interdependent, and necessary to function effectively. It is important that state safety program and safety management system requirements are not implemented only in a prescriptive manner. The traditional prescriptive requirements are to be complemented with a performance-based approach. 1.3.5.2 The programme/system is designed to deliver the desired outcomes for each organization without undue burden. state safety program and SMS, well implemented, are intended to complement and enhance the organization’s existing systems and processes. Effective safety management will be achieved through thoughtful planning and implementation, ensuring each requirement is addressed in ways that fit the organization’s culture and operating environment. More information on what to consider when implementing SSP/SMS for States and service providers may be found in Chapters 8 and 9, respectively. 1.3.6 Integrating the basic elements It is important to note that all systems are composed of three basic elements: people; processes; and technology. Safety management is no exception. When establishing or maintaining the different processes, activities and functions, all States and service providers should ensure they have considered the intention of each requirement and, most importantly, how they will work together to enable the organization to meet its safety objectives. Each of these elements of safety management, and the interrelationships, will be covered throughout this manual. 1.4 INTEGRATED RISK MANAGEMENT 1.4.1 The aviation system as a whole comprises many and different functional systems such as finance, environment, safety and security. The latter two are the primary operational domains of the greater aviation system. As concepts they share important features as they are all concerned with the risk of events with consequence of various magnitudes. Nevertheless, they differ in the important element of intent. Security is concerned with malicious, intentional acts to disrupt the performance of a system. Safety focuses on the negative impact to the concerned systems’ performance caused by unintended consequences of a combination of factors. 1.4.2 In the operational context, all of the functional systems produce some sort of risk that needs to be appropriately managed to lessen any adverse consequence. Traditionally, each system has developed sector specific risk management frameworks and practices designed to address the distinct characteristics of each system. Most of those risk management practices include comprehensive analysis on intra-system consequences, often referred to as the management of unintended consequences. Another aspect is inter-system consequences resulting from system specific risk management processes. This relates to the fact that an effective risk management strategy of one specific sector can have an adverse impact on another operational sector of aviation. In aviation, the most often emphasized inter-system dependence is the safety/security dilemma. Effective security measures may have negative impacts on safety, and vice versa. Safety and security domains may differ in the element of underlying intent, but they converge in their common goal to protect people and assets (e.g. addressing cyber threats and risks requires coordination across the aviation safety and security domains). In some cases the management of the inherent risk of one may affect the other domain in unforeseen ways, such as in the following examples: a) reinforced cockpit doors necessitated due to security risks may have safety implications on the operation of an aircraft; b) restrictions on the carriage of personal electronic devices in the cabin may displace the security risk from the cabin to the cargo hold, leading to heightened safety risk; and c) change of routes to avoid flying over conflict zones may result in congested air corridors that pose a safety issue. 1.4.3 Successful risk management in aviation should aim for overall risk reduction in the system, including all of the involved functional systems. This process requires the analytical assessment of the whole system at the highest level of the appropriate entity (State, regional organizations, service providers). The assessment and integration of functional system needs and interdependence are referred to as integrated risk management (IRM). IRM focuses on the overall risk reduction of the organization. This is achieved through the quantitative and qualitative analysis of both the inherent risks, and the effectiveness and impact of sector-specific risk management processes. IRM has a system-wide responsibility to coordinate, harmonize and optimize risk management processes with the single goal of risk reduction. IRM cannot replace the operating specific risk managements of the functional systems, and does not intend to delegate additional duties and responsibilities to them. IRM is a distinct high-level concept to leverage the expert advice of sectorspecific risk management and provide holistic feedback to achieve the highest level of system performance at a socially acceptable level. More information related to safety risk management, which is within the scope of this manual, may be found in Chapters 2, 8 (for States) and 9 (for service providers). Note.— The structure and areas of responsibility of the government within the State may affect oversight of each area. For example, the civil aviation authority (CAA) having responsibility for aviation safety, while the environmental protection agency has responsibility for environmental oversight. Each oversight entity may have different requirements and methodologies. Chapter 2 SAFETY MANAGEMENT FUNDAMENTALS 2.1 THE CONCEPT OF SAFETY AND ITS EVOLUTION 2.1.1 This chapter provides an overview of fundamental safety management concepts and practices. It is important to understand these fundamentals before focusing on the specifics of safety management found in the subsequent chapters. 2.1.2 Within the context of aviation, safety is “the state in which risks associated with aviation activities, related to, or in direct support of the operation of aircraft, are reduced and controlled to an acceptable level”. 2.1.3 Aviation safety is dynamic. New safety hazards and risks continuously emerge and must be mitigated. As long as safety risks are kept under an appropriate level of control, a system as open and dynamic as aviation can still be kept safe. It is important to note that acceptable safety performance is often defined and influenced by domestic and international norms and culture. 2.1.4 Progress in aviation safety can be described by four approaches, which roughly align with eras of activity. The approaches are listed below and are illustrated in Figure 2-1. a) Technical — From the early 1900s until the late 1960s, aviation emerged as a form of mass transportation in which identified safety deficiencies were initially related to technical factors and technological failures. The focus of safety endeavours was therefore placed on the investigation and improvement of technical factors (the aircraft, for example). By the 1950s, technological improvements led to a gradual decline in the frequency of accidents, and safety processes were broadened to encompass regulatory compliance and oversight. b) Human factors — By the early 1970s, the frequency of aviation accidents had significantly declined due to major technological advances and enhancements to safety regulations. Aviation became a safer mode of transportation, and the focus of safety endeavours was extended to include human factors, including such things as the “man/machine interface”. Despite the investment of resources in error mitigation, human factors continue to be cited as a recurring factor in accidents. Human factors tended to focus on the individual, without fully considering the operational and organizational context. It was not until the early 1990s that it was acknowledged that individuals operate in a complex environment that included multiple factors which could affect behaviour. c) Organizational — During the mid-1990s, safety began to be viewed from a systemic perspective and began encompassing organizational factors as well as human and technical factors. The notion of an “organizational accident” was introduced. This perspective considered the impact of such things as organizational culture and policies on the effectiveness of safety risk controls. Additionally, routine safety data collection and analysis using reactive and proactive methodologies enabled organizations to monitor known safety risks and detect emerging safety trends. These enhancements provided the learning and foundation which lead to the current safety management approach. d) Total system — From the beginning of the 21st century, many States and service providers had embraced the safety approaches of the past and evolved to a higher level of safety maturity. They have begun implementing state safety program or SMSs and are reaping the safety benefits. However, safety systems to date have focused largely on individual safety performance and local control, with minimal regard for the wider context of the total aviation system. This has led to growing recognition of the complexity of the aviation system and the different organizations that all play a part in aviation safety. There are many examples of accidents and incidents showing that the interfaces between organizations have contributed to negative outcomes. 2.1.5 The steady, compounding evolution of safety has led States and service providers to a point where they are giving serious consideration to the interactions and interfaces between the components of the system: people, processes, and technologies. This has led to a greater appreciation for the positive role people play in the system. Safety benefits from collaboration between service providers, and between service providers and States. This perspective has nurtured multiple collaborative initiatives between service providers and an appreciation of the benefits of collaboration when addressing safety issues. The international civil aviation organization Runway Safety Programme is a good example. 2.1.6 For the collaborative total system approach to flourish, the interfaces and interactions between the organizations (including States) need to be well understood and managed. States are also beginning to recognize the role the total aviation system approach can play in their state safety program development. For example, it helps to manage safety risks which cut across multiple aviation activities. 2.2 HUMANS IN THE SYSTEM 2.2.1 How people think about their responsibilities towards safety and how they interact with others to perform their tasks at work significantly affects their organization’s safety performance. Managing safety needs to address how people contribute, both positively and negatively, to organizational safety. Human factors is about: understanding the ways in which people interact with the world, their capabilities and limitations, and influencing human activity to improve the way people do their work. As a result, the consideration of human factors is an integral part of safety management, necessary to understand, identify and mitigate risks as well as to optimize the human contributions to organizational safety. 2.2.2 The following are key ways in which safety management processes consider human factors: a) senior management commitment to creating a working environment that optimizes human performance and encourages personnel to actively engage in and contribute to the organization’s safety management processes; b) responsibilities of personnel with respect to safety management are clarified to ensure common understanding and expectations; c) personnel are provided with information by the organization that: 1) describes the expected behaviours in respect to the organizational processes and procedures; 2) describes what actions will be taken by the organization in response to individual behaviours; d) human resourcing levels are monitored and adjusted to ensure there are enough individuals to meet operational demands; e) policies, processes and procedures are established to encourage safety reporting; f) safety data and safety information are analysed to allow consideration of those risks related to variable human performance and human limitations, with particular attention to any associated organizational and operational factors; g) policies, processes and procedures are developed that are clear, concise and workable, with the aim of: 1) optimizing human performance; 2) preventing inadvertent errors; 3) reducing the unwanted consequences of variable human performance; the effectiveness of these are continually monitored during normal operations; h) ongoing monitoring of normal operations includes assessment of whether processes and procedures are followed and, when they are not followed, investigations are carried out to determine the cause; i) safety investigations include the assessment of contributing human factors, examining not only behaviours but reasons for such behaviours (context), with the understanding that in most cases people are doing their best to get the job done; j) management of change process includes consideration of the evolving tasks and roles of the human in the system; k) personnel are trained to ensure they are competent to perform their duties, the effectiveness of training is reviewed and training programmes are adapted to meet changing needs. 2.2.3 The effectiveness of safety management depends largely on the degree of senior support and management commitment to create a working environment that optimizes human performance and encourages personnel to actively engage in and contribute to the organization’s safety management processes. 2.2.4 To address the way that the organization influences human performance there must be senior level support to implement effective safety management. This includes management commitment to create the right working environment and the right safety culture to address human factors. This will also influence the attitudes and behaviours of everyone in the organization. More information on safety culture can be found in Chapter 3. 2.2.5 A number of models have been created to support the assessment of human factors on safety performance. The software hardware environment liveware Model is well known and useful to illustrate the impact and interaction of the different system components on the human, and emphasizes the need to consider human factors as an integrated part of SRM. 2.2.6 Figure 2-2 illustrates the relationship between the human (at the centre of the model) and workplace components. The software hardware environment liveware Model contains four satellite components: a) Software (S): procedures, training, support, etc.; b) Hardware (H): machines and equipment; c) Environment (E): the working environment in which the rest of the L-H-S system must function; and d) Liveware (L): other humans in the workplace. 2.2.7 Liveware. The critical focus of the model is the humans at the front line of operations, and depicted in the centre of the model. However, of all the dimensions in the model, this is the one which is least predictable and most susceptible to the effects of internal (hunger, fatigue, motivation, etc.) and external (temperature, light, noise, etc.) influences. Although humans are remarkably adaptable, they are subject to considerable variations in performance. Humans are not standardized to the same degree as hardware, so the edges of this block are not simple and straight. The effects of irregularities at the interfaces between the various software hardware environment liveware blocks and the central Liveware block should be understood to avoid tensions that may compromise human performance. The jagged edges of the modules represent the imperfect coupling of each module. This is useful in visualizing the following interfaces between the various components of the aviation system: a) Liveware-Hardware (L-H). The L-H interface refers to the relationship between the human and the physical attributes of equipment, machines and facilities. This considers the ergonomics of operating the equipment by personnel, how safety information is displayed and how switches and operating levers are labelled and operated so they are logical and intuitive to operate. b) Liveware-Software (L-S). The L-S interface is the relationship between the human and the supporting systems found in the workplace, e.g. regulations, manuals, checklists, publications, processes and procedures, and computer software. It includes such issues as the recency of experience, accuracy, format and presentation, vocabulary, clarity and the use of symbols. L-S considers the processes and procedures - how easy they are to follow and understand. c) Liveware-Liveware (L-L). The L-L interface is the relationship and interaction between people in their work environment. Some of these interactions are within the organization (colleagues, supervisors, managers), many are between individuals from different organizations with different roles (air traffic controllers with pilots, pilots with engineers etc.). It considers the importance of communication and interpersonal skills, as well as group dynamics, in determining human performance. The advent of crew resource management and its extension to air traffic services (ATS) and maintenance operations has enabled organizations to consider team performance in the management of errors. Also within the scope of this interface are staff/management relationships and organizational culture. d) Liveware-Environment (L-E). This interface involves the relationship between the human and the physical environment. This includes things such as temperature, ambient light, noise, vibration and air quality. It also considers the externally environmental factors, such as weather, infrastructure and terrain. 2.3 ACCIDENT CAUSATION 2.3.1 The “Swiss-Cheese” (or Reason) Model, developed by Professor James Reason and well known to the aviation industry, illustrates that accidents involve successive breaches of multiple defences. These breaches can be triggered by a number of enabling factors such as equipment failures or operational errors. The Swiss-Cheese Model contends that complex systems such as aviation are extremely well defended by layers of defences (otherwise known as “barriers”). A single-point failure is rarely consequential. Breaches in safety defences can be a delayed consequence of decisions made at the higher levels of the organization, which may remain dormant until their effects or damaging potential are activated by certain operating conditions (known as latent conditions). Under such specific circumstances, human failures (or “active failures”) at the operational level act to breach the final layers of safety defence. The Reason Model proposes that all accidents include a combination of both active failures and latent conditions. 2.3.2 Active failures are actions or inactions, including errors and rule-breaking, that have an immediate adverse effect. They are viewed, with the benefit of hindsight, as unsafe acts. Active failures are associated with front-line personnel (pilots, air traffic controllers, aircraft maintenance engineers, etc.) and may result in a harmful outcome. 2.3.3 Latent conditions can exist in the system well before a damaging outcome. The consequences of latent conditions may remain dormant for a long time. Initially, these latent conditions are not perceived as harmful, but under certain conditions may become clear when the operational level defences are breached. People far removed in time and space from the event can create these conditions. Latent conditions in the system may include those created by the safety culture; equipment choices or procedural design; conflicting organizational goals; defective organizational systems; or management decisions. 2.3.4 The “organizational accident” paradigm assists by identifying these latent conditions on a system-wide basis, rather than through localized efforts, to minimize active failures by individuals. Importantly, latent conditions, when created, had good intentions. Organizational decision makers are often balancing finite resources, and potentially conflicting priorities and costs. The decisions taken by decision makers, made on a daily basis in large organizations, might, in particular circumstances, unintentionally lead to a damaging outcome. 2.3.5 Figure 2-3 illustrates how the Swiss-Cheese Model assists in understanding the interplay of organizational and managerial factors in accident causation. Multiple defensive layers are built into the aviation system to protect against variations in human performance or decisions at all levels of the organization. But each layer typically has weaknesses, depicted by the holes in the slices of “Swiss cheese”. Sometimes all of the weaknesses align (represented by the aligned holes) leading to a breach that penetrates all defensive barriers and may result in a catastrophic outcome. The Swiss-Cheese Model represents how latent conditions are ever present within the system and can manifest through local trigger factors. 2.3.6 It is important to recognize that some of the defences, or breaches, can be influenced by an interfacing organization. It is therefore vitally important that service providers assess and manage these interfaces. 2.3.7 “Swiss–Cheese” applications for safety management 2.3.7.1 The “Swiss-Cheese” Model can be used as an analysis guide by both States and service providers by looking past the individuals involved in an incident or identified hazard, into the organizational circumstances which may have allowed the situation to manifest. It can be applied during SRM, safety surveillance, internal auditing, change management and safety investigation. In each case, the model can be used to consider which of the organization’s defences are effective, which can or have been breached, and where the system could benefit from additional defences. Once identified, any weaknesses in the defences can be reinforced against future accidents and incidents. 2.3.7.2 In practice, the event will breach the defences in the direction of the arrow (hazards to losses) as displayed in the rendering of Figure 2-3. The assessments of the situation will be conducted in the opposite direction, in this case losses to hazard. Actual aviation accidents will usually include a degree of additional complexity. There are more sophisticated models which can help States and service providers to understand how and why accidents happen. 2.3.8 Practical drift 2.3.8.1 Scott A. Snook's theory of practical drift is used to understand how performance of any system “drifts away” from its original design. Tasks, procedures, and equipment are often initially designed and planned in a theoretical environment, under ideal conditions, with an implicit assumption that nearly everything can be predicted and controlled, and where everything functions as expected. This is usually based on three fundamental assumptions that the: a) technology needed to achieve the system production goals is available; b) personnel are trained, competent and motivated to properly operate the technology as intended; and c) policy and procedures will dictate system and human behaviour. These assumptions underlie the baseline (or ideal) system performance, which can be graphically presented as a straight line from the start of operational deployment as shown in Figure 2-4. 2.3.8.2 Once operationally deployed, the system should ideally perform as designed, following baseline performance (orange line) most of the time. In reality, the operational performance often differs from the assumed baseline performance as a consequence of real-life operations in a complex, ever-changing and usually demanding environment (red line). Since the drift is a consequence of daily practice, it is referred to as a “practical drift”. The term “drift” is used in this context as the gradual departure from an intended course due to external influences. 2.3.8.3 Snook contests that practical drift is inevitable in any system, no matter how careful and well thought out its design. Some of the reasons for the practical drift include: a) technology that does not operate as predicted; b) procedures that cannot be executed as planned under certain operational conditions; c) changes to the system, including the additional components; d) interactions with other systems; e) safety culture; f) adequacy (or inadequacy) of resources (e.g. support equipment); g) learning from successes and failures to improve operations, and so forth. 2.3.8.4 In reality people will generally make the system work on a daily basis despite the system’s shortcomings, applying local adaptations (or workarounds) and personal strategies. These workarounds may bypass the protection of existing safety risk controls and defences. 2.3.8.5 Safety assurance activities such as audits, observations and monitoring of SPIs can help to expose activities that are “practically drifting”. Analysing the safety information to find out why the drift is happening helps to mitigate the safety risks. The closer to the beginning of the operational deployment that practical drift is identified, the easier it is for the organization to intervene. More information on safety assurance for States and service providers may be found in Chapters 8 and 9, respectively. 2.4 MANAGEMENT DILEMMA 2.4.1 In any organization engaged in the delivery of services, production/profitability and safety risks are linked. An organization must maintain profitability to stay in business by balancing output with acceptable safety risks (and the costs involved in implementing safety risk controls). Typical safety risk controls include technology, training, processes and procedures. For the State, the safety risk controls are similar, i.e. training of personnel, the appropriate use of technology, effective oversight and the internal processes and procedures supporting oversight. Implementing safety risk controls comes at a price – money, time, resources – and the aim of safety risk controls is usually to improving safety performance, not production performance. However, some investments in “protection” can also improve “production” by reducing accidents and incidents and thereby their associated costs. 2.4.2 The safety space is a metaphor for the zone where an organization balances desired production/profitability while maintaining required safety protection through safety risk controls. For example, a service provider may wish to invest in new equipment. The new equipment may simultaneously provide the necessary efficiency improvements as well as improved reliability and safety performance. Such decision-making involves an assessment of both the benefits to the organization as well as the safety risks involved. The allocation of excessive resources to safety risk controls may result in the activity becoming unprofitable, thus jeopardizing the viability of the organization. 2.4.3 On the other hand, excess allocation of resources for production at the expense of protection can have an impact on the product or service and can ultimately lead to an accident. It is therefore essential that a safety boundary be defined that provides early warning that an unbalanced allocation of resources exists, or is developing. Organizations use financial management systems to recognize when they are getting too close to bankruptcy and apply the same logic and tools used by safety management to monitor their safety performance. This enables the organization to operate profitably and safely within the safety space. Figure 2-5 illustrates the boundaries of an organization’s safety space. Organizations need to continuously monitor and manage their safety space as safety risks and external influences change over time. 2.4.4 The need to balance profitability and safety (or production and protection) has become a readily understood and accepted requirement from a service provider perspective. This balance is equally applicable to the State’s management of safety, given the requirement to balance resources required for State protective functions that include certification and surveillance. 2.5 SAFETY RISK MANAGEMENT Safety Risk Management (SRM) is a key component of safety management and includes hazard identification, safety risk assessment, safety risk mitigation and risk acceptance. safety risk management is a continuous activity because the aviation system is constantly changing, new hazards can be introduced and some hazards and associated safety risks may change over time. In addition, the effectiveness of implemented safety risk mitigation strategies must be monitored to determine if further action is required. 2.5.1 Introduction to hazards 2.5.1.1 In aviation, a hazard can be considered as a dormant potential for harm which is present in one form or another within the system or its environment. This potential for harm may appear in different forms, for example: as a natural condition (e.g. terrain) or technical status (e.g. runway markings). 2.5.1.2 Hazards are an inevitable part of aviation activities, however, their manifestation and possible adverse consequences can be addressed through mitigation strategies which aim to contain the potential for the hazard to result in an unsafe condition. Aviation can coexist with hazards so long as they are controlled. Hazard identification is the first step in the safety risk management process. It precedes a safety risk assessment and requires a clear understanding of hazards and their related consequences. 2.5.2 Understanding hazards and their consequences 2.5.2.1 Hazard identification focuses on conditions or objects that could cause or contribute to the unsafe operation of aircraft or aviation safety-related equipment, products and services (guidance on distinguishing hazards that are directly pertinent to aviation safety from other general/industrial hazards is addressed in subsequent paragraphs) 2.5.2.2 Consider, for example, a fifteen-knot wind. Fifteen-knots of wind is not necessarily a hazardous condition. In fact, a fifteen-knot wind blowing directly down the runway improves aircraft take-off and landing performance. But if the fifteen-knot wind is blowing across the runway, a crosswind condition is created which may be hazardous to operations. This is due to its potential to contribute to aircraft instability. The reduction in control could lead to an occurrence, such as a lateral runway excursion. 2.5.2.3 It is not uncommon for people to confuse hazards with their consequences. A consequence is an outcome that can be triggered by a hazard. For example, a runway excursion (overrun) is a potential consequence related to the hazard of a contaminated runway. By clearly defining the hazard first, one can more readily identify possible consequences. 2.5.2.4 In the crosswind example above, an immediate outcome of the hazard could be loss of lateral control followed by a consequent runway excursion. The ultimate consequence could be an accident. The damaging potential of a hazard can materialize through one or many consequences. It is important that safety risk assessments identify all of the possible consequences. The most extreme consequence - loss of human life - should be differentiated from those that involve lesser consequences, such as: aircraft incidents; increased flight crew workload; or passenger discomfort. The description of the consequences will inform the risk assessment and subsequent development and implementation of mitigations through prioritization and allocation of resources. Detailed and thorough hazard identification will lead to more accurate assessment of safety risks. Hazard identification and prioritization 2.5.2.5 Hazards exist at all levels in the organization and are detectable through many sources including reporting systems, inspections, audits, brainstorming sessions and expert judgement. The goal is to proactively identify hazards before they lead to accidents, incidents or other safety-related occurrences. An important mechanism for proactive hazard identification is a voluntary safety reporting system. Additional guidance on voluntary safety reporting systems can be found in Chapter 5. Information collected through such reporting systems may be supplemented by observations or findings recorded during routine site inspections or organizational audits. 2.5.2.6 Hazards can also be identified in the review or study of internal and external investigation reports. A consideration of hazards when reviewing accident or incident investigation reports is a good way to enhance the organization’s hazard identification system. This is particularly important when the organization’s safety culture is not yet mature enough to support effective voluntary safety reporting, or in small organizations with limited events or reports. An important source of specific hazards linked to operations and activities is from external sources such as ICAO, trade associations or other international bodies. 2.5.2.7 Hazard identification may also consider hazards that are generated outside of the organization and hazards that are outside the direct control of the organization, such as extreme weather or volcanic ash. Hazards related to emerging safety risks are also an important way for organizations to prepare for situations that may eventually occur. 2.5.2.8 The following should be considered when identifying hazards: a) system description; b) design factors, including equipment and task design; c) human performance limitations (e.g. physiological, psychological, physical and cognitive); d) procedures and operating practices, including documentation and checklists, and their validation under actual operating conditions; e) communication factors, including media, terminology and language; f) organizational factors, such as those related to the recruitment, training and retention of personnel, compatibility of production and safety goals, allocation of resources, operating pressures and corporate safety culture; g) factors related to the operational environment (e.g. weather, ambient noise and vibration, temperature and lighting); h) regulatory oversight factors, including the applicability and enforceability of regulations, and the certification of equipment, personnel and procedures; i) performance monitoring systems that can detect practical drift, operational deviations or a deterioration of product reliability; j) human-machine interface factors; and k) factors related to the SSP/SMS interfaces with other organizations. Occupational safety health and environment hazards 2.5.2.9 Safety risks associated with compound hazards that simultaneously impact aviation safety as well as OSHE may be managed through separate (parallel) risk mitigation processes to address the separate aviation and OSHE consequences, respectively. Alternatively, an integrated aviation and OSHE risk mitigation system may be used to address compound hazards. An example of a compound hazard is a lightning strike on an aircraft at an airport transit gate. This hazard may be deemed by an OSHE inspector to be a “workplace hazard” (ground personnel/workplace safety). To an aviation safety inspector, it is also an aviation hazard with risk of damage to the aircraft and a risk to passenger safety. It is important to consider both the OSHE and aviation safety consequences of such compound hazards, since they are not always the same. The purpose and focus of preventive controls for OSHE and aviation safety consequences may differ. Hazard identification methodologies 2.5.2.10 The two main methodologies for identifying hazards are: a) Reactive. This methodology involves analysis of past outcomes or events. Hazards are identified through investigation of safety occurrences. Incidents and accidents are an indication of system deficiencies and therefore can be used to determine which hazard(s) contributed to the event. b) Proactive. This methodology involves collecting safety data of lower consequence events or process performance and analysing the safety information or frequency of occurrence to determine if a hazard could lead to an accident or incident. The safety information for proactive hazard identification primarily comes from flight data analysis (FDA) programmes, safety reporting systems and the safety assurance function. 2.5.2.11 Hazards can also be identified through safety data analysis which identifies adverse trends and makes predictions about emerging hazards, etc. Hazards related to safety management system interfaces with external organizations 2.5.2.12 Organizations should also identify hazards related to their safety management interfaces. This should, where possible, be carried out as a joint exercise with the interfacing organizations. The hazard identification should consider the operational environment and the various organizational capabilities (people, processes, technologies) which could contribute to the safe delivery of the service or product’s availability, functionality or performance. 2.5.2.13 As an example, an aircraft turnaround involves many organizations and operational personnel all working in and around the aircraft. There are likely to be hazards related to the interfaces between operational personnel, their equipment and the coordination of the turnaround activity. 2.5.3 Safety risk probability 2.5.3.1 Safety risk probability is the likelihood that a safety consequence or outcome will occur. It is important to envisage a variety of scenarios so that all potential consequences can be considered. The following questions can assist in the determination of probability: a) Is there a history of occurrences similar to the one under consideration, or is this an isolated occurrence? b) What other equipment or components of the same type might have similar issues? c) What is the number of personnel following, or subject to, the procedures in question? d) What is the exposure of the hazard under consideration? For example, during what percentage of the operation is the equipment or activity in use? 2.5.3.2 Taking into consideration any factors that might underlie these questions will help when assessing the probability of the hazard consequences in any foreseeable scenario. 2.5.3.3 An occurrence is considered foreseeable if any reasonable person could have expected the kind of occurrence to have happened under the same circumstances. Identification of every conceivable or theoretically possible hazard is not possible. Therefore, good judgment is required to determine an appropriate level of detail in hazard identification. Service providers should exercise due diligence when identifying significant and reasonably foreseeable hazards related to their product or service. Note.— Regarding product design, the term “foreseeable” is intended to be consistent with its use in airworthiness regulations, policy, and guidance. 2.5.3.4 Table 1 presents a typical safety risk probability classification table. It includes five categories to denote the probability related to an unsafe event or condition, the description of each category, and an assignment of a value to each category. This example uses qualitative terms; quantitative terms could be defined to provide a more accurate assessment. This will depend on the availability of appropriate safety data and the sophistication of the organization and operation. Safety risk probability table Likelihood - Frequent, Meaning - Likely to occur many times (has occurred frequently), Value 5 Likelihood - Occasional, Meaning - Likely to occur sometimes (has occurred infrequently), Value 4 Likelihood - Remote, Meaning - Unlikely to occur, but possible (has occurred rarely), Value 3 Likelihood - Improbable, Meaning - Very unlikely to occur (not known to have occurred), Value 2 Likelihood - Extremely, Meaning - improbable Almost inconceivable that the event will occur, Value 1 Note.— This is an example only. The level of detail and complexity of tables and matrices should be adapted to the particular needs and complexities of each organization. It should also be noted that organizations might include both qualitative and quantitative criteria. 2.5.4 Safety risk severity 2.5.4.1 Once the probability assessment has been completed, the next step is to assess the severity, taking into account the potential consequences related to the hazard. Safety risk severity is defined as the extent of harm that might reasonably be expected to occur as a consequence or outcome of the identified hazard. The severity classification should consider: a) fatalities or serious injury which would occur as a result of: 1) being in the aircraft; 2) having direct contact with any part of the aircraft, including parts which have become detached from the aircraft; or 3) having direct exposure to jet blast; and b) damage: 1) damage or structural failure sustained by the aircraft which: i) adversely affects the structural strength, performance or flight characteristics of the aircraft; ii) would normally require major repair or replacement of the affected component; 2) damage sustained by ATS or aerodrome equipment which: i) adversely affects the management of aircraft separation; or ii) adversely affects landing capability. 2.5.4.2 The severity assessment should consider all possible consequences related to a hazard, taking into account the worst foreseeable situation. Table 2 presents a typical safety risk severity table. It includes five categories to denote the level of severity, the description of each category, and the assignment of a value to each category. As with the safety risk probability table, this table is an example only. Example safety risk severity table Severity - Catastrophic, Meaning • Aircraft / equipment destroyed • Multiple deaths, Value A Severity - Hazardous, Meaning • A large reduction in safety margins, physical distress or a workload such that operational personnel cannot be relied upon to perform their tasks accurately or completely • Serious injury • Major equipment damage, Value B Severity - Major, Meaning • A significant reduction in safety margins, a reduction in the ability of operational personnel to cope with adverse operating conditions as a result of an increase in workload or as a result of conditions impairing their efficiency • Serious incident • Injury to persons, Value C Severity - Minor, Meaning • Nuisance • Operating limitations • Use of emergency procedures • Minor incident, Value C Severity - Negligible, Meaning • Few consequences, Value E 2.5.5 Safety risk tolerability 2.5.5.1 The safety risk index rating is created by combining the results of the probability and severity scores. In the example above, it is an alphanumeric designator. The respective severity/probability combinations are presented in the safety risk assessment matrix in Table 3. The safety risk assessment matrix is used to determine safety risk tolerability. Consider, for example, a situation where the safety risk probability has been assessed as Occasional (4), and the safety risk severity has been assessed as Hazardous (B), resulting in a safety risk index of (4B). 2.5.5.2 The index obtained from the safety risk assessment matrix should then be exported to a safety risk tolerability table that describes — in a narrative form — the tolerability criteria for the particular organization. Table 4 presents an example of a safety risk tolerability table. Using the example above, the criterion for safety risk assessed as 4B falls in the “intolerable” category. In this case, the safety risk index of the consequence is unacceptable. The organization should therefore take risk control action to reduce: a) the organization’s exposure to the particular risk, i.e., reduce the probability component of the risk to an acceptable level; b) the severity of consequences related to the hazard, i.e., reduce the severity component of the risk to an acceptable level; or c) both the severity and probability so that the risk is managed to an acceptable level. 2.5.5.3 Safety risks are conceptually assessed as acceptable, tolerable or intolerable. Safety risks assessed as initially falling in the intolerable region are unacceptable under any circumstances. The probability and/or severity of the consequences of the hazards are of such a magnitude, and the damaging potential of the hazard poses such a threat to safety, that mitigation action is required or activities are stopped. Example of safety risk tolerability Safety Risk Index Range - 5A, 5B, 5C, 4A, 4B, 3A; Safety Risk Description - INTOLERABLE; Recommended Action - Take immediate action to mitigate the risk or stop the activity. Perform priority safety risk mitigation to ensure additional or enhanced preventative controls are in place to bring down the safety risk index to tolerable. Safety Risk Index Range - 5D, 5E, 4C, 4D, 4E, 3B, 3C, 3D,2A, 2B, 2C, 1A; Safety Risk Description - TOLERABLE; Recommended Action - Can be tolerated based on the safety risk mitigation. Itmay require management decision to accept the risk. Safety Risk Index Range - 3E, 2D, 2E, 1B, 1C, 1D, 1E; Safety Risk Description - ACCEPTABLE; Recommended Action - Acceptable as is. No further safety risk mitigation required. 2.5.6 Assessing human factors related risks 2.5.6.1 The consideration of human factors has particular importance in safety risk management as people can be both a source and a solution of safety risks by: a) contributing to an accident or incident through variable performance due to human limitations; b) anticipating and taking appropriate actions to avoid a hazardous situation: and c) solving problems, making decisions and taking actions to mitigate risks. 2.5.6.2 It is therefore important to involve people with appropriate human factors expertise in the identification, assessment and mitigation of risks. 2.5.6.3 safety risk management requires all aspects of safety risk to be addressed, including those related to humans. Assessing the risks associated with human performance is more complex than risk factors associated with technology and environment since: a) human performance is highly variable, with a wide range of interacting influences internal and external to the individual. Many of the effects of the interaction between these influences are difficult, or impossible to predict; and b) the consequences of variable human performance will differ according to the task being performed and the context. 2.5.6.4 This complicates how the probability and the severity of the risk is determined. Therefore, human factors expertise is valuable in the identification and assessment of safety risks. (The management of fatigue using safety management system processes is addressed in the Manual for the Oversight of Fatigue Management Approaches (Doc 9966)). 2.5.7 Safety risk mitigation strategies 2.5.7.1 Safety risk mitigation is often referred to as a safety risk control. Safety risks should be managed to an acceptable level by mitigating the safety risk through the application of appropriate safety risk controls. This should be balanced against the time, cost and difficulty of taking action to reduce or eliminate the safety risk. The level of safety risk can be lowered by reducing the severity of the potential consequences, reducing the likelihood of occurrence or by reducing exposure to that safety risk. It is easier and more common to reduce the likelihood than it is to reduce the severity. 2.5.7.2 Safety risk mitigations are actions that often result in changes to operating procedures, equipment or infrastructure. Safety risk mitigation strategies fall into three categories: a) Avoidance: The operation or activity is cancelled or avoided because the safety risk exceeds the benefits of continuing the activity, thereby eliminating the safety risk entirely. b) Reduction: The frequency of the operation or activity is reduced, or action is taken to reduce the magnitude of the consequences of the safety risk. c) Segregation: Action is taken to isolate the effects of the consequences of the safety risk or build in redundancy to protect against them. 2.5.7.3 The consideration of human factors is an integral part of identifying effective mitigations because humans are required to apply, or contribute to, the mitigation or corrective actions. For example, mitigations may include the use of processes or procedures. Without input from those who will be using these in “real world” situations and/or individuals with human factors expertise, the processes or procedures developed may not be fit for their purpose and result in unintended consequences. Further, human performance limitations should be considered as part of any safety risk mitigation, building in error capturing strategies to address human performance variability. Ultimately, this important human factors perspective results in more comprehensive and effective mitigations. 2.5.7.4 A safety risk mitigation strategy may involve one of the approaches described above or may include multiple approaches. It is important to consider the full range of possible control measures to find an optimal solution. The effectiveness of each alternative strategy must be evaluated before a decision is made. Each proposed safety risk mitigation alternative should be examined from the following perspectives: a) Effectiveness. The extent to which the alternatives reduce or eliminate the safety risks. Effectiveness can be determined in terms of the technical, training and regulatory defences that can reduce or eliminate safety risks. b) Cost/benefit. The extent to which the perceived benefits of the mitigation outweighs the costs. c) Practicality. The extent to which mitigation can be implemented and how appropriate it is in terms of available technology, financial and administrative resources, legislation, political will, operational realities, etc. d) Acceptability. The extent to which the alternative is acceptable to those people that will be expected to apply it. e) Enforceability. The extent to which compliance with new rules, regulations or operating procedures can be monitored. f) Durability. The extent to which the mitigation will be sustainable and effective. g) Residual safety risks. The degree of safety risk that remains subsequent to the implementation of the initial mitigation and which may necessitate additional safety risk control measures. h) Unintended consequences. The introduction of new hazards and related safety risks associated with the implementation of any mitigation alternative. i) Time. Time required for the implementation of the safety risk mitigation alternative. 2.5.7.5 Corrective action should take into account any existing defences and their (in)ability to achieve an acceptable level of safety risk. This may result in a review of previous safety risk assessments that may have been impacted by the corrective action. Safety risk mitigations and controls will need to be verified/audited to ensure that they are effective. Another way to monitor the effectiveness of mitigations is through the use of SPIs. See Chapter 4 for more information on safety performance management and SPIs. 2.5.8 Safety risk management documentation 2.5.8.1 Safety risk management activities should be documented, including any assumptions underlying the probability and severity assessment, decisions made, and any safety risk mitigation actions taken. This may be done using a spread sheet or table. Some organizations may use a database or other software where large amounts of safety data and safety information can be stored and analysed. 2.5.8.2 Maintaining a register of identified hazards minimizes the likelihood that the organization will lose sight of its known hazards. When hazards are identified, they can be compared with the known hazards in the register to see if the hazard has already been registered, and what action(s) were taken to mitigate it. Hazard registers are usually in a table format and typically include: the hazard, potential consequences, assessment of associated risks, identification date, hazard category, short description, when or where it applies, who identified it and what measure have been put in place to mitigate the risks. 2.5.8.3 Safety risk decision-making tools and processes can be used to improve the repeatability and justification of decisions taken by organizational safety decision makers. An example of a safety risk decision airport information desk is provided below in Figure 2-6. 2.5.9 Cost-benefit analysis Cost-benefit or cost-effectiveness analysis is normally carried out during the safety risk mitigation activities. It is commonly associated with business management, such as a regulatory impact assessment or project management processes. However, there may be situations where a safety risk assessment may have a significant financial impact. In such situations, a supplementary cost-benefit analysis or cost-effectiveness process to support the safety risk assessment may be warranted. This will ensure cost-effectiveness analysis or justification of recommended safety risk control actions has been taken into consideration, with the associated financial implications. Chapter 3 SAFETY CULTURE 3.1 INTRODUCTION 3.1.1 A safety culture is the natural consequence of having humans in the aviation system. Safety culture has been described as “how people behave in relation to safety and risk when no one is watching”. It is an expression of how safety is perceived, valued and prioritized by management and employees in an organization, and is reflected in the extent to which individuals and groups are: a) aware of the risks and known hazards faced by the organization and its activities; b) continuously behaving to preserve and enhance safety; c) able to access the resources required for safe operations; d) willing and able to adapt when facing safety issues; e) willing to communicate safety issues; and f) consistently assessing the safety related behaviours throughout the organization. 3.1.2 Annex 19 requires that both States and service providers promote a positive safety culture with the aim of fostering effective safety management implementation through the SSP/SMS. This chapter provides guidance on the promotion of a positive safety culture. 3.2 SAFETY CULTURE AND SAFETY MANAGEMENT 3.2.1 Whether an organization realizes it or not, it will have a number of different “safety cultures” that reflect group-level attitudes and behaviours. No two organizations are identical, and even within the same organization, different groups may have various ways of thinking about safety, talking about safety and acting on safety issues. This variation may be appropriate for different activities. 3.2.2 How safety values are incorporated into practices by management and personnel directly affects how key elements of the state safety program and safety management system are established and maintained. As a consequence, safety culture has a direct impact on safety performance. If someone believes that safety is not that important then workarounds, cutting corners, or making unsafe decisions or judgements may be the result, especially when the risk is perceived as low and there is no apparent consequence or danger. The safety culture of an organization therefore significantly influences how their state safety program or safety management system develops and how effective it becomes. Safety culture is arguably the single most important influence on the management of safety. If an organization has instituted all the safety management requirements but does not have a positive safety culture, it is likely to underperform. 3.2.3 When the organization has a positive safety culture, and this is visibly supported by upper- and middlemanagement, front-line personnel tend to feel a sense of shared responsibilities towards achieving the organization’s safety objectives. Effective safety management also supports efforts to drive towards an increasingly positive safety culture by increasing the visibility of management’s support and improving active involvement of personnel in managing safety risk. 3.2.4 A positive safety culture relies on a high degree of trust and respect between personnel and management. Time and effort are needed to build a positive safety culture, which can be easily damaged by management decisions and actions, or inactions. Continuous effort and reinforcement are needed. When leadership actively endorses safe practices, it becomes the normal way of doing things. The ideal situation is a fully implemented and effective SSP/SMS and a positive safety culture. Hence, an organization’s safety culture is often seen as a reflection of the maturity of its SSP/SMS. Effective safety management empowers a positive safety culture and a positive safety culture empowers effective safety management. 3.2.5 Safety culture and its influence on safety reporting 3.2.5.1 SSPs and SMSs are sustained by safety data and safety information that is necessary to address existing and potential safety deficiencies and hazards, including safety issues identified by personnel. The success of a reporting system depends entirely on the continuous flow of information from, and feedback to, organizations and individuals. The protection of safety data, safety information and related sources is essential to ensure continued availability of information. For example, in voluntary safety reporting systems, this may be realized through a system that is confidential, and not used for purposes other than maintaining or improving safety. The benefits are twofold. Often personnel are the closest to safety hazards, so a voluntary reporting system enables them to actively identify these hazards and suggest workable solutions. At the same time, the regulator or management is able to gather important safety information and build trust with the organizations or operational personnel who are reporting the information. For more information about the protection of safety data and safety information refer to Chapter 7. 3.2.5.2 Whether organizations or individuals are willing to report their experiences and errors is largely dependent on the perceived benefits and disadvantages associated with reporting. Safety reporting systems may be anonymous or confidential. In general, in an anonymous reporting system a reporter does not provide their identity. In this case there is no opportunity for further clarification of the report’s contents, or the ability to provide feedback. In a confidential reporting system, any identifying information about the reporter is known only to a designated custodian. If organizations and individuals who report safety issues are protected and treated in a fair and consistent manner, they are more likely to divulge such information and work with the regulator or management to effectively manage the associated safety risk(s). 3.2.5.3 States are expected to adopt laws to adhere to the provisions outlined in Annex 19 for the protection of safety data, safety information and related sources. In the case of a voluntary reporting system, confidentiality should be ensured and the reporting system operated in accordance with safety protection laws. Further, organizations need to have an appropriate disciplinary policy, which is accessible to all and widely understood. A disciplinary policy should clearly indicate what behaviours are considered unacceptable and how the organization will respond in such cases. The disciplinary policy needs to be applied fairly, reasonably and consistently. Finally, organizations and individuals are more likely to report their experiences and errors in an environment where they will not be judged or treated unfairly by their peers or their employer. 3.2.5.4 Overall, organizations and individuals must believe they will be supported when reporting in the interest of safety. This includes organizational and personal errors and mistakes. An increase in confidential reports and a decrease in anonymous reports is usually indicative of the organization’s progress towards a positive safety culture. 3.2.6 Safety culture and cultural diversity 3.2.6.1 National culture differentiates the characteristics of particular nations, including the role of the individual within society, the manner in which authority is distributed, and national priorities with respect to resources, accountabilities, morality, objectives and legal systems. 3.2.6.2 From a safety management perspective, national culture influences organizational culture and plays a large part in determining the nature and scope of regulatory enforcement policies, including the relationship between regulatory authority personnel and industry personnel, and the extent to which safety information is protected. These, in turn, impact on peoples’ willingness to report safety issues. 3.2.6.3 The majority of organizations today employ people from multiple cultural backgrounds, which may be defined by their nationality, ethnicity, religion, and/or gender. Aviation operations and safety rely on effective interaction between different professional groups, each with its own professional culture. Hence, the organization’s safety culture may also be significantly affected by the variety of cultural backgrounds of the members of its workforce. 3.2.6.4 Managing safety within the aviation system therefore requires interaction with, and management of, culturally diverse personnel. However, when implementing safety management, managers should be capable of moulding their culturally-diverse workforce into effective teams. Eliminating differences in safety risk perceptions that may derive from different cultural interpretations and enhancing other safety-related aspects, such as communication, leadership styles and interaction between supervisors and subordinates is key. The degree of success will depend on management’s ability to promote a common understanding of safety and each individual’s role in its effectiveness. Regardless of an individual’s cultural background, effective safety management relies on a shared safety culture, with everyone in the organization understanding how they are expected to behave in relation to safety and risk “even when no one is watching”. 3.2.7 Safety culture and organizational change Safety management requires that organizations manage the safety risks associated with organizational and operational changes. Staff concerns about workload, job security and access to training are associated with significant change in organizations and can have a negative impact on safety culture. The degree to which staff feel involved in the development of change and understand their role in the process will also influence the safety culture. 3.3 DEVELOPING A POSITIVE SAFETY CULTURE 3.3.1 A positive safety culture has the following features: a) managers and employees, individually and collectively, want to make decisions and take actions that promote safety; b) individuals and groups continually critique their behaviours and processes and welcome the critique of others searching for opportunities to change and improve as their environment changes; c) management and staff share a common awareness of the hazards and risks faced by the organization and its activities, and the need to manage risks; d) individuals act and make decisions according to a common belief that safety is part of the way they do business; e) individuals value being informed, and informing others, about safety; f) individuals trust their colleagues and managers with information about their experiences, and the reporting of errors and mistakes is encouraged to improve how things are done in the future. 3.3.2 Actions by management and employees can help drive their safety culture to be more positive. Table 5 provides examples of the types of management and employee actions that will enable or disable a positive safety culture in an organization. Organizations should focus on providing enablers and removing any disablers to promote and achieve a positive safety culture. 3.3.3 Monitoring safety culture 3.3.3.1 Safety culture is subject to many influences and organizations may choose to assess their safety culture to: a) understand how people feel about the organization and how importantly safety is perceived; b) identify strengths and weaknesses; c) identify differences between various groups (subcultures) within an organization; and d) examine changes over time (e.g. in response to significant organizational changes such as following an accident, a change in senior management or altered industrial relations arrangement). 3.3.3.2 There are a number of tools which are used to assess safety culture maturity, usually in combination: a) questionnaires; b) interviews and focus groups; c) observations; and d) document reviews. 3.3.3.3 Assessing safety culture maturity can provide valuable insight, leading to actions by management that will encourage the desired safety behaviours. It should be noted that there is a degree of subjectivity with such assessments and they may reflect the views and perceptions of the people involved at a particular moment only. Also, scoring safety culture maturity can have unintended consequences by inadvertently encouraging the organization to strive to achieve the “right” score, rather than working together to understand and improve the safety culture. Chapter 4 SAFETY PERFORMANCE MANAGEMENT 4.1 INTRODUCTION 4.1.1 Safety performance management is central to the functioning of SSPs and SMSs. Properly implemented, it will provide an organization with the means to determine whether its activities and processes are working effectively to achieve its safety objectives. This is accomplished through the identification of safety performance indicators (SPIs), which are used to monitor and measure safety performance. Through the identification of SPIs, information obtained will allow senior management to be aware of the current situation and support decision-making, including determining whether actions are required to further mitigate safety risks to ensure the organization achieves its safety goals. 4.1.2 The generic safety performance management process and how it is linked with safety data collection and processing systems (SDCPS) and safety analysis, discussed in Chapters 5 and 6, respectively, is shown in Figure 4-1 below. The link to safety promotion is shown to highlight the importance of communicating this information throughout the organization. More information on safety promotion, an important component of state safety program and safety management system which is often underappreciated, can be found in Chapters 8 and 9, respectively. 4.1.3 Safety performance management helps the organization to ask and to answer the four most important questions regarding safety management: a) What are the organization’s top safety risks? Derived from a review of aviation accident and incident data as well as predictive analysis to identify and define emerging risks. b) What does the organization want to achieve in terms of safety and what are the top safety risks that need to be addressed? The organization’s safety objectives. c) How will the organization know if it is making progress toward its safety objectives? Through SPIs, SPTs and, if practicable, safety triggers. d) What safety data and safety information are needed to make informed safety decisions? Including the allocation of the organization’s resources. Through an evolving SDCPS and safety data analysis. 4.1.4 The safety performance management process can also be used to establish an acceptable level of safety performance (ALoSP). More details on the establishment of an ALoSP can be found in Chapter 8. 4.1.5 Relationship between States and service providers 4.1.5.1 There are similarities between the State and service providers in the use and application of safety performance techniques. While the guidance in this chapter has been developed for both States and service providers, some differences are identified in this section. 4.1.5.2 The development of State safety performance should focus on what the State considers to be its most important aspects to managing safety. For the State, an effectively implemented state safety program is used as a decision-making tool for the management of safety performance, which should include: the safety performance of its service providers; the State’s oversight capability; and the support provided to service providers through the establishment of guidelines. States should consider measuring their ability to: a) maintain their safety oversight system; b) apply specific safety actions and introduce safety initiatives; and c) adapt existing safety risk controls to ensure they remain effective. 4.1.5.3 For service providers, the primary function of safety performance management is to monitor and measure how well it is managing its safety risks. This is achieved through the effective implementation of an safety management system that generates information that will be used to make decisions regarding the management of safety, including the implementation of safety risk controls and the allocation of resources. 4.1.5.4 The success of safety management depends on the commitment between the State and its service providers. There may be benefits in the State identifying suitable SPIs that could be monitored by service providers and then shared with the State, in particular for the establishment of the ALoSP (see Chapter 8 for more information). The information received from service providers will assist the State with its assessment of the safety performance of its aviation industry and its own ability to provide effective oversight and support to service providers. However, service providers should ensure their SPIs are appropriate to their operational context, performance history and expectations. 4.1.6 Safety performance management and interfaces 4.1.6.1 When States and service providers are considering implementing safety management, it is important to consider the safety risks induced by interfacing entities. Interfaces can be internal (e.g. between operations and maintenance or finance, human resources or legal departments), or they can be external (e.g. other State, service providers or contracted services). Hazards and related risks at the interface points are among the most common contributors to safety occurrences. States and service providers have greater control over interface-related risks when their interfaces are identified and managed. Interfaces should be defined in the organization’s system description. 4.1.6.2 States and service providers are responsible for ongoing monitoring and management of their interfaces to ensure safe outcomes. The safety risk posed by each interface should, ideally, be collaboratively assessed by the interfacing entities. Collaboration is highly desirable because the perception of safety risks and their tolerability may vary between the interfacing organizations. Sharing of interface risk management, through the establishment and monitoring of SPIs, encourages the mutual awareness of safety risks rather than ignorance or potentially one-sided risk management. It also creates an opportunity for transfer of knowledge and working practices that could improve the safety effectiveness of both organizations. 4.1.6.3 For this reason, SPIs should be agreed and established to monitor and measure the risks and the effectiveness of mitigating actions. A formal interface management agreement between interfacing organizations, with clearly defined monitoring and management responsibilities, is an example of an effective approach. 4.2 SAFETY OBJECTIVES 4.2.1 Safety objectives are brief, high-level statements of safety achievements or desired outcomes to be accomplished. Safety objectives provide direction to the organization’s activities and should therefore be consistent with the safety policy that sets out the organization’s high-level safety commitment. They are also useful to communicate safety priorities to personnel and the aviation community as a whole. Establishing safety objectives provides strategic direction for the safety performance management process and provides a sound basis for safety related decision-making. The management of safety performance should be a primary consideration when amending policies or processes, or allocating the organization’s resources in pursuit of improving safety performance. 4.2.2 Safety objectives may be: a) process-oriented: stated in terms of safe behaviours expected from operational personnel or the performance of actions implemented by the organization to manage safety risk; or b) outcome-oriented: encompass actions and trends regarding containment of accidents or operational losses. 4.2.3 The suite of safety objectives should include a mix of both process-oriented and outcome-oriented objectives to provide enough coverage and direction for the SPIs and SPTs. Safety objectives on their own do not have to be specific, measurable, achievable, relevant and timely (SMART) (George T. Doran, 1981), provided the safety objectives and accompanying SPIs and SPTs form a package that allows an organization to demonstrate whether it is maintaining or improving its safety performance. 4.2.4 An organization may also choose to identify safety objectives at the tactical or operational level or apply them to specific projects, products and processes. A safety objective may also be expressed by the use of other terms with a similar meaning (e.g. goal or target). 4.3 SAFETY PERFORMANCE INDICATORS AND SAFETY PERFORMANCE TARGETS 4.3.1 Types of safety performance indicators Qualitative and quantitative indicators 4.3.1.1 SPIs are used to help senior management know whether or not the organization is likely to achieve its safety objective; they can be qualitative or quantitative. Quantitative indicators relate to measuring by the quantity, rather than its quality, whereas qualitative indicators are descriptive and measure by quality. Quantitative indicators are preferred over qualitative indicators because they are more easily counted and compared. The choice of indicator depends on the availability of reliable data that can be measured quantitatively. Does the necessary evidence have to be in the form of comparable, generalizable data (quantitative), or a descriptive image of the safety situation (qualitative)? Each option, qualitative or quantitative, involves different kinds of SPIs, and requires a thoughtful SPI selection process. A combination of approaches is useful in many situations, and can solve many of the problems which may arise from adopting a single approach. An example of a qualitative indicator for a State could be the maturity of their service providers’ safety management system in a particular sector, or for a service provider the assessment of the safety culture. 4.3.1.2 Quantitative indicators can be expressed as a number (x incursions) or as a rate (x incursions per n movements). In some cases, a numerical expression will be sufficient. However, just using numbers may create a distorted impression of the actual safety situation if the level of activity fluctuates. For example, if air traffic control records three altitude busts in July and six in August, there may be great concern about the significant deterioration in safety performance. But August may have seen double the movements of July meaning the altitude busts per movement, or the rate, has decreased, not increased. This may or may not change the level of scrutiny, but it does provide another valuable piece of information that may be vital to data-driven safety decision-making. 4.3.1.3 For this reason, where appropriate, SPIs should be reflected in terms of a relative rate to measure the performance level regardless of the level of activity. This provides a normalized measure of performance; whether the activity increases or decreases. As another example, an SPI could measure the number of runway incursions. But if there were fewer departures in the monitored period, the result could be misleading. A more accurate and valuable performance measure would be the number of runway incursions relative to the number of movements, e.g. x incursions per 1 000 movements. Lagging and leading indicators 4.3.1.4 The two most common categories used by States and service providers to classify their SPIs are lagging and leading. Lagging SPIs measure events that have already occurred. They are also referred to as “outcome-based SPIs” and are normally (but not always) the negative outcomes the organization is aiming to avoid. Leading SPIs measure processes and inputs being implemented to improve or maintain safety. These are also known as “activity or process SPIs” as they monitor and measure conditions that have the potential to lead to or contribute to a specific outcome. 4.3.1.5 Lagging SPIs help the organization understand what has happened in the past and are useful for long-term trending. They can be used as a high-level indicator or as an indication of specific occurrence types or locations, such as “types of accidents per aircraft type” or “specific incident types by region”. Because lagging SPIs measure safety outcomes, they can measure the effectiveness of safety mitigations. They are effective at validating the overall safety performance of the system. For example, monitoring the “number of ramp collisions per number of movements between vehicles following a redesign of ramp markings” provides a measure of the effectiveness of the new markings (assuming nothing else has changed). The reduction in collisions validates an improvement in the overall safety performance of the ramp system; which may be attributable to the change in question. 4.3.1.6 Trends in lagging SPIs can be analysed to determine conditions existing in the system that should be addressed. Using the previous example, an increasing trend in ramp collisions per number of movements may have been what led to the identification of sub-standard ramp markings as a mitigation. 4.3.1.7 Lagging SPIs are divided into two types: a) low probability/high severity: outcomes such as accidents or serious incidents. The low frequency of high severity outcomes means that aggregation of data (at industry segment level or regional level) may result in more meaningful analyses. An example of this type of lagging SPI would be “aircraft and/or engine damage due to bird strike”. b) high probability/low severity: outcomes that did not necessarily manifest themselves in a serious accident or incident, these are sometimes also referred to as precursor indicators. SPIs for high probability/low severity outcomes are primarily used to monitor specific safety issues and measure the effectiveness of existing safety risk mitigations. An example of this type of precursor SPI would be “bird radar detections”, which indicates the level of bird activity rather than the amount of actual bird strikes. 4.3.1.8 Aviation safety measures have historically been biased towards SPIs that reflect “low probability/high severity” outcomes. This is understandable in that accidents and serious incidents are high profile events and are easy to count. However, from a safety performance management perspective, there are drawbacks in an overreliance on accidents and serious incidents as a reliable indicator of safety performance. For instance, accidents and serious incidents are infrequent (there may be only one accident in a year, or none) making it difficult to perform statistical analysis to identify trends. This does not necessarily indicate that the system is safe. A consequence of a reliance on this sort of data is a potential false sense of confidence that an organization’s or system’s safety performance is effective, when it may in fact be perilously close to an accident. 4.3.1.9 Leading indicators are measures that focus on processes and inputs that are being implemented to improve or maintain safety. These are also known as “activity or process SPIs” as they monitor and measure conditions that have the potential to become or to contribute to a specific outcome. 4.3.1.10 Examples of leading SPIs driving the development of organizational capabilities for proactive safety performance management include such things as “percentage of staff who have successfully completed safety training on time” or “frequency of bird scaring activities”. 4.3.1.11 Leading SPIs may also inform the organization about how their operation copes with change, including changes in its operating environment. The focus will be either on anticipating weaknesses and vulnerabilities as a result of the change, or monitoring the performance after a change. An example of an SPI to monitor a change in operations would be “percentage of sites that have implemented procedure X”. 4.3.1.12 For a more accurate and useful indication of safety performance, lagging SPIs, measuring both “low probability/high severity” events and “high probability/low severity” events should be combined with leading SPIs. Figure 4-2 illustrates the concept of leading and lagging indicators that provide a more comprehensive and realistic picture of the organization’s safety performance. 4.3.2 Selecting and defining SPIs 4.3.2.1 SPIs are the parameters that provide the organization with a view of its safety performance: where it has been; where it is now; and where it is headed, in relation to safety. This picture acts as a solid and defensible foundation upon which the organization’s data-driven safety decisions are made. These decisions, in turn, positively affect the organization’s safety performance. The identification of SPIs should therefore be realistic, relevant, and linked to safety objectives, regardless of their simplicity or complexity. 4.3.2.2 It is likely the initial selection of SPIs will be limited to the monitoring and measurement of parameters representing events or processes that are easy and/or convenient to capture (safety data that may be readily available). Ideally, SPIs should focus on parameters that are important indicators of safety performance, rather than on those that are easy to attain. 4.3.2.3 SPIs should be: a) related to the safety objective they aim to indicate; b) selected or developed based on available data and reliable measurement; c) appropriately specific and quantifiable; and d) realistic, by taking into account the possibilities and constraints of the organization. 4.3.2.4 A combination of SPIs is usually required to provide a clear indication of safety performance. There should be a clear link between lagging and leading SPIs. Ideally lagging SPIs should be defined before determining leading SPIs. Defining a precursor SPI linked to a more serious event or condition (the lagging SPI) ensures there is a clear correlation between the two. All of the SPIs, lagging and leading, are equally valid and valuable. An example of these linkages is illustrated in Figure 4-3. 4.3.2.5 It is important to select SPIs that relate to the organization’s safety objectives. Having SPIs that are well defined and aligned will make it easier to identify SPTs, which will show the progress being made towards the attainment of safety objectives. This allows the organization to assign resources for greatest safety effect by knowing precisely what is required, and when and how to act to achieve the planned safety performance. For example, a State has a safety objective of “reduce the number of runway excursions by 50 per cent in three years” and an associated, well-aligned SPI of “number of runway excursions per million departures across all aerodromes”. If the number of excursions drops initially when monitoring commences, but starts to climb again after twelve months, the State could choose to reallocate resources away from an area where, according to the SPIs, the safety objective is being easily achieved and towards the reduction of runway excursions to alleviate the undesirable trend. Defining SPIs 4.3.2.6 The contents of each SPI should include: a) a description of what the SPI measures; b) the purpose of the SPI (what it is intended to manage and who it is intended to inform); c) the units of measurement and any requirements for its calculation; d) who is responsible for collecting, validating, monitoring, reporting and acting on the SPI (these may be staff from different parts of the organization); e) where or how the data should be collected; and f) the frequency of reporting, collecting, monitoring and analysis of the SPI data. SPIs and safety reporting 4.3.2.7 Changes in operational practices may lead to underreporting until their impact is fully accepted by potential reporters. This is known as “reporting bias”. Changes in the provisions related to the protection of safety information and related sources could also lead to over-reporting. In both cases, reporting bias may distort the intent and accuracy of the data used for the SPI. Employed judiciously, safety reporting may still provide valuable data for the management of safety performance. 4.3.3 Setting safety performance targets 4.3.3.1 Safety performance targets (SPTs) define short-term and medium-term safety performance management desired achievements. They act as “milestones” that provide confidence that the organization is on track to achieving its safety objectives and provide a measurable way of verifying the effectiveness of safety performance management activities. SPT setting should take into consideration factors such as the prevailing level of safety risk, safety risk tolerability, as well as expectations regarding the safety of the particular aviation sector. The setting of SPTs should be determined after considering what is realistically achievable for the associated aviation sector and recent performance of the particular SPI, where historical trend data is available. 4.3.3.2 If the combination of safety objectives, SPIs and SPTs working together are SMART, it allows the organization to more effectively demonstrate its safety performance. There are multiple approaches to achieving the goals of safety performance management, especially, setting SPTs. One approach involves establishing general highlevel safety objectives with aligned SPIs and then identifying reasonable levels of improvements after a baseline safety performance has been established. These levels of improvements may be based on specific targets (e.g. percentage decrease) or the achievement of a positive trend. Another approach which can be used when the safety objectives are SMART is to have the safety targets act as milestones to achieving the safety objectives. Either of these approaches are valid and there may be others that an organization finds effective at demonstrating their safety performance. Different approaches can be used in combination as appropriate to the specific circumstances. Setting targets with high-level safety objectives 4.3.3.3 Targets are established with senior management agreeing on high-level safety objectives. The organization then identifies appropriate SPIs that will show improvement of safety performance towards the agreed safety objective(s). The SPIs will be measured using existing data sources, but may also require the collection of additional data. The organization then starts gathering, analysing and presenting the SPIs. Trends will start to emerge, which will provide an overview of the organization’s safety performance and whether it is steering towards or away from its safety objectives. At this point the organization can identify reasonable and achievable SPTs for each SPI. Setting targets with SMART safety objectives 4.3.3.4 Safety objectives can be difficult to communicate and may seem challenging to achieve; by breaking them down into smaller concrete safety targets, the process of delivering them is easier to manage. In this way, targets form a crucial link between strategy and day-to-day operations. Organizations should identify the key areas that drive the safety performance and establish a way to measure them. Once an organization has an idea what their current level of performance is by establishing the baseline safety performance, they can start setting SPTs to give everyone in the State a clear sense of what they should be aiming to achieve. The organization may also use benchmarking to support setting performance targets. This involves using performance information from similar organizations that have already been measuring their performance to get a sense of how others in the community are doing. 4.3.3.5 An example of the relationship between safety objectives, SPIs and SPTs is illustrated in Figure 4-4. In this example, the organization recorded 100 runway excursions per million movements in 2018. It has been determined this is too many, and an objective to reduce the number of runway excursions by fifty per cent by 2022 has been set. Specific targeted actions and associated timelines have been defined to meet these targets. To monitor, measure and report their progress, the organization has chosen “RWY excursions per million movements per year” as the SPI. The organization is aware that progress will be more immediate and effective if specific targets are set which align with the safety objective. They have therefore set a safety target which equates to an average reduction of 12.5 per year over the reporting period (four years). As shown in the graphical representation, the progress is expected to be greater in the first years and less so in the later years. This is represented by the curved projection towards their objective. In the Figure 4-4: a) the SMART safety objective is “50 per cent reduction in runway excursions rate by 2022”; b) the SPI selected is the “number runway excursions per million movements per year”; and c) the safety targets related to this objective represent milestones for reaching the SMART safety objective and equate to a ~12 per cent reduction each year until 2022; 1) SPT 1a is “less than 78 runway excursions per million movement in 2019”; 2) SPT 1b is “less than 64 runway excursions per million movement in 2020”; 3) SPT 1c is “less than 55 runway excursions per million movement in 2021”. Additional considerations for SPI and SPT selection 4.3.3.6 When selecting SPIs and SPTs, the following should also be considered: a) Workload management. Creating a workable amount of SPIs can help personnel manage their monitoring and reporting workload. The same is true of the SPIs complexity, or the availability of the necessary data. It is better to agree on what is feasible, and then prioritize the selection of SPIs on this basis. If an SPI is no longer informing safety performance, or been given a lower priority, consider discontinuing in favour of a more useful or higher priority indicator. b) Optimal spread of SPIs. A combination of SPIs that encompass the focus areas will help gain an insight to the organization’s overall safety performance and enable data-driven decision-making. c) Clarity of SPIs. When selecting an SPI, it should be clear what is being measured and how often. SPIs with clear definitions airport information desk understanding of results, avoid misinterpretation, and allow meaningful comparisons over time. d) Encouraging desired behaviour. SPTs can change behaviours and contribute to desired outcomes. This is especially relevant if achievement of the target is linked to organizational rewards, such as management remuneration. SPTs should foster positive organizational and individual behaviours that deliberately result in defensible decisions and safety performance improvement. It is equally important to consider the potential unintended behaviours when selecting SPIs and SPTs. e) Choosing valuable measures. It is imperative that useful SPIs are selected, not only ones which are easy to measure. It should be up to the organization to decide what the most useful safety parameters are; those that guide the organization to improve decision-making, safety performance management, and achievement of its safety objectives. f) Achieving SPTs. This is a particularly important consideration, and linked to the desired safety behaviours. Achieving the agreed SPTs is not always indicative of safety performance improvement. The organization should distinguish between just meeting SPTs and actual, demonstrable organizational safety performance improvement. It is imperative that the organization consider the context within which the target was achieved, rather than looking at an SPT in isolation. Recognition for overall improvement in safety performance, rather than an individual SPT achievement, will foster desirable organizational behaviours and encourage exchange of safety information that lies at the heart of both safety risk management and safety assurance. This could also enhance the relationship between the State and the service provider and their willingness to share safety data and ideas. Caveats on setting SPTs 4.3.3.7 It is not always necessary or appropriate to define SPTs as there may be some SPIs that are better to monitor for trends rather than use to determine a target. Safety reporting is an example of when having a target could either discourage people not to report (if the target is not to exceed a number) or to report trivial matters to meet a target (if the target is to reach a certain number). There may also be SPIs better used to define a direction of travel to target continuous safety performance improvement (i.e. to reduce the number of events) rather than used to define an absolute target, as these may be difficult to determine. The following should also be considered in deciding appropriate SPTs: a) Drive undesirable behaviours; if managers or organizations are too focused on achievement of the numbers as an indicator of success they may not achieve the intended improvement in safety performance. b) Operational targets; too much focus on achieving operational targets (such as: on time departures, reduction in overhead costs, etc.) without a balance of SPTs can lead to “achieving the operational targets” while not necessarily improving safety performance. c) Focus on quantity rather than quality; this can encourage personnel or departments to meet the target but in doing so deliver a poor product or service. d) Cap innovation; although not intended, once a target is met this can lead to a relaxation and that no further improvements are needed and complacency can set in. e) Organizational conflict; targets can create conflict between departments and organizations as they argue over who is responsible rather than focusing on trying to work together. 4.3.4 Safety Performance Measurement Getting safety performance measurement right involves deciding how best to measure the achievement of the safety objectives. This will vary from State to State and from service provider to service provider. Organizations should take the time to develop their strategic awareness of what it is that drives safety improvement for their safety objectives. 4.3.5 Use of SPIs and SPTs SPIs and SPTs can be used in different ways to demonstrate safety performance. It is crucial that organizations tailor, select and apply various measurement tools and approaches depending on their specific circumstances and the nature of what is being measured. For instance, in some cases, organizations could adopt SPIs that all have specific associated SPTs. In another situation, it may be preferable to focus on achieving a positive trend in the SPIs, without specific target values. The package of selected performance metrics will usually employ a combination of these approaches. 4.4 MONITORING SAFETY PERFORMANCE 4.4.1 Once an organization has identified the targets based on the SPIs they believe will deliver the planned outcome, they must ensure the stakeholders follow through by assigning clear responsibility for delivery. Defining SPTs for each aviation authority, sector and service provider supports the achievement of the ALoSP for the State by assigning clear accountability. 4.4.2 Mechanisms for monitoring and measuring the organization’s safety performance should be established to identify what changes may be needed if the progress made isn't as expected and reinforce the commitment of the organization to meet its safety objectives. 4.4.3 Baseline safety performance Understanding how the organization plans to progress towards its safety objectives requires that they know where they are, in relation to safety. Once the organization’s safety performance structure (safety objectives, indicators, targets, triggers) has been established and is functioning, it is possible to learn their baseline safety performance through a period of monitoring. Baseline safety performance is the safety performance at the commencement of the safety performance measurement process, the datum point from which progress can be measured. In the example used in figures 4-3 and 4-4, the baseline safety performance for that particular safety objective was “100 runway excursions per million movements during the year (2018)”. From this solid basis, accurate and meaningful indications and targets can be recorded. 4.4.4 Refinement of SPIs and SPTs 4.4.4.1 SPIs and associated SPTs will have to be reviewed to determine if they are providing the information needed to track the progress being made toward the safety objectives and to ensure that the targets are realistic and achievable. 4.4.4.2 Safety performance management is an ongoing activity. Safety risks and/or availability of data change over time. Initial SPIs may be developed using limited resources of safety information. Later, more reporting channels may be established, more safety data may be available and the organization’s safety analysis capabilities will likely mature. It may be appropriate for organizations to develop simple (broader) SPIs initially. As they gather more data and safety management capability, they can consider refining the scope of SPIs and SPTs to better align with the desired safety objectives. Small non-complex organizations may elect to refine their SPIs and SPTs and/or select generic (but specific) indicators which apply to most aviation systems. Some examples of generic indicators would be: a) events including structural damage to equipment; b) events indicating circumstances in which an accident nearly occurred; c) events in which operational personnel or members of the aviation community were fatally or seriously injured; d) events in which operational personnel became incapacitated or unable to perform their duties safely; e) rate of voluntary occurrence reports; and f) rate of mandatory occurrence reports. 4.4.4.3 Larger more complex organizations may elect to institute a broader and/or deeper range of SPIs and SPTs and to integrate generic indicators such as those listed above with activity-specific ones. A large airport, for example, providing services to major airlines and situated under complex airspace, might consider combining some of the generic SPIs with deeper-scope SPIs representing specific aspects of their operation. The monitoring of these may require greater effort but will likely produce superior safety results. There is a clear correlation between the relative complexity of SPIs and SPTs and the scale and complexity of the State’s or service providers’ operations. This relative complexity should be reflected in the indicator and target set. Those responsible for establishing safety performance management should be conscious of this. 4.4.4.4 The set of SPIs and SPTs selected by an organization should be periodically reviewed to ensure their continued meaningfulness as indications of organizational safety performance. Some reasons to continue, discontinue or change SPIs and SPTs include: a) SPIs continually report the same value (such as zero per cent or 100 per cent); these SPIs are unlikely to provide meaningful input to senior management decision-making; b) SPIs that have similar behaviour and as such are considered a duplication; c) the SPT for an SPI implemented to measure the introduction of a programme or targeted improvement has been met; d) another safety concern becomes a higher priority to monitor and measure; e) to gain a better understanding of a particular safety concern by narrowing the specifics of an SPI (i.e. reduce the “noise” to clarify the “signal”); and f) safety objectives have changed and as a consequence the SPIs require updating to remain relevant. 4.4.5 Safety triggers 4.4.5.1 A brief perspective on the notions of triggers is relevant to assist in their eventual role within the context of the management of safety performance by an organization. 4.4.5.2 A trigger is an established level or criteria value that serves to trigger (start) an evaluation, decision, adjustment or remedial action related to the particular indicator. One method for setting out-of-limits trigger criteria for SPTs is the use of the population standard deviation (STDEVP) principle. This method derives the standard deviation (SD) value based on the preceding historical data points of a given safety indicator. The SD value plus the average (mean) value of the historical data set forms the basic trigger value for the next monitoring period. The SD principle (a basic statistical function) sets the trigger level criteria based on actual historical performance of the given indicator (data set), including its volatility (data point fluctuations). A more volatile historical data set will usually result in a higher (more generous) trigger level value for the next monitoring period. Triggers provide early warnings which enable decision makers to make informed safety decisions, and thus improve safety performance. An example of trigger levels based on standard deviations (SDs) is provided at Figure 4-5 below. In this example, data-driven decisions and safety mitigation actions may need to be taken when the trend goes beyond +1SD or +2SD from the mean of the preceding period. Often the trigger levels (in this case +1SD, +2SD or beyond +2SD) will align with decision management levels and urgency of action. 4.4.5.3 Once SPTs and trigger settings (if used) have been defined, their associated SPI may be tracked for their respective performance status. A consolidated summary of the overall SPT and trigger performance outcome of the complete SPIs package may also be compiled and/or aggregated for a given monitoring period. Qualitative values (satisfactory/unsatisfactory) may be assigned for each SPT achievement and each trigger level not breached. Alternatively, numeric values (points) may be used to provide a quantitative measurement of the overall performance of the SPIs package. 4.4.5.4 It should be noted that trigger values serve to trigger (start) an evaluation, decision, adjustment or remedial action related to the particular indicator. An SPI being triggered is not necessarily catastrophic or an indication of failure. It is merely a sign that the activity has moved beyond the predetermined limit. The trigger aims to attract the attention of decision makers who are now in a position to take remedial action, or not, depending on the circumstances. 4.4.6 Caveat on triggers 4.4.6.1 There are challenges in identifying reliable trigger levels. Triggers and their associated levels work best when there are ample safety data and safety data management capabilities. This can impose an additional workload on the organization. The notion of trigger was designed and is best suited to safety risk management of purely technical systems (e.g. aircraft engine monitoring). In this case, large amounts of quantitative data support the identification of accurate triggers and trigger levels. The notion of triggers is arguably less relevant to safety risk management of socio-technical systems. Socio-technical systems are systems where people actively interact with the processes and technologies to achieve the system’s service delivery or production objectives. Both state safety program and safety management system are socio-technical systems. The less reliable and meaningful triggers used in socio-technical systems are due to the limitations of reliable measures when humans are involved. 4.4.6.2 A more flexible approach is therefore needed for the triggers to be meaningful. Annex 19 does not require that States or service providers define trigger levels for each SPI. However, there are benefits for organizations where their data for an SPI is very specific, there are enough data points and the data is sufficiently trustworthy. 4.4.6.3 Figure 4-6 below is an extension of the previous example, “50 per cent reduction in runway excursions by 2022”. In this scenario, it is now the year 2020. The organization has been collecting safety data (SPI – “No runway excursions/million movement/yr”) and working with stakeholders to reduce the instances. The SPT for 2019 (<78 runway excursions/million movement in year) was achieved. However, the SPI shows that, not only was the SPT for 2020 (<64 runway excursions/million movement in year) not achieved, the number of excursions has exceeded the trigger in two consecutive reporting periods. The decision makers have been alerted to the deterioration in safety performance and are in a position to make decisions based on the data to take further action(s). Their data-driven decisions will aim to drive the safety performance back to within the acceptable zone, and on track to achieve their safety objective. 4.4.7 Identifying actions required 4.4.7.1 Arguably the most important outcome of establishing a safety performance management structure is the presentation of information to the organization’s decision makers so they can make decisions based on current, reliable safety data and safety information. The aim should always be to make decisions in accordance with the safety policy and towards the safety objectives. 4.4.7.2 In relation to safety performance management, data-driven decision-making is about making effective, well-informed decisions based on the results of monitored and measured SPIs, or other reports and analysis of safety data and safety information. Using valid and relevant safety data combined with information that provides context supports the organization in making decisions that align with its safety objectives and targets. Contextual information may also include other stakeholder priorities, known deficiencies in the data, and other complementary data to evaluate the pros, cons, opportunities, limitations and risks associated with the decision. Having the information readily available and easy to interpret helps to mitigate bias, influence and human error in the decision-making process. 4.4.7.3 Data-driven decision-making also supports the evaluation of decisions made in the past to support any realignment with the safety objectives. More guidance about data-driven decision-making is provided in Chapter 6. 4.5 UPDATE OF SAFETY OBJECTIVES Safety performance management is not intended to be “set and forget”. Safety performance management is dynamic and central to the functioning of every State and every service provider, and should be reviewed and updated: a) routinely, in accordance with the periodic cycle established and agreed upon by the high-level safety committee; b) based on inputs from safety analyses (see Chapter 6 for details); and c) in response to major changes in the operation, top risks or environment. Chapter 5 SAFETY DATA COLLECTION AND PROCESSING SYSTEMS 5.1 INTRODUCTION 5.1.1 The distinction between safety data and safety information is made in the definitions found in Annex 19. Safety data is what is initially reported or recorded as the result of an observation or measurement. It is transformed to safety information when it is processed, organized, integrated or analysed in a given context to make it useful for management of safety. Safety information may continue to be processed in different ways to extract different meanings. 5.1.2 The effective management of safety is highly dependent on the effectiveness of safety data collection, analysis and overall management capabilities. Having a solid foundation of safety data and safety information is fundamental for safety management, since it is the basis for data-driven decision-making. Reliable safety data and safety information is needed to identify trends, make decisions and evaluate safety performance in relation to safety targets and safety objectives, and to assess risk. 5.1.3 Annex 19 requires that service providers develop and maintain a formal process to collect, record, act on and generate feedback on hazards in their activities, based on a combination of reactive and proactive methods of safety data collection. 5.1.4 Similarly, Chapter 8 of Annex 13 — Aircraft Accident and Incident Investigation requires States to establish and maintain an accident and incident database to facilitate the effective analysis of information on actual or potential safety deficiencies, and to determine any preventive actions required. 5.1.5 Annex 19 requires States to establish safety data collection and processing systems (SDCPS) to capture, store, aggregate, and enable the analysis of safety data and safety information to support their safety performance management activities. SDCPS is a generic term used to refer to processing and reporting systems, databases and schemes for exchange of safety information and recorded information. The term “safety database” may refer to a single or multiple database(s). State authorities with responsibilities for the implementation of the state safety program should have access to the SDCPS to support their safety responsibilities. 5.1.6 Service providers are also required to develop and maintain the means to verify their safety performance with reference to their SPIs and SPTs, in support of their safety objectives by means of SDCPS. They may be based on reactive and proactive methods of safety data and safety information collection. 5.1.7 The guidance in this chapter is equally valid for States and service providers to assure that the safety data and safety information collected will enable effective and valid decision-making. 5.1.8 Organizations should ensure they have personnel qualified to collect and store safety data, and the competencies needed to process safety data. This usually requires individuals with strong information technology skills as well as knowledge of data requirements, data standardization, data collection and storage, data governance and the ability to understand potential queries that may be needed for analysis. Additionally, the organization should ensure that each SDCPS has a designated custodian to apply the protection to safety data, safety information and related sources in accordance with Appendix 3 to Annex 19. Chapter 7 contains further details. 5.2 SAFETY DATA AND SAFETY INFORMATION COLLECTION 5.2.1 Objectives at different levels of the aviation system 5.2.1.1 international civil aviation organization has been introducing provisions across Annexes, Procedures for Air Navigation Services (PANS) and documents since the 1970s requiring States to establish reporting systems to collect safety data and safety information. Most of these provisions relate to sector-specific safety reporting systems, with the exception of Annex 13, which focuses specifically on the reporting of accidents and serious incidents. The provisions for mandatory and voluntary safety reporting systems found in Annex 19 originated in Annex 13. 5.2.1.2 Many service providers have collected a wealth of safety data and safety information, including mandatory and voluntary safety reporting systems as well as automated data capture systems. This safety data and safety information allows service providers to identify hazards and supports safety performance management activities at the service provider level. There are many benefits to sharing safety information, not least of which is the identification of hazards that are beyond the view of a single service provider. Information on the sharing and exchange of safety information can be found in Chapter 6. 5.2.1.3 Annex 19 requires States to establish SDCPS to capture, store, aggregate and enable the analysis of safety data and safety information to support the identification of hazards which cut across the aviation system. This implies more than just having access to view the data for the purposes of monitoring the safety performance of service providers. Furthermore, putting in place reporting systems and databases for the collection of safety data and safety information is not sufficient to ensure the availability of the safety data to enable the analysis. States must also put in place laws, regulations, processes and procedures to make sure that safety data and safety information identified in Annex 19 are reported and collected from service providers and others to feed the SDCPS. This requires having the protections in place, as per Annex 19, Appendix 3, to ensure the use of safety data and safety information for purposes of maintaining or improving safety. Arrangements may also be put in place for a third party to collect, store and analyse the safety data and safety information on behalf of the State. Information on the protection of safety data and safety information can be found in Chapter 7. 5.2.1.4 Furthermore, safety data and safety information need to be collected, stored and analysed at the regional level through the regional aviation safety groups (RASGs) to facilitate the identification of hazards that transcend State borders and to promote collaborative efforts to mitigate safety risks. 5.2.2 Determining what to collect 5.2.2.1 Each organization needs to determine what safety data and safety information it must collect to support the safety performance management process and make safety decisions. Safety data and safety information requirements can be determined using a top-down and/or a bottom-up approach. The chosen approach can be influenced by different considerations, such as national and local conditions and priorities, or the need to provide the data to support the monitoring of the SPIs. 5.2.2.2 Identifying and collecting the safety data should be aligned with the organization’s need to effectively manage safety. In some cases, the safety risk management process will highlight the need for additional safety data to better assess the impact (the level of probability and severity) and determine the associated risks. Equally, the safety performance management process may highlight a need for additional information for a more comprehensive understanding of a particular safety issue or to facilitate the establishment or refinement of SPIs. 5.2.2.3 Possible bias needs to be taken into account when collecting and using safety data and safety information. For example, the language used in voluntary reports can sometimes be emotive or aimed at achieving the objectives of an individual, which may not necessarily be in the best interests of the whole organization. In these cases, the information should be used judiciously. 5.2.2.4 States and service providers should consider taking an integrated approach to the collection of safety data that come from different sources, both internal and external. Integration allows organizations to get a more accurate view of their safety risks and the organization’s achievement of its safety objectives. It is worth noting that safety data and safety information that initially seems to be unrelated, may later turn out to be critical for identifying safety issues and supporting data-driven decision-making. 5.2.2.5 It is advisable to streamline the amount of safety data and safety information by identifying what specifically supports the effective management of safety within their organization. The safety data and safety information collected should support the reliable measure of the system’s performance and the assessment of known risks, as well as the identification of emerging risks, within the scope of the organization’s activities. The safety data and safety information required will be influenced by the size and complexity of the organization’s activities. 5.2.2.6 Figure 5-1 provides examples of typical safety data and safety information, which in many cases are already available. Coordination among departments or divisions is necessary to streamline efforts for reporting and collecting safety data to avoid duplication. 5.2.3 Accident and incident investigations Annex 13 requires States to establish and maintain an accident and incident database to facilitate the effective analysis of information on actual or potential safety deficiencies and to determine any preventive actions required. State authorities responsible for the implementation of the state safety program should have access to the State accident and incident database to support their safety responsibilities. Additional information on which to base preventive actions may be contained in the Final Reports on accidents and incidents that have been investigated. 5.2.4 Safety investigations by State authorities or aviation service providers 5.2.4.1 According to the provisions in Annex 13, States are required to investigate accidents, as well as serious incidents of aircraft of a maximum mass of over 2 250 kg which have occurred in their territory. These investigations are conducted by the State’s accident investigation authority (AIA) in compliance with Annex 13. The conducting of such investigations may be delegated to another State or a regional accident and incident investigation organization (RAIO) by mutual arrangement and consent. 5.2.4.2 Safety investigations outside of those mandated by Annex 13 are encouraged as they provide useful safety information to support safety performance improvement. Additional information on service provider safety investigations can be found in Chapter 9. 5.2.5 Mandatory safety reporting systems 5.2.5.1 Annex 19 requires States to establish a mandatory safety reporting system that includes, but is not limited to, the reporting of incidents. The reporting systems developed by States and service providers should be made as simple as possible to access, generate and submit mandatory reports. Mandatory safety reporting systems should aim to capture all of the valuable information about an occurrence, including: what happened, where, when and to whom the report is addressed. In addition, mandatory safety reporting systems should provide for the capture of some specific hazards which are known to contribute to accidents, the timely identification and communication of which is considered valuable (e.g. routine meteorological conditions, volcanic activity, etc.). 5.2.5.2 Regardless of the scope of the mandatory reporting system(s), it is recommended that all mandatorily collected reports be protected as per the principles detailed in Chapter 7. 5.2.5.3 Mandatory occurrence reporting systems tend to collect more technical information (e.g. hardware failures) than human performance aspects. To address the need for a greater range of safety reporting, States should also implement a voluntary safety reporting system. This aims to acquire more information, such as human factors related aspects, and enhance aviation safety. Reporting of accidents and incidents 5.2.5.4 Accident and incident reporting is relevant to every stakeholder in aviation. Operational personnel are required to report accidents and certain types of incidents as soon as possible and by the quickest means available to the State’s AIA. Serious incidents must be reported, a list of examples of incidents that are likely to be serious incidents may be found in Attachment C of Annex 13. 5.2.5.5 The following are two main aspects to consider when deciding whether an incident should be classified as a serious incident: a) Were there circumstances indicating that there was a high probability of an accident? b) Was the accident avoided only due to providence? 5.2.6 Voluntary safety reporting systems 5.2.6.1 Voluntary safety reporting systems should be established to collect safety data and safety information not captured by the mandatory safety reporting system. These reports go beyond typical incident reporting. Voluntary reports tend to illuminate latent conditions, such as inappropriate safety procedures or regulations, human error, etc. One way to identify hazards is through voluntary reporting. 5.2.6.2 States should accord protection to safety data captured by, and safety information derived from, voluntary safety reporting systems and related sources. States and service providers are advised to refer to Chapter 7 for guidance on how to apply the protection to safety data, safety information and related sources. Appropriate application of the protection will ensure the continued availability of safety data and safety information. States should also consider means to promote voluntary reporting. 5.2.7 Sector-specific safety reporting provisions Provisions for safety reporting systems continue to evolve. New sector-specific reporting requirements, such as fatigue and remotely piloted aircraft systems (RPAS), have been introduced more recently to address specific safety concerns and emerging aviation activities. Table 7 provides some examples of sector-specific reporting systems included in various Annexes, PANS and documents. 5.2.8 Self-disclosure reporting systems Service providers’ systems for the collection of safety data through self-disclosure reporting systems, including automatic data capture such as aviation safety action programme (ASAP) and FDA programmes (flight operations quality assurance (FOQA) programme, line operations safety audit (LOSA) and the normal operations safety survey (NOSS)), are examples of systems that capture safety data through direct observations of flight crews or air traffic controllers, respectively. All these systems permit recording successful system and human performance. Please see Chapter 7 for information regarding the protection of safety data and safety information captured by self-disclosure reporting systems and their sources. 5.2.9 Results of inspections, audits or surveys Results of interactions between State representatives and service providers, such as inspections, audits or surveys, can also be a useful input to the pool of safety data and safety information. The safety data and safety information from these interactions can be used as evidence of the efficacy of the surveillance programme itself. 5.2.10 Optimal safety data and safety information collection Much of the safety data and safety information used as the basis for data-driven decision-making comes from routine, everyday operations which are available from within the organization. The organization should first identify what specific question the safety data and safety information aims to answer or what problem needs to be addressed. This will help determine the appropriate source and clarify the amount of data or information needed. 5.3 TAXONOMIES 5.3.1 Safety data should ideally be categorized using taxonomies and supporting definitions so that the data can be captured and stored using meaningful terms. Common taxonomies and definitions establish a standard language, improving the quality of information and communication. The aviation community's capacity to focus on safety issues is greatly enhanced by sharing a common language. Taxonomies enable analysis and facilitate information sharing and exchange. Some examples of taxonomies include: a) Aircraft model: The organization can build a database with all models certified to operate. b) Airport: The organization may use international civil aviation organization or International Air Transport Association (IATA) codes to identify airports. c) Type of occurrence: An organization may use taxonomies developed by international civil aviation organization and other international organizations to classify occurrences. 5.3.2 There are a number of industry common aviation taxonomies. Some examples include: a) ADREP: an occurrence category taxonomy that is part of ICAO’s accident and incident reporting system. It is a compilation of attributes and the related values that allow safety trend analysis on these categories. b) Commercial Aviation Safety Team (CAST)/International Civil Aviation Organization (ICAO) Common Taxonomy Team (CICTT): tasked with developing common taxonomies and definitions for aircraft accident and incident reporting systems. c) Safety Performance Indicators Task Force (SPI-TF): tasked with developing globally harmonized metrics for service providers’ SPIs as part of their SMS, to ensure uniformity in the collection of information and comparison of analysis results. 5.3.3 An excerpt of taxonomy from the CICTT is provided in Table 8 as an example only. Example of typical taxonomy Type Operation - Aerodrome, Air Navigation Service Provider, Air Operation, Maintenance Organization, Design & Manufacturing Organization; Activity/infrastructure/system - Regulator; Value - Lack of, poor or ineffective legislation and/or regulations, Lack of or ineffective accident investigation capability, Inadequate oversight capability Type Operation - Aerodrome, Air Navigation Service Provider, Air Operation, Maintenance Organization, Design & Manufacturing Organization; Activity/infrastructure/system - Management; Value - Limited or lack of management commitment – Management do not demonstrate support for the activity, Lack of or incomplete description of roles, accountabilities and responsibilities, Limited or lack of resource availability or planning, including staffing, Lack of or ineffective policies, Incorrect or incomplete procedures including instructions, Lack of or poor management and labour relationships, Lack of or ineffective organizational structure, Poor organizational safety culture, Lack of or ineffective audit procedures, Lack of or limited resource allocation 5.3.4 Hazard taxonomies are especially important. Identification of a hazard is often the first step in the risk management process. Commencing with a commonly recognized language makes the safety data more meaningful, easier to classify and simpler to process. The structure of a hazard taxonomy may include a generic and specific component. 5.3.5 The generic component allows users to capture the nature of a hazard with a view to airport information desk in identification, analysis, and coding. A high-level taxonomy of hazards has been developed by the CICTT which classifies hazards in families of hazard types (Environmental, Technical, Organizational, and Human). 5.3.6 The specific component adds precision to the hazard definition and context. This enables more detailed risk management processing. The following criteria may be helpful when formulating hazard definitions. When naming a hazard, it should be: a) clearly identifiable; b) described in the desired (controlled) state; and c) identified using accepted names. 5.3.7 Common taxonomies may not always be available between databases. In such a case, data mapping should be used to allow the standardization of safety data and safety information based on equivalency. Using an aircraft type example, a mapping of the data could show that a “Boeing 787-8” in one database is equivalent with a “788” in another. This may not be a straightforward process as the level of detail during safety data and safety information capture may differ. Most SDCPS will be configured to assist with the standardization of data capture, easing the burden of data mapping. 5.4 SAFETY DATA PROCESSING Safety data processing refers to the manipulation of safety data to produce meaningful safety information in useful forms such as diagrams, reports, or tables. There are a number of important considerations related to safety data processing, including: data quality, aggregation, fusion, and filtering. 5.4.1 Data quality 5.4.1.1 Data quality relates to data that is clean and fit for purpose. Data quality involves the following aspects: a) cleanliness; b) relevance; c) timeliness; and d) accuracy and correctness. 5.4.1.2 Data cleansing is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data. 5.4.1.3 Relevant data is data which meets the organization’s needs and represents their most important issues. An organization should assess the relevance of data based on its needs and activities. 5.4.1.4 Safety data and safety information timeliness is a function of its currency. Data used for decisions should reflect what is happening as close to real time as possible. Judgement is often required based on the volatility of the situation. For example, data collected two years ago on an aircraft type still operating the same route, with no significant changes, may provide a timely reflection of the situation. Whereas data collected one week ago on an aircraft type no longer in service may not provide a meaningful, timely reflection of the current reality. 5.4.1.5 Data accuracy refers to values that are correct and reflect the given scenario as described. Data inaccuracy commonly occurs when users enter the wrong value or make a typographical error. This problem can be overcome by having skilled and trained data entry personnel or by having components in the application such as spell check. Data values can become inaccurate over time, also known as “data decay”. Movement is another cause of inaccurate data. As data is extracted, transformed and moved from one database to another, it may be altered to some extent, especially if the software is not robust. 5.4.2 Aggregation of safety data and safety information Data aggregation is when safety data and safety information is gathered and stored in the organization’s SDCPS and expressed in a summary form for analysis. To aggregate safety data and safety information is to collect them together, resulting in a larger data set. In the case of SDCPS, individual items of safety data are aggregated into a database without giving one piece of safety data precedence over another. A common aggregation purpose is to get information about a particular group or type of activity based on specific variables such as: location; fleet type; or professional group. Data aggregation can sometimes be helpful across multiple organizations or regions that do not have enough data to ensure proper de-identification to protect the sources of the safety data and safety information, and to support analysis. 5.4.3 Data fusion Data fusion is the process of merging multiple safety data sets to produce more coherent, linked and useful safety data than that provided by any individual set of safety data. The integration of safety data sets followed by its reduction or replacement improves the reliability and usability of said data. Thus, for example, data from FDA systems of air operators could be merged with meteorological data and radar data to obtain a more useful data set for further processing. 5.4.4 Filtering of safety data and safety information Safety data filtering refers to a wide range of strategies or solutions for refining safety data sets. This means the data sets are refined into simply what the decision-maker needs, without including other data that can be repetitive, irrelevant or even sensitive. Different types of data filters can be used to generate reports or present the data in ways that facilitate communication. 5.5 SAFETY DATA AND SAFETY INFORMATION MANAGEMENT 5.5.1 Safety data and safety information management can be defined as the development, execution and supervision of plans, policies, programmes and practices that ensure the overall integrity, availability, usability, and protection of the safety data and safety information used by the organization. 5.5.2 Safety data and safety information management which addresses the necessary functions will ensure that the organization’s safety data and safety information is collected, stored, analysed, retained and archived, as well as governed, protected and shared, as intended. Specifically, it should identify: a) what data will be collected; b) data definitions, taxonomy and formats; c) how the data will be collected, collated and integrated with other safety data and safety information sources; d) how the safety data and safety information will be stored, archived and backed up; for example, database structure, and, if an IT system, supporting architecture; e) how the safety data and safety information will be used; f) how the information is to be shared and exchanged with other parties; g) how the safety data and safety information will be protected, specific to the safety data and safety information type and source; and h) how quality will be measured and maintained. 5.5.3 Without clearly defined processes to produce safety information, an organization cannot achieve defensible, reliable, and consistent information upon which data-driven decisions are confidently made. 5.5.4 Data governance Data governance is the authority, control and decision-making over the processes and procedures that support an organization’s data management activities. It dictates how safety data and safety information are collected, analysed, used, shared and protected. Data governance ensures that the data management system(s) has the desired effect through the key characteristics of integrity, availability, usability and protection as described below. Integrity — Data integrity refers to the reliability of the sources, information, and events it contains. However, data integrity includes the maintenance and the assurance of the accuracy and consistency of data over its entire life-cycle. This is a critical aspect to the design, implementation and usage of the SDCPS when storing, processing, or retrieving the data. Availability — It should be clear who has permission to use or share the stored safety data and safety information. This has to take into account the agreement between the data/information owner and custodian. For the entities that are allowed to use the data, it should be clear how to gain access and how to process it. A variety of techniques exist to maximize data availability, including redundancy of storage locations and data access methods and tools. Usability — In order to maximize returns on safety data and safety information, it is important to also consider usability standards. Humans are continuously interacting and engaging with safety data and safety information as they are acquired. Organizations should minimize human error as automation applications are applied. Tools which can increase usability include data dictionaries and metadata repositories. As human interaction evolves towards big data applications and machine learning processes, it will become increasingly important to better understand human usability as it is applied to machines to minimize safety data and safety information miscalculations in the future. Protection — States should ensure that safety data, safety information and related sources are afforded appropriate protection. For more information refer to Chapter 7. 5.5.5 Metadata management 5.5.5.1 Metadata is defined as a set of data that describes and gives information about other data, in other words, data about data. Using metadata standards provides a common meaning or definition of the data. It ensures proper use and interpretation by owners and users, and that data is easily retrieved for analysis. 5.5.5.2 It is important that organizations catalogue their data based on its properties, including but not limited to: a) what the data is; b) where it comes from (the original source); c) who created it; d) when it was created; e) who used it; f) what it was used for; g) frequency of collection; and h) any processing or transformation. 5.5.5.3 Metadata provides a common understanding of what the data is and ensures correct use and interpretation by its owners and users. This can also identify errors in the data collection which leads to continuous improvements of the program. Chapter 6 SAFETY ANALYSIS 6.1 INTRODUCTION 6.1.1 Safety analysis is the process of applying statistical or other analytical techniques to check, examine, describe, transform, condense, evaluate and visualize safety data and safety information in order to discover useful information, suggest conclusions and support data-driven decision-making. Analysis helps organizations to generate actionable safety information in the form of statistics, graphs, maps, dashboards and presentations. Safety analysis is especially valuable for large and/or mature organization with rich safety data. Safety analysis relies on the simultaneous application of statistics, computing and operations research. The result of a safety analysis should present the safety situation in ways that enable decision makers to make data-driven safety decisions. 6.1.2 States are required to establish and maintain a process to analyse the safety data and safety information from the SDCPS and associated safety databases. One of the objectives of safety data and safety information analysis at the State level is the identification of systemic and cross-cutting hazards that might not otherwise be identified by the safety data analysis processes of individual service providers. 6.1.3 Safety analysis may be a new function the State or service provider may need to establish. It should be noted that the required competencies to conduct effective safety analysis might be outside of the purview of a traditional safety inspector. States and service providers should consider the skills necessary to analyse safety information and decide whether this role, with appropriate training, should be an extension of an existing position or whether it would be more efficient to establish a new position, outsource the role, or use a hybrid of these approaches. The decision will be driven by the plans and circumstances of each State or service provider. 6.1.4 In parallel with the human resourcing considerations should be an analysis of the existing software, and business and decision-making policies and processes. To be effective, the safety analysis should be integrated with the organization’s existing core tools, policies and processes. Once amalgamated, the ongoing development of safety intelligence should be seamless and part of the organization’s usual business practice. 6.1.5 Safety data and safety information analysis can be conducted in many ways, some requiring more robust data and analytic capabilities than others. The use of suitable tools for analysis of safety data and safety information provides a more accurate understanding of the overall situation by examining the data in ways that reveal the existing relationships, connections, patterns and trends that exist within. 6.1.6 An organization with a mature analysis capability is better able to: a) establish effective safety metrics; b) establish safety presentation capabilities (e.g. safety dashboard) for ready interpretation of safety information by decision makers; c) monitor safety performance of a given sector, organization, system or process; d) highlight safety trends, safety targets; e) alert safety decision makers, based on safety triggers; f) identify factors that cause change; g) identify connections or “correlations” between or among various factors; h) test assumptions; and i) develop predictive modelling capabilities. 6.1.7 Organizations should include a range of appropriate information sources in their safety analysis, not just “safety data”. Examples of useful additions to the data set include: weather, terrain, traffic, demographics, geography, etc. Having access to and exploiting a broader range of data sources will ensure analysts and safety decision makers are aware of the bigger picture, within which the safety decisions are made. 6.1.8 States, in particular, should be especially interested in information which identifies safety trends and hazards that cut across the aviation system. 6.2 TYPES OF ANALYSIS Analysis of safety data and safety information also allows decision makers to compare information to other groups (i.e. a control or comparison group) to help draw conclusions from the safety data. Common approaches include descriptive analysis (describing), inferential analysis (inferring) and predictive analysis (predicting), as illustrated in Figure 6-1. 6.2.1 Descriptive analysis 6.2.1.1 Descriptive statistics are used to describe or summarize data in ways that are meaningful and useful. They help describe, show or summarize data in ways so patterns can emerge from the data and help to clearly define case studies, opportunities and challenges. Descriptive techniques provide information about the data; however, they do not allow users to make conclusions beyond the analysed data or to reach conclusions regarding any hypotheses about the data. They are a way to describe the data. 6.2.1.2 Descriptive statistics are helpful because if we simply presented the risk achievement worth data, particularly in large quantities, it would be hard to visualize what the data is showing us. Descriptive statistics enable users to present and see the data in a more meaningful way, allowing simpler interpretation of the data. Tools such as tables and matrices, graphs and charts and even maps are examples of tools used for summarizing data. Descriptive statistics include measures of central tendency such as mean (average), median and mode, as well as measures of variability such as range, quartiles, minimum and maximum, frequency distributions, variance and standard deviation (SD). These summaries may either be the initial basis for describing the data as part of a more extensive statistical analysis or they may be sufficient in and of themselves for a particular investigation. 6.2.2 Inferential analysis Inferential (or inductive) statistics aim to use the data to learn about the larger population the sample of data represents. It is not always convenient or possible to examine each item of an entire population and to have access to a whole population. Inferential statistics are techniques that allow users of available data to make generalizations, inferences and conclusions about the population from which the samples were taken to describe trends. These include methods for estimating parameters, testing of statistical hypotheses, comparing the average performance of two groups on the same measure to identify differences or similarities, and identifying possible correlations and relationships among variables. 6.2.3 Predictive analysis Other types of analyses include probability or predictive analyses that extract information from historical and current data and use it to predict trends and behaviour patterns. The patterns found in the data help identify emerging risks and opportunities. Often the unknown event of interest is in the future, but predictive analysis can be applied to any type of unknown in the past, present or future. The core of predictive analysis relies on capturing relationships between variables from past occurrences and exploiting them to predict the unknown outcome. Some systems allow users to model different scenarios of risks or opportunities with different outcomes. This enables decision makers to assess the decisions they can make in the face of different unknown circumstances and to evaluate how they can effectively allocate limited resources to areas where the highest risks or best opportunities exist. 6.2.4 Combined analysis 6.2.4.1 Various types of statistical analyses are interconnected and often conducted together. For example, an inferential technique may be the main tool used to draw conclusions regarding a set of data, but descriptive statistics are also usually used and presented. Also, outputs of inferential statistics are often used as the basis for predictive analysis. 6.2.4.2 Analytical techniques can be applied to safety analysis in order to: a) identify the causes and contributing factors related to hazards and elements which are detrimental to the continuous improvement of aviation safety; b) examine areas for improvement and increase in the effectiveness of safety controls; and c) support ongoing monitoring of safety performance and trends. 6.3 REPORTING OF ANALYSIS RESULTS 6.3.1 Results of safety data analysis can highlight areas of high safety risk and assist decision makers and managers to: a) take immediate corrective actions; b) implement safety risk-based surveillance; c) define or refine safety policy or safety objectives; d) define or refine SPIs; e) define or refine SPTs; f) set SPI triggers; g) promote safety; and h) conduct further safety risk assessment. 6.3.2 The results of a safety analysis should be made available to aviation safety stakeholders in a way that can be easily understood. The results should be presented with the audience, such as organizational decision makers, external service providers, CAAs and other States, in mind. Safety analysis results may be presented several ways; the following are some examples: a) Imminent safety alerts: for the transmittal to other States or service providers of safety hazards with potential outcomes that could be catastrophic, and which require immediate actions. b) Safety analysis reports: usually present quantitative and qualitative information with a clear description of the degree and source of the uncertainty involved in the analysis findings. These reports may also include relevant safety recommendations. c) Safety conferences: for States and service providers to share safety information and safety analysis results that can promote collaborative initiatives. 6.3.3 It is helpful to translate recommendations into action plans, decisions and priorities that decision makers in the organization must consider and, if possible, to outline who needs to do what about the analysis results and by when. 6.3.4 Visualization tools such as charts, graphs, images and dashboards are simple yet effective means of presenting results of data analysis. Several examples of visual data analysis reports can be found on ICAO’s integrated Safety Trend Analysis and Reporting System (iSTARS) at https://icao.int/safety/iSTARS. 6.3.5 Safety dashboards 6.3.5.1 The safety performance of the organization should be demonstrable and should clearly indicate to all interested parties that safety is being managed effectively. One approach to demonstrating this is through a “safety dashboard”, which is a visual representation that enables senior executives, managers, and safety professionals a quick and easy way to view the organization’s safety performance. 6.3.5.2 In addition to a real time display of the organization’s SPIs and SPTs, dashboards may also include information relating to category, cause and severity of specific hazards. Ideally, the information presented on the dashboard can be customized to display the information required to support the decision-making at varying levels of the organization. The use of triggers is useful for providing basic visuals to highlight if there are any issues to be addressed for a specific indicator. Analysts and decision makers will want the ability to configure the dashboard to display their top indicators as well as a feature which allows them to delve deeper into the metrics. 6.3.5.3 Collecting and analysing the data required for effective management and decision-making is an ongoing process. The results of data analysis may reveal that more and better data must be collected and analysed in support of the actions and decisions that the organization needs to take. Figure 6-2 shows how reporting of analysis results may determine further requirements for data to be collected. 6.4 SAFETY INFORMATION SHARING AND EXCHANGE Safety can be further improved when safety information is shared or exchanged. It ensures a consistent, data-driven and transparent response to safety concerns at the global, State and organizational levels. Sharing of safety information refers to giving, while exchange refers to giving and receiving in return. 6.4.1 Sharing within the State 6.4.1.1 States should promote the establishment of safety information sharing or exchange networks among users of the aviation system, and facilitate the sharing and exchange of safety information, unless their national law provides otherwise. Safety promotion guidance for States and service providers is provided in Chapters 8 and 9, respectively. 6.4.1.2 The level of protection and conditions under which safety information will be shared or exchanged between State authorities and service providers must be consistent with national laws. Further information on the protection of safety data and safety information can be found in Chapter 7. 6.4.2 Sharing between States States should share safety information with other States as soon as possible if, in the analysis of the information contained in its SDCPS, safety matters that may be of interest to another State are identified. States are also encouraged to share safety information within their RASG. Prior to the sharing of safety information, States should ensure that the level of protection and conditions under which safety information will be shared are in line with Annex 19, Appendix 3. Detailed guidance is available in Chapter 7. 6.5 DATA-DRIVEN DECISION-MAKING 6.5.1 The primary purpose of safety analysis and safety reporting is to present a picture of the safety situation to decision makers which will empower them to make decisions based on the data presented. This is known as data-driven decision-making (also referred to as DDDM or D3M), a process-driven approach to decision-making. 6.5.2 Many aviation occurrences have resulted, at least in part, from poor management decisions, which can result in wasted money, labour and resources. The goal of safety decision makers is, in the short term, to minimize poor outcomes and achieve effective results, and in the long term, to contribute to the achievement of the organization’s safety objectives. 6.5.3 Good decision-making is not easy. Decisions are often made without being able to consider all the relevant factors. Decision makers are also subject to bias that, whether consciously or not, affects decisions made. 6.5.4 The intent of D3M is not necessarily to make the “perfect” or ideal decision, but rather to make a good decision that achieves the short-term objective (about which the actual decision is being made) and works towards satisfying the longer-term objective (improved organizational safety performance). Good decisions meet the following criteria: a) Transparent: the aviation community should know all the factors that influence a decision, including the process used to arrive at the decision. b) Accountable: the decision maker “owns” the decision and the associated outcomes. Clarity and transparency also bring about accountability – it’s not easy to hide behind a decision where roles and responsibilities are defined in detail and where expectations associated with the new decision are clearly outlined. c) Fair and objective: the decision maker is not influenced by considerations that are not relevant (e.g. monetary gain or personal relationships). d) Justifiable and defendable: the decision can be shown to be reasonable given the inputs to the decision and the process followed. e) Reproducible: given the same information that was available to the decision maker, and using the same process, another person would arrive at the same decision. f) Executable: the decision is clear enough and that clarity minimizes uncertainty. g) Pragmatic: humans are creatures of emotion, which means eliminating emotion from a decision isn't feasible. However, what can be eliminated are self-serving emotional biases. A healthy question to ask in the face of difficult decisions is: whom does the decision serve? 6.5.5 Advantages of data-driven decision-making 6.5.5.1 D3M enables decision makers to focus on desired safety outcomes which align with the safety policy and objectives, and address various aspects related to change management, safety risk assessments, etc. D3M can assist with decisions related to: a) changes that can be expected in statutory and regulatory requirements, emerging technologies or resources which may affect the organization; b) potential changes in the needs and expectations of the aviation community and interested parties; c) various priorities that need to be established and managed (e.g. strategic, operational, resources); d) new skills, competencies, tools and even change management processes that may be needed to implement new decision(s); e) risks that must be assessed, managed or minimized; f) existing services, products and processes that currently provide the most value for interested parties; and g) evolving demands for new services, products and processes. 6.5.5.2 A structured approach such as D3M drives decision makers to decisions that are aligned with what the safety data is indicating. This requires trust in the safety performance management framework; if there is confidence in the SDCPS, there will be trust in any decisions derived from them. 6.5.6 Common challenges with data-driven decision-making 6.5.6.1 Implementing processes for data collection and analysis takes time and money, as well as expertise and skills that may not be readily available to the organization. The appropriate amount of time and resources vested into the decision-making process needs to be carefully considered. Factors to consider include the amount of money involved in the decision, the extent of the influence of the decision and the decision’s safety permanence. If the organization does not understand what is involved, then the D3M process may become a source of frustration for safety decision makers, causing them to undermine or abandon the process. Like SSP, SMS, D3M and safety performance management require a commitment to build and sustain the structures and skills necessary to maximize the opportunities presented by D3M. 6.5.6.2 It is harder to build trust in data than it is to trust an expert’s input and opinion. Adopting the D3M approach requires a shift in the culture and mindset of the organization where decisions are based upon reliable SPIs and the results of other safety data analysis. 6.5.6.3 In some cases the decision-making process may become bogged down in an attempt to find the “best possible” solution, also known as “analysis paralysis”. Strategies that can be used to avoid this include: a) setting a deadline; b) having a well-defined scope and objective; and c) not aiming for a “perfect” decision or solution the first time, but rather coming up with a “suitable” and “practical” decision and improving further decisions. 6.5.7 Data-driven decision-making process 6.5.7.1 The D3M process can be a critical tool that increases the value and effectiveness of the state safety program and SMS. Effective safety management depends on making defendable and informed decisions. In turn, effective D3M relies on clearly defined safety data and information requirements, standards, collection methods, data management, analysis and sharing, all of which are components of a D3M process. Figure 6-3 illustrates shows the D3M process. Step 1 — Defining the problem or objective 6.5.7.2 The first step in planning and establishing the D3M process is to define the problem that needs to be solved or the safety objective that must be achieved. What is the question that needs to be answered? What decision must the safety decision makers make? How will it align with the more strategic organizational objectives? In the process of defining the problem statement, decision makers should ask themselves the following questions: a) Does the collection and analysis of data support and relate to the organization’s safety objectives or safety targets? b) Is the required data available? Or can it be obtained in a reasonable manner? c) Is it practical and feasible to collect and analyse the data? d) Are the required resources (people, equipment, software, funds) available? 6.5.7.3 In the safety management context, the main problem statements within the organization are related to evaluating and selecting safety priorities – in alignment with the safety objectives – and establishing measures for safety risk mitigation. Step 2 — Access to data to support the decision-making 6.5.7.4 The next step is to identify what data is needed to answer the problem (taking into account the provisions on information protection). No data is any more valuable than other data. Focus should be on whether the available data is appropriate to help answer and resolve the problem. If the data required is available, proceed to step 4. If the right data is not available, the organization will need to collect, store, analyse and present new safety data and safety information in meaningful ways. Step 3 — Request data to support the decision-making 6.5.7.5 If the data isn’t already available, the organization needs to find ways of collecting it. This may mean establishing another SPI and perhaps aligned SPTs. Establishing additional indicators can come at a cost. Once the cost is known, the organization should estimate if the benefits outweigh those costs. The focus should primarily be on identifying, monitoring and measuring safety data that is needed to make effective data-driven safety decisions. If the costs outweigh the benefits, consider alternative data sources and/or indicators. 6.5.7.6 In the planning phase of the D3M process, the organization must define what it wants to achieve by establishing the SPTs and SPIs, and analysing the data. Why does the organization need to address the identified problem? What is a reasonable target? And how and where will safety decision makers use the results of data collection and analysis? Having a clear understanding of why the organization needs to collect, analyse, share and exchange safety data and information is fundamental for any SDCPS. 6.5.7.7 The following elements combine to enable an organization to identify trends, make informed decisions, evaluate the safety performance in relation to defined objectives, assess risks or fulfil its requirements: a) safety performance management - as the safety data and safety information governance framework; b) SDCPS - as the safety data collection and processing functionality; and c) D3M as a dependable decision-making process. Step 4 — Interpret results of data analysis and make data-driven decision 6.5.7.8 The data gathered must be presented to the decision makers at the right time and in meaningful ways. The appropriateness and size of the data sets, the sophistication of the analytics and the skills of the data analysts will only be effective if the data is presented when needed and in formats that make it easy for decision makers to comprehend. The insights gained from the data should inform decision-making, and ultimately, improve safety performance. 6.5.7.9 There are many decision-making models available. Using an agreed and standardized approach will maximize consistency and effectiveness of the organization’s data-driven decisions, most include the following steps: a) assemble a team/group with the necessary skills and experience (e.g. safety action group (SAG)); b) clearly define the safety problem or objective and the context; c) review the organization’s SPTs and safety objectives to ensure continued alignment; d) review and interpret the safety data to understand what it is indicating; e) consider and analyse the viable alternatives; f) consider the risk of feasible actions (or inactions); g) gain consensus among the decision-making group; h) commit to the data-driven decision and act on the decision (turning data into action); and i) monitor and evaluate the outcomes. Step 5 — Communicate the decision 6.5.7.10 For the safety decision to be effective, it needs to be communicated to stakeholders, these include: a) staff required to enact the necessary actions; b) person who reported the situation (if required); c) all personnel, to ensure they are kept informed of safety improvements (safety promotion; States refer to chapter 8; service providers refer to chapter 9); and d) organizational knowledge managers to ensure the safety decision is incorporated into the learning of the organization. 6.5.7.11 For more information on safety communications, refer to 8.6 for States and 9.6 for service providers. Chapter 7 PROTECTION OF SAFETY DATA, SAFETY INFORMATION AND RELATED SOURCES 7.1 OBJECTIVES AND CONTENT 7.1.1 This chapter describes the basic principles governing the protection of safety data and safety information captured by or derived from safety reporting systems, as well as the sources of such data and information.1 It also provides guidance and advice on the implementation of these principles by State aviation regulatory authorities, service providers, legislators, lawyers, prosecutors, judicial officers and other competent authorities with responsibility for making decisions about the use and protection of safety data, safety information and their related sources. This chapter may be of use to any other persons seeking access to, or the disclosure of, safety data or safety information. 7.1.2 The chapter includes the following topics: a) fundamental principles; b) scope and level of protection; c) principles of protection; d) principles of exception; e) public disclosure; f) protection of recorded data; and g) safety information exchange and sharing. 7.2 FUNDAMENTAL PRINCIPLES 7.2.1 The objective of protecting safety data, safety information and their related sources is to ensure their continued availability, with a view to using it for maintaining or improving aviation safety, while encouraging individuals and organizations to report safety data and safety information. In this context, the importance of implementing protections cannot be overstated. The protections are not intended to relieve sources of their safety related obligations or interfere with the proper administration of justice. 7.2.2 Aviation safety is not the sole responsibility of States or service providers. It is a shared responsibility to which all stakeholders should contribute by, among other things, providing relevant data and information through safety reports. 7.2.3 While data and information can come from various sources, reporting of safety data and safety information by individuals and organizations in the aviation system is fundamental to safety management. Effective safety reporting systems help to ensure that people are and remain willing to report their errors and experiences, so that States and service providers have access to the relevant data and information necessary to address existing and potential safety deficiencies and hazards. This assurance is provided by creating an environment in which people can be confident that safety data and safety information will be used exclusively for maintaining and improving safety, unless one of the principles of exception applies. 7.2.4 Annex 19 does not provide protection to individuals or organizations mentioned in the report. However, States can extend the protection to individuals or organizations mentioned in the report. 7.2.5 It is important that both individuals and organizations are protected, as well as the safety data and safety information they report. Individuals and organizations are protected by: a) ensuring they are not punished on the basis of their report; and b) limiting the use of reported safety data and safety information to purposes aimed at maintaining or improving safety. These protections apply unless one of the principles of exception discussed below is applicable. 7.2.6 Annex 19 requires States to ensure that safety data and safety information are not used for the purposes other than those set out in the principles of protection unless a principle of exception applies. The principles of exception set out the circumstances in which a departure from those protective principles may be permissible. 7.2.7 Preventive, corrective or remedial action, based on reported safety data and safety information, may necessarily be taken by States and service providers for the purposes of maintaining or improving safety — that is, to allow States and service providers to take appropriate steps to: a) guard against the potential for immediate harm or injury as a result of a safety risk until that risk can be identified and mitigated; b) ensure that appropriate action is taken to minimize the likelihood that such a risk might occur again in the future; c) prevent exposure to an unmitigated safety risk; or d) ensure the integrity of the reporting system itself and the larger system of which the reporting system is a part. 7.2.8 Because such actions are fundamental to the objectives and efficacy of any safety management system, Annex 19 expressly provides that preventive, corrective or remedial action to maintain or improve aviation safety shall not be prevented. Such actions may be taken as a function of applicable safety management processes and are therefore not subject to the principles of exception set out in Annex 19. 7.2.9 Preventive, corrective or remedial action may entail restricting, limiting or preventing2 the exercise of certain privileges3, the performance of services or the operation of aircraft, until the safety risks identified have been effectively addressed. When taken for these purposes, under established protocols, protective or precautionary actions are not to be regarded as punitive or disciplinary. The purpose of such actions is to prevent or minimize the exposure to an unmitigated safety risk. 7.2.10 The principles related to the protection of safety data and safety information, and of their sources, contained in Annex 19 provide for more clarity and transparency, as well as a level playing field, with a view to facilitating the exchange of safety data and safety information between States as required by Annex 19. 7.3 SCOPE OF PROTECTION 7.3.1 Scope of safety data and safety information covered by the principles of protection 7.3.1.1 Protection applies to safety data captured by, and safety information derived from, voluntary safety reporting systems and related sources. This may apply to mandatory safety reporting systems where it is applicable (refer to 7.4.3 below). Sources of safety data and safety information can be individuals or organizations. 7.3.1.2 In some States, safety reporting systems may include the reporting of data to safety investigations by State authorities or aviation service providers, data and information captured by self-disclosure reporting systems (including automatic data capture systems and manual data capture systems) or other relevant safety data and information. The principles of protection and exception therefore may be extended to safety data and safety information captured by those systems as well. 7.3.1.3 There are other cases when the principles of protection and exception will apply. For example, Annex 6 — Operation of Aircraft, Part I — International Commercial Air Transport – Aeroplanes provides that sources of flight data analysis (FDA) programmes should be protected in accordance with the principles contained in Annex 19. 7.3.1.4 The type of safety data and safety information that can be captured by, and the kinds of systems that can be part of, safety reporting systems may evolve over time along with the evolution of safety management systems themselves. Safety data, safety information and safety reporting systems that are not expressly identified in Annex 19 today may be governed by Annex 19 in the future. 7.3.2 Interaction with the principles of protection contained in other Annexes 7.3.2.1 Certain types of safety data and safety information that are protected under Annex 19 may, in certain circumstances, be subject to other protection requirements. 7.3.2.2 In particular, Annex 19 specifies that when an investigation under Annex 13 has been instituted, accident and incident investigation records listed in Annex 13 are subject to the protections accorded in Annex 13, not those in Annex 19. 7.3.2.3 This principle applies from the time an accident or incident under Annex 13 occurs and remains applicable even after the publication of the Final Report. Guidance on protection of accident and incident investigation records is provided in the Manual on Protection of Safety Information (Doc 10053). 7.3.2.4 Similarly, while Annex 19 provides protection to recorded data when it is used for safety management purposes, Annex 6 affords protection to the flight recorder recordings in normal operations, outside of Annex 13-type investigations. 7.3.2.5 Annex 6 addresses the use of cockpit voice recorders (CVRs) and airborne image recorders (AIRs) which should be limited to safety-related purposes with appropriate safeguards for inspections of flight recorder systems, or when associated recordings or transcripts are sought for criminal proceedings. Such criminal proceedings are introduced into the amendment as an exception to the protections accorded to CVRs and AIRs in order to allow competent authorities to access and use these types of recordings and their transcripts without restriction in cases where criminal offences are committed and crew members involved may not have consented to such use (e.g. cases of hijacking). 7.3.2.6 Likewise, the use of flight data recorders (FDRs), aircraft data recording systems (ADRS) as well as Class B and C AIR and airborne image recording systems (AIRS) should be limited to airworthiness or maintenance purposes, including FDA programmes, with appropriate protections accorded by Annex 19. 7.3.2.7 Figure 7-1 provides general guidelines regarding the interaction between the protective frameworks in Annexes 6, 13 and 19 and is meant to be used in consultation with applicable provisions. 7.3.2.8 With respect to FDA programmes, the sources remain, in any situation, protected by the principles contained in Annex 19. 7.3.3 Application of Annex 19 principles to service providers 7.3.3.1 Annex 19 describes a reporting environment that fosters trust as an environment “where employees and operational personnel may trust that their actions or omissions that are commensurate with their training and experience will not be punished”. An action or omission is commensurate with a person’s training and experience where it is reasonable to anticipate that a person with the same level of experience and training might do, or fail to do, the same thing. Such an environment is fundamental to effective and efficient safety reporting. 7.3.3.2 Encouraging people to report relevant safety data or safety information requires that the sources of those reports are protected from actions taken by a State in accordance with Annex 19, as well as from actions taken within their working environment. 7.3.3.3 The Annex provisions are designed to provide the minimum requirements to be met by all States, regardless of the size and complexity of their civil aviation activities. Individual States are responsible for developing requirements sufficient to ensure satisfactory compliance by the State and its service providers. 7.3.3.4 The principles of protection and exception applied to safety data, safety information and related sources under Annex 19 should be implemented by States and service providers alike. To ensure the achievement of this objective, States are expected to adopt relevant national laws, regulations and policies to ensure that their service providers implement the provisions contained in Annex 19. 7.4 LEVEL OF PROTECTION 7.4.1 Conditions to qualify for protection under Annex 19 7.4.1.1 Annex 19 requires States to determine the conditions under which safety data and safety information qualify for protection. In doing so, States are expected to consider whether: a) safety data or safety information is covered under the scope of Annex 19; b) there are circumstances under which Annex 6 or Annex 13 would take precedence over Annex 19; and c) a principle of exception applies. 7.4.2 Actions necessary for maintaining or improving aviation safety 7.4.2.1 Annex 19 ensures that States and service providers are not prevented from using safety data or safety information to take any preventive, corrective, or remedial action that is necessary to maintain or improve aviation safety. Consistent with that objective, such action, when taken, should avoid wherever possible financial, reputational or other adverse impacts on the source of the safety data or safety information. 7.4.2.2 Preventive, corrective or remedial action aims to address circumstances or conditions that present unacceptable risks to aviation safety. 7.4.2.3 Preventive action may be understood to involve action taken to prevent the occurrence or recurrence of an event or a hazard that poses a risk to safety. 7.4.2.4 Corrective action may be understood to involve action taken to address particular safety-related shortcomings or deficiencies, such as an authorization holder who is unable to demonstrate compliance with applicable safety or competency standards. Corrective action may be necessary to bring an authorization holder back into compliance. 7.4.2.5 Remedial action may be understood to involve action taken to address the underlying causes of particular safety-related shortcomings or deficiencies, such as training. Remedial action might also involve restricting, limiting, suspending or revoking the privileges of an authorization, certificate or licence holder who fails to continue to meet the necessary qualifications to exercise those privileges. 7.4.2.6 Although they may be specified as serving one or another purpose, such actions may serve more than one purpose. For example, action may be taken by a regulator or a service provider, requiring the holder of a licence or certificate to undertake additional training, and to refrain from exercising the privileges of that licence or certificate until such training is successfully completed. Action may also be taken by a regulator to revoke, remove or suspend certain privileges of an organization’s certificate. Such actions, while remedial because they address the underlying cause of a safety issue, may also be considered corrective because they address a particular deficiency. Regardless of the characterization of the action taken, there should be a clear and demonstrable link between the particular action taken and the maintenance or improvement of safety. 7.4.2.7 Safety data or safety information might reveal hazards or deficiencies that necessitate remedial or corrective action to maintain safety or identify areas where preventive action would enhance aviation safety by addressing potential or emerging risks. To substantiate the underlying condition or hazard warranting the preventive, corrective, or remedial action, States may need to use the safety data or safety information. For example, safety data and safety information may be necessary to establish the basis for an administrative licence action or satisfy requisite burdens of proof. Or, safety data and safety information may be necessary to establish the need for additional training of a licensee or changes to an operator’s systems. It may also be necessary to use safety data or safety information to ensure the integrity and proper operation of the reporting system, and the larger system of which the reporting system is a part. 7.4.2.8 Depending on the circumstances, preventive, corrective or remedial actions, while not intended to be, may be perceived as punitive by the individual or the service provider subject to such action. Indeed, some may view any licence actions taken to address competency deficiencies as punitive, rather than an action necessary to correct or remediate a risk to safety. 7.4.2.9 Despite these perceptions, Annex 19 does not prevent States from using safety data and safety information to support action necessary to maintain or improve aviation safety. Where actions are needed to maintain or improve the level of aviation safety or to prevent the safety of the aviation system from deteriorating in the short term or over a longer term, States may use safety data or safety information to support those actions, provided that they have a demonstrably preventive, corrective or remedial objective and effect. In such cases, States should consider taking the necessary measures to clearly communicate the rationale behind the action taken, in order to demonstrate the safety purpose and minimize any adverse impact on future reporting. On the other hand, the use of safety data and safety information to take actions that cannot be shown to serve one or more of these purposes, and which can be shown instead to have a purely punitive or disciplinary objective and effect, should be prohibited, unless one of the principles of exception applies. 7.4.3 Protection of mandatory reporting systems 7.4.3.1 Annex 19 specifies different requirements for the protection of safety data, safety information and related sources captured by voluntary and mandatory safety reporting systems. Protecting safety data and safety information captured by voluntary safety reporting systems is a Standard, to ensure the continued availability and greater uniformity among States, whereas for mandatory safety reporting systems the provision of such protection is a Recommended Practice. 7.4.3.2 In certain jurisdictions, safety data and safety information captured by mandatory and voluntary safety reporting systems are subject to different levels of protection, offering greater protection to safety data and safety information from voluntary systems compared to safety data and safety information from mandatory ones. This distinction can be justified by the need to incentivize the voluntary provision of safety data or safety information in ways that are not seen to be necessary in the case of a mandatory reporting system. 7.4.3.3 Other States offer the same high level of protection to safety data and safety information in both mandatory and voluntary safety reporting systems. This can be justified by the recognition that requiring reporting by law may not, in itself, be sufficient to ensure that relevant safety data and safety information are reported and that the value of a trustworthy environment is fundamental to any kind of reporting. Extending protections to mandatory reporting systems may also encourage reporters to supply additional details that they may otherwise not provide if those protections were not available. 7.4.3.4 If a State extends the protection afforded to safety data and safety information captured by voluntary safety reporting systems to mandatory safety reporting systems, the principles of protection and exception contained in Annex 19 should apply to safety data and safety information captured by both of those systems as well as to their respective sources. 7.4.4 Protection of data and information in the public domain 7.4.4.1 There may be cases in which safety data or safety information is available in the public domain. In some cases, it may be that such safety data or safety information is not sensitive and its further disclosure will not adversely impact the continued availability of safety data or safety information. Safety data and safety information related to weather may be an example of such non-sensitive data and information. 7.4.4.2 In other cases, safety data and safety information normally subject to the principles of protection may find its way into the public domain, for instance, through a leak to the media. In such cases, States should refrain from further disclosure of the leaked data and information as the principles of protection will not be automatically waived. 7.5 PRINCIPLES OF PROTECTION 7.5.1 Application of the principles of protection 7.5.1.1 The protection of safety data, safety information and related sources should be the default position for a State. A State may provide effective protection by law, supported by comprehensive and clear procedures. 7.5.1.2 The basic purpose of providing protection is to ensure the continued availability of safety data and safety information by encouraging individuals and organizations to identify, report, analyse and correct deficiencies. This requires that all involved know the governing rules and processes for protection in advance. Such rules and processes should be formalized, and they should not be open to arbitrary application if they are to serve as the foundation of a system based on trust. 7.5.1.3 In protecting safety data or safety information, consideration should be given to the objective such protection is meant to achieve. The objective may be evident from the type of data and information to be protected. In many cases, protection aims to prevent safety data and safety information from being used against the individual or organization that reported the specific data or information. In other cases, it may be important to shield safety data or safety information from general publication or use in non-safety related contexts, such as local land use controversies concerning airport operations and noise abatement issues. 7.5.1.4 State action is central to creating protective provisions. In formal proceedings where there are rules governing what evidence is allowed to be presented, only State action can provide the necessary protection by the enactment of appropriate legislation or regulations that either prohibit or strictly limit admissibility of protected information. For example, in criminal proceedings against an individual, the use of a voluntary report filed by the accused person should be prohibited if it is not directly related to the alleged criminal act. 7.5.1.5 In civil proceedings against a service provider, a rule should, at a minimum, require a rebuttable presumption4 that protected information may not be used. In an action against an airline for damages sustained as a result of an occurrence, a plaintiff may seek general access to the operator’s safety management system files to attempt to discover general information that might not be directly related to the incident, but which might tend to cast the operator in an unfavourable light. The established procedure for determining such questions should direct the competent authority (in this case most likely a court) that is tasked with applying the principles of exception, (discussed more fully in 7.6) to require the plaintiff to show precisely what information is intended to be discovered and to demonstrate the relevance of the information to the action, as well as demonstrating the unavailability of alternative sources for the same or similar information. The competent authority might also ask a plaintiff to show how they are prejudiced by not having access to the information. Where the decision is to allow such access, formal safeguards should be imposed by the competent authority in accordance with applicable procedural requirements, such as a protective order to preclude publication generally and restricting access to the relevant portions of the proceedings. 7.5.1.6 In administrative proceedings where particular operational or technical qualifications, competencies and capabilities of an individual or an organization are in question, safety will almost invariably be at issue. Use of safety data or safety information may be required in such cases, but enforceable requirements should provide for the controlled and limited use of such data and information. Where safety data or safety information provide the basis for decision in such safety-related cases, extraordinary care should be required to prevent adverse or prejudicial consequences to the source of the information as a result of the use of said data and information. Generally, individuals and organizations who are encouraged to report under a protected reporting scheme will recognize that there are circumstances in which action in the interest of safety must be taken, based, in whole or in part, on a protected report. Enforceable requirements should ensure that such action complies with fundamental fairness in pursuit of the objective of maintaining or improving safety. 7.5.1.7 An example of such a situation might be a report by an air traffic controller who lost consciousness for a short period of time while working. No separation was lost and the only proof that the event occurred was the controller’s own report. For safety-related purposes, analysis of that report required further investigation, which in turn required that the reporting individual be identifiable by some process. Immediate correction might involve removal of the controller from active duty (without financial or reputational disadvantage) while a comprehensive medical examination and review is conducted. Upon completion of the medical review, the result may entail medical clearance, medical treatment or medical retirement (again, without financial or reputational disadvantage). If the controller were simply discharged, it is highly unlikely that similar reports from others would be forthcoming in the future. 7.5.1.8 Up to this point, the focus has been on direct State action to provide necessary and appropriate protection. In practice, much of the safety data and safety information for which protection is required is within the operational environment of a service provider and involves relations between employers and employees. Protection in these situations may not always be provided for in legislation or other forms of enforceable State requirements. Even in such cases, however, States may be in a position to require effective protection through their certification, approval and continuing surveillance processes. Annex 19 requires specified service providers to implement an effective SMS. Effective safety management is based on data collection, analysis and protection. Without data the system would lose effectiveness. The state safety program should allow States to direct organizations to implement policies that provide protection to their employees as an element of their SMS. 7.5.1.9 One way of providing for such protection might involve de-identification of the reporter. While confidentiality of reports is a useful strategy, complete de-identification, where possible, removes the opportunity for follow-up during the analysis phase. Policies should focus on what use the competent authority may make of, and allow for, the safety data and safety information in question. The discussion above (refer to 7.5.1.6) in relation to administrative proceedings is equally applicable in the employer/employee context. Again, those from whom reports are necessary will be reluctant to provide such reports if those reports, or other data or data capture, are used to support a punitive or disciplinary suspension or discharge. 7.5.1.10 The capture of safety data and safety information by automatic means, such as FDRs, voice or video recorders, or air traffic environment recorders, should be part of any protection policy or regulation. Use of these devices as a part of safety management system data capture where allowed by regulation or policy must fully respect the principles of protection in the same way voluntarily submitted reports are respected. The trust of the reporting population is fundamental to effective safety management. 7.5.2 Proceedings 7.5.2.1 Annex 19 requires States to ensure that safety data and safety information are not used in disciplinary, civil, administrative and criminal proceedings against employees, operational personnel or organizations, unless a principle of exception applies. 7.5.2.2 The term “proceeding” may be more comprehensive and broader in scope than the term “action”. It may also refer rather more narrowly to the processes of a particular body to review or enforce “actions” that have been taken by another authority (or an agency within the same authority). In a general sense, the terms “proceeding” and “action” may be understood to encompass all the steps taken or measures adopted in order to initiate, give effect to, or review a decision of an authority affecting a person’s rights, privileges, legitimate interests or reasonable expectations (as these may be identified under applicable laws). In view of different legal systems, the nature and scope of particular actions or proceedings may vary. For example, in some States: a) Criminal and civil actions or proceedings usually involve judicial authorities. These proceedings may include the commencement of the action, the appearance of the defendant, all ancillary or provisional steps, the pleadings, the trial discovery processes and other formal inquiries. As a consequence of such actions or proceedings, a person may be subject to monetary damages, fines or in some cases incarceration. b) Administrative actions or proceedings may involve an inquiry, investigation or hearing before a regulator or a tribunal that relates to action to vary, suspend, revoke or cancel an authorization (for demonstrably safety-related purposes in some cases, and for punitive purposes in others). c) Disciplinary actions or proceedings may refer to the process by which an employer responds to actual or apparent violations or breaches of rules and procedures by an employee. The result of such actions or proceedings may be to absolve an employee of the alleged misconduct, or to discipline or discharge an employee if the allegations are substantiated. 7.5.2.3 Other authorities may be involved in the actions and proceedings mentioned above, such as administrative tribunals, professional, ethical bodies or other review bodies within an organization. 7.5.2.4 It is important to remember that the principles of protection do not apply when States take a preventive, corrective or remedial action that is necessary to maintain or improve aviation safety (refer to 7.4.2 above). This also applies to any proceeding, action or measure associated with a preventive, corrective or remedial action taken for purposes of maintaining or improving safety. For example, the use of safety data or safety information to justify the adoption of a preventive, corrective or remedial action is allowed in proceedings initiated by an individual or an organization seeking to challenge the said action. 7.5.2.5 While there may be cases when safety data or safety information is used in litigation initiated by a third party against the source of the report, States are encouraged to take all necessary measures to ensure that safety data and safety information are not used for purposes other than maintaining or improving aviation safety (unless a principle of exception applies). 7.5.3 Authoritative safeguards 7.5.3.1 Certain factors may mitigate the negative consequences associated with the disclosure or use of safety data or safety information for purposes other than maintaining or improving aviation safety. It might be possible to limit any potential damage from the proposed disclosure or use by putting in place safeguards to further limit the disclosure or use of safety data and safety information. A State may include in its legislation or regulations, pursuant to which the application of the principles of exception is considered, the power for the competent authority to impose requirements for the safety data or safety information to be kept confidential following a decision to allow access. 7.5.3.2 De-identification of the source of the safety data and safety information is another safeguard that may be used before release for purposes other than maintaining or improving aviation safety is granted by a competent authority. De-identification may, however, be difficult where the sources providing the safety data or safety information may be readily ascertainable from the substance of the data or information reported. For example, the report of an occurrence involving a type of aircraft that is used only by a single operator within a particular jurisdiction may immediately point to that operator (or even to an individual employee) simply by identifying the type of aircraft involved. In such cases, how and where the safety data or safety information is proposed to be disclosed or used, and the nature of the information involved, would be of especial significance. 7.5.3.3 If the safety data or safety information is proposed to be used in a forum where knowledge of the persons or organizations connected to the data or information is limited, then the competent authority might be confident that deidentification would provide a sufficient safeguard for the sources. Similarly, if the nature of the information is primarily technical, then there may not be much identifying information in the safety data or safety information that needs to be removed or redacted, making the protective task more easily achievable. The competent authority should also consider whether the forum of the proposed disclosure, or use of the data or information and the nature of the information, will affect the degree to which the sources can be identified, and whether removing identifying information would be enough. If the proposed disclosure or use may adversely affect an organization or a company, such as an aircraft operator, then the competent authority should decide whether de-identification of the data or information would provide reasonable protection similar to that which the company or operator would have obtained if the disclosure or use had not been allowed. 7.5.3.4 If the competent authority considers that the de-identification of safety data and safety information may prevent the intended or otherwise permissible use of safety data or safety information, de-identification will not be appropriate. Therefore, States may opt to implement different kinds of safeguards (or combinations of safeguards) to allow limited disclosure for a specific purpose while preventing wider use or public disclosure of the safety data or safety information. Protective orders, closed proceedings, in camera review and summaries are examples of such safeguards. 7.5.3.5 States and organizations may also adopt best practices, such as ensuring that the environment in which information is collected, stored, processed and transmitted is sufficiently secure, and that controls over access and authorization are sufficient to protect safety data and safety information. 7.6 PRINCIPLES OF EXCEPTION The principles of protection apply to safety data, safety information and related sources, unless a competent authority determines that one of three principles of exception applies. The custodian of SDCPS should be aware of the protections applied to safety data, safety information and related sources and ensure that they are released and used in accordance with Annex 19 provisions. 7.6.2 Designation of a competent authority 7.6.2.1 As the principles of exception will be administered for a range of different purposes, the competent authority will be different depending on the nature of the data or information in question and the type of use that is being sought. In each particular case, the task of the competent authority will be to decide whether a particular principle of exception applies. The competent authority will need to be capable of balancing competing interests, such as right-toknow laws, regulations unrelated to aviation safety, litigation disclosure rules and others in order for the public to have confidence in its decision-making capabilities. Competent authorities could include judicial authorities, regulatory authorities or others entrusted with aviation responsibilities designated in accordance with national laws and other enforceable requirements. 7.6.2.2 States and organizations will need to identify competent authorities appropriate to the task of applying the principles of exception for different purposes. Table 9 below provides examples of possible competent authorities and situation examples. 7.6.2.3 Where an organization identifies its competent authority, the responsible exercise of discretion of the competent authority on the application of the principles of exception and the principles of protection may well provide sufficient self-policing within the organization. The final determination of the competent authority for each specific purpose remains a matter for each State and organization, depending on the applicable laws and policies. 7.6.2.4 Permanent designation of the office and jurisdiction of the competent authority (e.g., judicial authorities for matters involving litigation, the civil aviation authority for matters involving regulatory actions) may be considered to allow for expeditious decision-making. A permanent designation will also provide certainty in the competent authority’s standing and experience in dealing with these matters. Furthermore, it is critical that the competent authority has in place rules and procedures governing the decision-making process. These rules and procedures should flow from applicable national laws. This can only be achieved if the designation of the competent authority in a particular area remains constant. 7.6.3 Application of the principles of exception 7.6.3.1 The first case in which a competent authority may determine that an exception to the protection applies is where there are “facts and circumstances reasonably indicating that the occurrence may have been caused by an act or omission considered, in accordance with national laws, to be conduct constituting gross negligence, wilful misconduct or criminal activity”. The appropriate competent authority for undertaking such a determination will, in most cases, be a judicial, administrative or prosecutorial authority. 7.6.3.2 Because an assessment of the substance of the safety data or safety information in question will often determine whether the conduct involved satisfies one or another of the conditions for exceptional use, it is not, therefore, necessary that facts and circumstances of the case make it unequivocally clear that such exceptional conduct has occurred. Rather, it is only necessary that those facts and circumstances provide a reasonable basis on which it could be found that the occurrence may have been caused by such conduct. Where the competent authority determines that, on the basis of the facts and circumstances of a case, an occurrence may have been the result of either gross negligence, wilful misconduct or criminal activity — as these terms are understood under national law — a principle of exception applies and the safety data, safety information or related sources may be released. 7.6.3.3 Different legal systems may have different understandings under national law as to what is meant by these terms. In general, gross negligence refers to an act or omission undertaken with a serious disregard or indifference to an obvious risk, regardless of whether the risk was fully appreciated by the actor. This is sometimes described as reckless conduct. Wilful misconduct is a wrongful act or omission which the actor either knows to be wrongful, or is consciously indifferent to the question of whether it is wrongful or not. Knowledge and intent in such cases may also sometimes have regard to the consequences of the conduct, as opposed to its formal depiction as unlawful. In any case, the evidentiary tests and measures applicable in making a determination as to the nature of the conduct involved should be consistent with the laws of the relevant jurisdiction. Also, because the exception principle differentiates between conduct constituting “gross negligence” or “wilful misconduct”, on the one hand, and “criminal activity” on the other, it is clear that conduct that might constitute either “gross negligence” or “wilful misconduct” (however such conduct may be described under the applicable national law) is meant to be assessed on the basis of a civil, as opposed to a criminal, standard. 7.6.3.4 The second case in which a competent authority may determine that an exception to the protection rule applies is where, having reviewed the safety data or safety information in question, the competent authority determines that release of such data or information is “necessary for the proper administration of justice” and “the benefits of its release outweighs the adverse domestic and international impact such release is likely to have on the future collection and availability of safety data and safety information”. 7.6.3.5 This involves a two-step assessment process, in which the competent authority must consider first, whether the data or information is “necessary for the proper administration of justice”, which may not be the case if alternative sources for the same information are available; and second, if it finds that the release is necessary for the proper administration of justice, whether, on balance, the value of such data or information outweighs the prejudice its release is likely to have on the future collection and availability of safety data and safety information for the purposes of maintaining or improving safety. 7.6.3.6 If the safety data or safety information is proposed for use in an action or proceeding (civil, administrative, criminal or disciplinary), then the potential negative impact of such use may relate to the source of such data or information. Even if safeguards can be put in place to prevent the safety data or safety information from being disclosed outside the confines of the action or proceeding, any negative impact from the use of such data or information during a proceeding may still discourage future reporting or disclosure of safety data and safety information for the purposes of maintaining or improving safety. If the proposed use of the safety data or safety information involves dissemination or publication of such data or information beyond the confines of the proceeding, the competent authority should also consider the potential prejudicial effect on the wider community (domestic and international). 7.6.3.7 On the individual level, making the information public can have prejudicial detriment to the person involved, such as embarrassment and/or the potential loss of livelihood. On a broader level, the publication or dissemination of safety data or safety information in a particular case may create a general disincentive for people similarly situated, but not involved in the particular action or proceeding, to report or contribute to the collection of such data and information. 7.6.3.8 In making a determination regarding the first two principles of exception, the competent authority must be satisfied, that: a) in the first case, the content of the safety data or safety information sought to be disclosed or used is necessary in order to decide whether the act or omission constitutes gross negligence, wilful misconduct or criminal activity; or b) in the second case, that such data, information or the related source is necessary for the proper administration of justice. 7.6.3.9 The competent authority will determine whether the safety data, safety information or the identity of the source of such data or information is necessary to the case. If a competent authority can reasonably make a decision without referring to the protected data, information or source, then greater weight must be given to preserving the protection of the safety data, safety information and related sources. There is no need to prejudice the collection and availability of safety data, safety information and related sources when a decision can be made by the competent authority without requiring the disclosure (or use) of such data and information. This will help ensure the continued availability of safety data and safety information for maintaining or improving aviation safety. 7.6.3.10 Adverse consequences might flow from the disclosure or use of safety data, safety information and related sources, such as the reluctance of aviation operational personnel to willingly cooperate with inspectors. If such data, information or details about their sources are not necessary to prove an essential fact in a proceeding, then the future collection and availability of safety data, safety information and related sources should not be jeopardized by unnecessary release under either of these principles of exception. Furthermore, if the required information can practicably be obtained from alternate sources, the competent authority might decide against allowing access to the safety data or safety information until all reasonable alternative avenues to acquire the information have been exhausted. 7.6.3.11 Similarly, if a competent authority in a State that does not have a right-to-know law is asked to decide whether the safety data or safety information should be disclosed to the public (for example, in response to a request from the media), the competent authority would most likely want to know how important it is that the public knows the contents of such data or information. In such a situation, the competent authority might ask a question like, “Without knowing the contents of the data or information, would the public have a proper understanding of the occurrence, or would the event have safety consequences for the travelling public?” Being able to substantiate a view that the public’s knowledge would be compromised without access to the safety data or safety information might give weight to an argument for its disclosure. However, this data or information would not have to be disclosed just because these grounds are established. If disclosure would seriously compromise the continued availability of safety data and safety information by discouraging future safety reporting, the scales may not necessarily be tipped in favour of disclosure. 7.6.3.12 The third exception involves cases in which, “after reviewing the safety data or safety information,” the competent authority “determines that its release is necessary for maintaining or improving safety, and that the benefits of its release outweigh the adverse domestic and international impact such release is likely to have on the future collection and availability of safety data and safety information”. This exception applies to the release of safety data or safety information necessary for maintaining or improving safety. It has no application to the use of safety data or safety information in connection with preventive, corrective or remedial action taken by a regulatory authority that is necessary to maintain or improve aviation safety. 7.6.3.13 The circumstances contemplated by Annex 19 involve consideration by a competent authority of the benefits of releasing safety data or safety information for more general purposes related to the maintenance or improvement of safety, including, for example, training and educational purposes or the publication of safety information and advice for the benefit of the wider community. The analysis for these situations involves the same kind of two-step process described in 7.6.3.5 above: first, requiring the competent authority to decide that the “release is necessary for maintaining or improving safety”, and, second, requiring the competent authority to determine that the benefits of releasing the safety data or safety information outweigh the potential adverse impact such a release will have on the future collection and availability of such data and information. 7.6.3.14 In considering the second step of this analysis, Annex 19 encourages competent authorities to take into account the “consent of the source of the safety data and safety information”. The importance of this recognition underscores the critical distinction discussed in 7.4.2 above, differentiating between the release of safety data and safety information for purposes generally related to the maintenance or improvement of safety (in which case this principle of exception will apply), and the use of safety data and safety information for particular preventive, corrective and remedial purposes in support of the maintenance or improvement of safety (in which case it will not be necessary to satisfy the requirements of any principle of exception as this usage is already permitted within the principles of protection). 7.6.3.15 In keeping with the spirit of the principles of protection, when considering the use of safety data or safety information in support of preventive, corrective or remedial actions taken for the purpose of maintaining or improving safety, it may be possible for the competent authority to ascertain whether an appropriate alternative source for such data or information may practicably be available. If so, even this unexceptional use of protected safety data or safety information may be avoided. 7.6.3.16 However, such a consideration of practicability does not require or invite the formal application of a principle of exception called up in Annex 19. This is because the principle of exception applies where the interest of maintaining or improving safety is weighed against some other competing public interest (e.g. the proper administration of justice, providing public access to data or information, or facilitating training or educational processes by allowing for the inclusion of protected data or information). Preventive, corrective or remedial action taken for the purpose of maintaining or improving safety falls within the scope of the principles of protection, and there is no countervailing nonsafety related interest against which such use needs to be balanced. 7.6.4 Additional considerations in applying a principle of exception 7.6.4.1 In deciding whether a principle of exception applies in a case, the competent authority should always take into account the consent of the source of the safety data or safety information. If a person has been given assurances of confidentiality in respect of safety data or safety information of which they are the source, then the use, disclosure or release of such data or information in a manner that conflicts with those assurances is likely to have an adverse impact on the safety data and safety information that may be provided by that person in the future. In addition, if safety data or safety information were to be released or used in spite of confidentiality assurances to the source, this may have a similarly adverse impact on any person who may become aware of that fact. 7.6.4.2 To avoid undesirable situations of the kind mentioned in 7.6.4.1 from arising, it will be prudent to ensure that individuals and organizations clearly understand in advance how, when, where and for what purposes the data and information they provide may be used in accordance with the application of the principles of exception. Such an understanding is essential to the establishment and maintenance of a predictable reporting environment based on trust. 7.6.4.3 General guidelines regarding the application of the principles of exception by the competent authority consistent with the provisions of the Annex 19 are illustrated in Figure 7-2.6 7.7 PUBLIC DISCLOSURE 7.7.1 The public has an overarching interest in safety data or safety information. The public’s interest is in openness, transparency and accountability so that it has a general awareness of the safety of the system and can be assured that everything necessary to address safety is being done. Specific individuals or interest groups may also have an interest in safety data or safety information for reasons other than those directly related to safety. Disclosure may occur voluntarily, as a result of a request for information to the government or through the processes of a judicial proceeding. Whether or not it is appropriate to disclose any safety data or safety information publicly depends on the nature of the safety data and safety information. Such determination is the domain of the competent authority as previously discussed. 7.7.2 If safety data or safety information is disclosed publicly, it is not usually possible to limit how the information would be used. Certainly, openness and transparency should be encouraged but, at the same time, the rights and legitimate expectations of those involved in reporting and analysing the safety data and safety information, and the need to protect them from inappropriate damage to their interests or reputation, must be taken into account. However, this may not always apply to States with right-to-know laws. 7.7.3 Many States have legislation which in effect mandates release of all information held by State institutions. Such laws are sometimes referred to as right-to-know laws. Under these laws, unless there is an exemption for a particular type of information, it must be disclosed by the government upon request. Some examples of exemptions might be classified information, commercially sensitive information or information such as medical records which are protected by privacy laws. Safety data or safety information is not usually exempted. In accordance with Annex 19, States may choose to create exemptions or rules to protect from public disclosure in right-to-know laws or in any other type of laws, including aviation legislation. 7.7.4 Right-to-know laws generally apply to information held by the government. Since most safety data and safety information requiring protection from disclosure is obtained from operational personnel or a service provider, a practical approach would be to allow such data and information to remain with the organization rather than depositing it with a government authority. This way the question of public disclosure does not arise unless some additional government action such as an administrative proceeding is convened. Where the question of public disclosure is faced in an administrative or judicial proceeding, the competent authority should apply the basic principles of protection previously discussed. This approach may not work if service providers are obliged to report safety data and safety information to a government authority, or if the service provider is a governmental authority or agency or part of a governmental authority or agency. 7.7.5 Failure to properly assess the competing claims made for access to safety data or safety information can impact current and future efforts in two ways. Public disclosure of certain data or information can be perceived as a violation of the privacy of individuals or the confidentiality expectations of organizations associated with the safety data or safety information. Use of certain data or information as part of an argument supporting sanctions against involved individuals or organizations can be seen to violate basic principles of fairness. Future availability of safety data and safety information may be impacted by the predictable human behaviour of withholding information that results from anticipating a perceived threat from its disclosure or incriminating use. This can have an obvious impact on both data collection and data analysis functions of safety management. 7.7.6 If a competent authority determines that safety data or safety information may be disclosed to the public, the State is expected to ensure that any public disclosure is made in accordance with applicable privacy laws or in a deidentified, summarized or aggregate form. Further information on authoritative safeguards is contained in 7.5.3. 7.8 PROTECTION OF RECORDED DATA 7.8.1 Protection of ambient workplace recordings 7.8.1.1 Ambient workplace recordings should be part of any protection policy or regulation. The use of these recordings as a part of safety management where allowed by regulation or policy should fully respect the principles of protection and exception. The trust of the reporting population is fundamental to an effective safety management. That trust should not be compromised. 7.8.1.2 Provisions contained in Annex 19 are applicable to safety management functions related to, or in direct support of, the safe operation of aircraft. Ambient workplace recordings may be governed by national privacy laws that are not defined in Annex 19. 7.8.1.3 Ambient workplace recordings may include CVRs, AIRs, other flight recorder recordings, or recordings of background communication and the aural environment at air traffic controller work stations. 7.9 SAFETY INFORMATION SHARING AND EXCHANGE 7.9.1 Protection of information shared between States 7.9.1.1 Taking into account that one of the main objectives of sharing and exchange of safety information is to ensure a consistent, fact-based and transparent response to safety concerns at the State and global levels, in the process of sharing and exchange of safety information, States shall act in accordance with the following principles: a) compliance with the Convention on International Civil Aviation (Chicago Convention), its Annexes and other multilateral and bilateral obligations of States; b) sharing and exchange of safety information does not lead to violation by the relevant States’ authorities of national laws relating to the protection of safety information, including but not limited to the national laws and regulations on State secret, personal data protection, commercial (trade) secret as well as violation of the rights of individuals and legal entities; c) safety information shared and exchanged by a State should not be used in a way adversely affecting such State itself, its airlines, its public servants and its citizens as well as for other inappropriate purposes, including for the purpose of gaining economic advantage; d) the sole purpose of protecting safety information from inappropriate use is to ensure its continued availability so that proper and timely preventive actions can be taken and aviation safety improved; and e) sharing and exchange of safety information should be in line with the principles of protection provided in Annex 19. 7.9.1.2 A legal framework for sharing and exchange of information can be based on bilateral arrangements between States inserted, for instance, into their air transport (air services) agreement. For facilitating sharing and exchange of information, States can also agree that such bilateral arrangements apply provisionally, if applicable, pending their ratification and entry into force. 7.9.1.3 States should promote and facilitate the establishment of safety information sharing and exchange networks among users of its aviation system. The sharing and exchange of safety information is fundamental to ensuring a consistent, fact-based and transparent response to safety concerns at the State and global levels. Chapter 8 STATE SAFETY MANAGEMENT 8.1 INTRODUCTION 8.1.1 Chapter 3 of Annex 19 contains standard and recommended practices related to the safety management responsibilities of States. This includes the establishment and maintenance of a State safety programme (SSP) intended to manage safety in an integrated manner. 8.1.2 With the First Edition of Annex 19, States were expected to establish and implement two sets of provisions, these were the eight critical elements (CEs) of a State’s safety oversight (SSO) system; and the four components of an SSP. The safety oversight aspect reflected the traditional role of the State, which is to ensure the effective implementation by the aviation industry of prescriptive SARPs, while the state safety program represented the incorporation of safety management principles. The details of the eight critical elements were found in Appendix 1 of the Annex with the status of SARPs, and the detailed elements of a framework for the implementation and maintenance of the state safety program were provided in Attachment A as guidance material. 8.1.3 The safety oversight system and the state safety program were closely connected in terms of the safety objectives that each seeks to achieve. Both address the functions and responsibilities of the State; the former primarily with regard to safety oversight, and the latter with regard to safety management and safety performance. There are clearly some aspects of safety management within the eight CEs that reflect the transition to a proactive approach in managing safety. For example, surveillance obligations (CE-7) can be considered an element of safety assurance and primary aviation legislation (CE-1) and specific operating regulations (CE-2) were also reflected in the original state safety program framework as important safety risk controls. 8.1.4 These responsibilities have been integrated in the Second Edition of Annex 19 and are collectively referred to as the State’s safety management responsibilities. The standard and recommended practices related to the State’s safety management responsibilities, which cover both safety oversight and safety management, are interdependent and constitute an integrated approach towards effective safety management. Although the term state safety program is still used in the Second Edition of Annex 19, the meaning has changed to encompass the integrated set of standard and recommended practices found in Chapter 3. As such, the state safety program is no longer described as a framework, but rather as a programme to meet the State’s safety management responsibilities, which includes safety oversight. So, the state safety program is part of the broad concept of State safety management. This evolution is illustrated in Figure 8-1. 8.2 STATE SAFETY PROGRAMME (SSP) 8.2.1 State safety oversight system critical elements The CEs of a State safety oversight (SSO) system form the foundation of the SSP. The Second Edition of Annex 19 emphasizes the importance of a safety oversight system by maintaining the provisions related to the eight CEs at the level of a Standard. The majority of the requirements from the state safety program framework have been upgraded to Recommended Practices, with a few upgraded to a Standard. Details on the CEs of an SSO system are addressed in the Safety Oversight Manual, Part A — The Establishment and Management of a State Safety Oversight System (Doc 9734). 8.2.2 State safety programme overview 8.2.2.1 An state safety program is an integrated set of regulations and activities aimed at improving safety. For the establishment and maintenance of the SSP, the international civil aviation organization standard and recommended practices are structured into the following four components: a) State safety policy, objectives and resources; b) State safety risk management; c) State safety assurance; and d) State safety promotion. 8.2.2.2 The implementation of an state safety program requires coordination among multiple authorities responsible for the aviation functions of the State. The implementation of an state safety program does not alter the respective roles of the State’s aviation organizations or their normal interaction with one another. Rather, the state safety program aims to leverage the collective safety functions and capabilities to further enhance safety within the State. When starting to implement an SSP, most States find they already have existing processes and activities that address many aspects of an SSP. The implementation of an state safety program aims to enhance these processes with additional performance and safety risk-based elements, and facilitate the effective implementation of safety management system by the aviation industry in the State. 8.2.2.3 The state safety program aims to: a) ensure the State has an effective legislative framework in place with supporting specific operating regulations; b) ensure safety risk management and safety assurance coordination and synergy among relevant State aviation authorities; c) support effective implementation and appropriate interaction with service providers’ SMS; d) facilitate the monitoring and measurement of the safety performance of the State’s aviation industry; and e) maintain and/or continuously improve the State’s overall safety performance. 8.2.3 Delegation of safety management functions and activities 8.2.3.1 Some safety management activities require new competencies such as: conducting safety risk assessments; performing safety data analyses; or evaluating the appropriateness of SPIs. 8.2.3.2 A State may choose to delegate some specific functions or tasks under the state safety program to another State, regional safety oversight organization (RSOO) or other competent organization, such as a trade association, industry representative organization or private body. Although a State may delegate specific functions, it will still need enough personnel to interface with the delegated entity and to process the information provided by the delegated entity. 8.2.3.3 States should also consider the establishment of appropriate technical and administrative processes to ensure that the delegated functions are carried out to their satisfaction. 8.2.3.4 Regardless of the arrangement, the State retains the responsibility to ensure that any delegated tasks are performed in accordance with their national requirements and SARPs. 8.2.3.5 Delegation may allow States with a relatively low level of aviation activities to collectively gather safety data to identify trends and coordinate mitigation strategies. 8.2.3.6 If a State chooses to receive assistance for the development of surveillance processes it should include the development of organizational safety risk profiles for service providers, the planning and prioritization of inspections, audits and monitoring activities of approved organization/service providers. 8.2.3.7 If a State chooses to delegate the surveillance activities, the State should ensure it retains access to surveillance records with documented outcomes. The State should also periodically monitor and review the safety performance of each service provider and ensure it is clearly established who will monitor and enforce (if needed) the resolution of any safety issues. 8.2.3.8 Delegation is a means for States with limited resources to ensure they have access to the appropriate expertise. Guidance on the establishment of an RSOO can be found in Safety Oversight Manual, Part B — The Establishment and Management of a Regional Safety Oversight Organization (Doc 9734). 8.3 COMPONENT 1: STATE SAFETY POLICY, OBJECTIVES AND RESOURCES 8.3.1 The first state safety program component defines how a State will manage safety throughout its aviation system. It includes determining the requirements, obligations, functions and activities of the different State aviation authorities related to the SSP, as well as the broad safety objectives to be achieved. The State safety policy and objectives should be documented to provide clear expectations and keep the safety management efforts of the State’s CAA, and those of other State aviation authorities, focused on maintaining and improving safety performance. This enables the State to provide clear safety guidelines to support an air transportation system that is continuing to grow and becoming more complex. 8.3.2 The State’s legal framework dictates how aviation safety will be managed. Service providers are legally responsible for the safety of their products and services. They must be in compliance with safety regulations established by the State. The State should ensure that aviation authorities involved with the implementation and maintenance of the state safety program have the necessary resources for the state safety program to be implemented effectively. 8.3.3 Component 1 of the SSP, State safety policy, objectives and resources, is composed of the following elements: a) primary aviation legislation; b) specific operating regulations; c) State system and functions; d) qualified technical personnel; and e) technical guidance, tools and provision of safety-critical information. 8.3.4 Primary aviation legislation 8.3.4.1 Guidance on primary aviation legislation (CE-1) can be found in Doc 9734, Part A. Note.— Throughout this manual, the term “legislation” is used as a generic term to include primary aviation legislation and specific operating regulations. 8.3.4.2 There may be a need for legislative provisions that empower the various State aviation authorities (e.g. civil aviation authority or Accident Investigation Authority) to perform their roles. Whether or not the primary aviation legislation needs to specifically mention state safety program implementation as a role of the civil aviation authority depends on the legal system of the State. Some States may consider that state safety program implementation is implied in the functions already mentioned in their primary aviation legislation. In that case, amendment of the primary aviation legislation may not be necessary. Evidence of state safety program implementation should be clearly available in formal State documents. The State should also be able to demonstrate its commitment to address its safety management responsibilities, as outlined in Annex 19. 8.3.4.3 As part of its SSP, a State is expected to establish an enforcement policy that: a) supports and encourages a positive safety culture; b) describes how the State assures protection of safety data and safety information and related sources, especially if information provided is self-incriminating; and c) specifies the conditions and circumstances under which service providers with an safety management system are allowed to deal with and resolve events involving certain safety issues internally, within the context of their safety management system and to the satisfaction of the relevant State authority, provided that the safety management system is in accordance with the safety management system framework and shown to be effective and mature. 8.3.4.4 By using safety management principles, the relationship between a State and its service providers should evolve beyond compliance and enforcement, to a partnership aimed at maintaining or continuously improving safety performance. 8.3.5 Specific operating regulations 8.3.5.1 Guidance on specific operating regulations (CE-2), including adapting or adopting regulations from another State can be found in Doc 9734, Part A. Prescriptive and performance-based regulations 8.3.5.2 Safety regulations are an important tool that can be used by States to control safety risks. With the transition to safety management, there has also been a trend towards introducing performance-based regulations. To understand what performance-based regulations are, one must first understand prescriptive regulations. Prescriptive regulations are regulations that explicitly spell out what must be done and how it must be done. The expectation is that compliance with these regulations will achieve the desired level of safety. Many prescriptive regulations were developed following an accident and are based on lessons learned and the desire to avoid an accident taking place from the same causes in the future. From the service provider’s perspective, meeting prescriptive requirements entails implementing the regulations without deviation. No further analysis or justification is expected from the service provider or from the authority. 8.3.5.3 Up until recently international civil aviation organization standard and recommended practices have focused on prescriptive requirements as a means of identifying minimum standards and ensuring interoperability. However, increasingly there is a need to enable performance-based regulations to support innovative implementation approaches that may improve efficiencies and that can meet or exceed the safety objectives. 8.3.5.4 international civil aviation organization Annexes provide examples of Standards that enable both prescriptive and performance-based regulations. The following is an example of a Standard from Annex 14 — Aerodromes, Volume I — Aerodrome Design and Operations, that enables prescriptive regulations: 3.3.1 Where the end of a runway is not served by a taxiway or a taxiway turnaround and where the code letter is D, E or F, a runway turn pad shall be provided to facilitate a 180-degree turn of aeroplanes. 8.3.5.5 The example above enables a prescriptive regulation as it identifies only one way of demonstrating compliance if the runway is of the specified criteria: that is, to provide a runway turn pad. Deviation from prescriptive regulations is generally granted by means of exemption from the regulations. 8.3.5.6 In contrast, Standards which enable performance-based regulations are expressed in terms of the desired outcome. The resulting performance-based regulations require that the service provider demonstrate that its proposed approach will achieve the desired outcome. The following is an example of a performance-based Standard from Annex 6, Part I. 7.2.11 The aeroplane shall be sufficiently provided with navigation equipment to ensure that, in the event of the failure of one item of equipment at any stage of the flight, the remaining equipment will enable the aeroplane to navigate in accordance with 7.2.1 and, where applicable, 7.2.2, 7.2.5 and 7.2.6. 8.3.5.7 Note that the Standard above does not indicate the specific navigation equipment required. Instead, it describes the outcome that is desired, that is, that in the event of the failure of one item, the remaining equipment needs to enable the aircraft to still be navigated safely. The required equipment would depend on the design of the aircraft. Regulations written in this manner would require the air operator to provide the necessary data to the authority to show how it complies with this requirement. This can be done through its own analysis, but for such types of performancebased regulations, the information needed is often available from other sources. In this case, both the authority and air operator would make use of data from aircraft manufacturers to guide their decision, and there is no need for the air operator to develop its own novel solution. When writing performance-based regulations, States must keep in mind how compliance can be demonstrated. There may be a need for the State to develop guidance material and/or acceptable means of compliance to support the industry in meeting the requirement. 8.3.5.8 The following is another example of a performance-based Standard from Appendix 2 of Annex 19. 2.1.1 The service provider shall develop and maintain a process to identify hazards associated with its aviation products or services. 8.3.5.9 In the example above, although the Standard requires that a process be put in place to identify hazards, it does not specify what such a process should look like. States may allow service providers to design their own methodology. The regulator’s role would be to assess whether the service provider’s methodology, processes and system would indeed result in hazards being identified. The authority would also make an assessment of the performance of the service provider’s hazard identification process, for example by evaluating the volume, types and significance of the hazards identified. Performance-based regulations that are written in this manner require regulators to have the skills and expertise to assess the performance of the system, rather than to merely assess prescriptive compliance with the letter of the regulations. More resources are also required for evaluation as implementation would differ from one service provider to another. Providing prescriptive and performance-based options 8.3.5.10 In some cases, international civil aviation organization standard and recommended practices require that prescriptive regulations be established, and at the same time offer States the choice of establishing performance-based regulations to support alternative means of compliance. Where States establish both prescriptive and performance-based regulatory options, service providers that do not have the expertise to develop their own approach to meet the performance-based regulations can choose to comply with the prescriptive regulations. For those service providers who do have such expertise, the resulting regulations allow service providers to develop a means of compliance appropriate to their own operations, and may also offer potential for increased operational flexibility and more efficient use of resources. Fatigue management Standards, such as those in Annex 6, Part I, amendment 43, provide a good example of this: 4.10.1 The State of the Operator shall establish regulations for the purpose of managing fatigue. These regulations shall be based upon scientific principles, knowledge and operational experience with the aim of ensuring that flight and cabin crew members are performing at an adequate level of alertness. Accordingly, the State of the Operator shall establish: a) prescriptive regulations for flight time, flight duty period, duty period limitations and rest period requirements; and b) where authorizing the operator to use a Fatigue Risk Management System (FRMS) to manage fatigue, FRMS regulations. 4.10.2 The State of the Operator shall require that the operator, in compliance with 4.10.1 and for the purposes of managing its fatigue-related safety risks, establish either: a) flight time, flight duty period, duty period limitations and rest period requirements that are within the prescriptive fatigue management regulations established by the State of the Operator; or b) a Fatigue Risk Management System (FRMS) in compliance with 4.10.6 for all operations; or c) an FRMS in compliance with 4.10.6 for part of its operations and the requirements of 4.10.2 a) for the remainder of its operations. 8.3.5.11 In the example above, the Standard requires States to establish prescriptive flight and duty limitation regulations, while the establishment of regulations to support FRMS is optional. FRMS gives the air operator the opportunity to better address its specific fatigue risks and at the same time offers the potential for operational flexibility outside the prescriptive flight and duty limitation regulations. A State must consider whether it is necessary to provide, alternatively, FRMS regulations to the mandatory prescriptive limitation regulations, and whether it has the necessary resources to provide appropriate oversight of FRMS. Standard 4.10.2 then goes on to clarify that air operators are required to manage their fatigue-related safety risks. Where FRMS regulations are established, they can do so within the prescriptive limitations regulations referenced in 4.10.2 (a), or by implementing a performance-based FRMS referenced in 4.10.2 (b) and (c). Air operators that do not have the expertise to develop an FRMS and meet the associated regulatory requirements would need to comply with the prescriptive regulations. 8.3.5.12 It should be apparent that performance-based regulations are not always appropriate. Prescriptive requirements continue to be appropriate when a standardized means of compliance is necessary, for example to facilitate interoperability. Requirements for runway markings, for example, are necessarily prescriptive in nature. 8.3.5.13 In practice, regulations are rarely fully prescriptive or fully performance-based, but rather contain elements of both. They are also performance-based to different degrees. As a State considers implementing performance-based regulations, it needs to consider the capability and maturity of the industry, specific sectors of industry, or even the maturity of individual service providers and their SMS. Performance-based regulations also demand more of the regulator, requiring them to not only check for compliance, but to also be able to evaluate systems and assess safety performance taking into account the specific operational context of each service provider. States need to ensure that they are able to continue to oversee and manage the industry, noting that higher levels of expertise, as well as more resources, are required. safety management system provide a foundation and tools for service providers to meet performance-based regulations, but it is not an automatic assurance that every service provider with an safety management system has the ability to do so. It depends on the demands of the specific performance-based requirement. 8.3.5.14 Performance-based regulations also have an impact on enforcement. Enforcement of prescriptive regulations is straightforward as non-compliance can be easily determined. Enforcement is more challenging with performance-based regulations. For example, a service provider may be able to show that it has a process in place that meets the regulation (for example, it has a hazard reporting system in place), but is unable to show that the process can deliver the intended outcome (for example, whether the hazard reporting system is effective). This could lead to the establishment of systems or processes that merely meet the “letter of the law” but do not deliver on the required safety outcome. Regulators may need to involve the relevant enforcement agencies in the development of performance-based regulations to ensure their enforceability. 8.3.6 State system and functions 8.3.6.1 Guidance on State system and functions (CE-3), can be found in Doc 9734, Part A. Organization responsible for coordinating the state safety program 8.3.6.2 State’s safety management responsibilities can be discharged by multiple aviation authorities within the State, for example, the civil aviation authority and an independent AIA. States should clarify which authority within the State is responsible for coordinating the maintenance and implementation of the SSP. Many States assign this role to the CAA, given that the civil aviation authority is normally responsible for most of the state safety program responsibilities. The roles and responsibilities of all the authorities involved should be identified and documented. state safety program coordination group 8.3.6.3 The State should establish a suitable coordination group with representation from the impacted aviation authorities with responsibilities related to the implementation and maintenance of the SSP, including Accident Investigation Authorities as well as military aviation authorities. Appointment of a coordination group will facilitate good communication, avoid duplication of effort and conflicting policies and ensure effective and efficient state safety program implementation. This group is a form of committee chaired by the head of the organization responsible for coordinating the SSP. 8.3.6.4 The State may also find it beneficial to allocate the day-to-day planning and management of the state safety program implementation to a person, a department or a team. Such a person, department or team can ensure that the various aspects work together to deliver the State’s safety objectives. state safety program functions and activities 8.3.6.5 How States choose to organize their workforce and organizational structure to address the acceptance and monitoring of safety management system implementation by service providers in compliance with Annex 19 is a matter for each State to decide. A State can choose to establish a new office or to add this responsibility to the responsibilities of existing offices, for example: airworthiness office, flight operation office, air navigation and aerodrome office, etc. The decision will depend on how the State chooses to address its new competency requirements. 8.3.6.6 It is important for the various aviation authorities to have role clarity. This should include all of their state safety program obligations, functions and activities. The State should ensure that each authority understands its contribution to meeting each Annex 19 requirement; most importantly, their responsibility for management of safety in the State. The obligations and functions of each aviation authority with respect to state safety program implementation should be documented to avoid ambiguity. 8.3.6.7 There should be appropriate governance structures in States where the staff involved in safety are geographically dispersed. A complex governance structure may not be necessary for less complex aviation systems, where few people are involved in safety management. The State should ensure that all personnel have the same understanding of state safety program implementation at a national level. The state safety program implementation approach should be documented. State safety policy and safety objectives 8.3.6.8 Effective implementation of an state safety program requires commitment by the State’s senior management and support of personnel at all levels. State safety policies and State safety objectives are high-level statements endorsed by the State aviation authorities. Combined, they guide safety behaviour and resource allocation. The State safety policy and objectives should be published and reviewed periodically to ensure they remain relevant and appropriate to the State. State safety policy 8.3.6.9 The commitment of senior management should be articulated in the State safety policy. The State safety policy is a formal document describing the State’s safety intentions and direction. The State safety policy projects senior management’s attitude to safety and to the promotion of a positive safety culture in the State. It can be thought of as the State’s safety mission and vision statement. 8.3.6.10 The safety policy should address key practices that are essential for safety management and how senior management expects to deliver on their safety responsibilities, (e.g. the use of a data-driven approach). The principles reflected in the safety policy should be clearly visible in the day-to-day practices of the State. 8.3.6.11 The State safety policy is endorsed by the State aviation authorities to demonstrate their safety intent and is implemented as a procedure or protocol. A typical policy statement is: “We will achieve safety through: (1) our acceptance of accountability for safe conditions and behaviours (2) a culture of safety leadership, collaboration, open communication, etc.” State safety objectives 8.3.6.12 The development of safety objectives starts with a clear understanding of the highest safety risks in the aviation system. Safety risk in the aviation system is influenced by many different factors, such as the size and complexity of the aviation system as well as the operational environment. The development of a good system description will provide a good background and understanding. Refer to state safety program implementation in 8.7 of this chapter. 8.3.6.13 Quantitative data should be used where available to develop an understanding of its top safety risks. The State may also use qualitative information and expert analysis. A group of selected experts may be created to participate in guided discussions to gain understanding of the broader safety risks across the aviation system. This group would have a similar role as the service provider’s safety review board (SRB), as discussed in Chapter 9, 9.3.6; in this case at State level. These experts can be guided by available safety trend information, known accidents and serious incidents contributing factors, or known deficiencies in the State’s SSO processes. They could also consider regional objectives or global objectives as identified in the GASP. This brainstorming-type approach could be done collaboratively with service providers, to identify “known” safety issues for each aviation sector. 8.3.6.14 State safety objectives are brief, high-level statements that provide direction for all relevant State aviation authorities. They represent the desired safety outcomes that the State aims to achieve. It is also important, when defining the safety objectives, to take into account the State’s ability to influence the desired outcomes. The safety objectives represent the State’s priorities for the management of safety and provide a blueprint for allocating and directing the State’s resources. 8.3.6.15 The safety objectives support the identification of the State’s SPIs and SPTs and the subsequent establishment of the acceptable level of safety performance (ALoSP), discussed later in this Chapter. Safety objectives work together as a package with SPIs and SPTs to enable the State to monitor and measure its safety performance. Further guidance on SPIs and SPTs can be found in Chapter 4. 8.3.6.16 Once the state safety program is implemented, the State should periodically reassess its identified safety risks by analysing the safety information generated by the SSP. The analysis will also support the identification of emerging issues. Guidance on safety analysis can be found in Chapter 6. The State should also periodically review its progress towards achieving its safety objectives and their continued relevance, keeping in mind any reassessments of the current risks. State safety resources 8.3.6.17 The State must ensure that agencies that have safety responsibilities are given sufficient resources to carry out their mandates. This includes financial resources as well as human resources. 8.3.6.18 Some aviation authorities receive their funding based on a State-allocated budget. Others are funded by fees and charges collected from those participating in the aviation system (such as licence and approval fees), or from those using services within the aviation system (for example levies on passengers or fuel). The source of funding that is most appropriate to the State depends on the circumstances of that State. For example, a State that has a small aviation industry may find that it is not enough for its civil aviation authority to rely only on fees and charges to fund its regulatory activities. A State may need to have multiple sources of funding for its aviation activities. 8.3.6.19 As a State starts to fully implement its state safety program and adopt safety management practices, it may need to revisit its budget and funding to ensure that it continues to have a sufficient revenue stream. New functions are introduced and will must be carried out well in order for a safety management approach to succeed, including for example SRM, data collection and analysis, and safety promotion. Safety management also requires the State’s aviation authorities to be able to continually monitor and review their own processes to manage risk. Inspectors and other personnel may need to be retrained. As such, the State may find it necessary to allocate sufficient financial resources for State agencies when transitioning to a safety management approach. National Aviation Safety Plan (NASP) 8.3.6.20 Assembly resolution A39-12 on international civil aviation organization global planning for safety and air navigation recognizes the importance of effective implementation of national aviation safety plans. It resolves that States should develop and implement national aviation safety plans, in line with the goals of the Global Aviation Safety Plan (GASP, Doc 10004). At the international level, the GASP sets forth a strategy which supports the prioritization and continuous improvement of aviation safety. Regional and national aviation safety plans should be developed in alignment with the GASP. 8.3.6.21 At the regional level, the regional aviation safety groups (RASGs) coordinate the planning process. Regional and national safety enhancement initiatives (SEIs) should be adapted based on issues faced by the States concerned. The national aviation safety plan presents the strategic direction for the management of aviation safety at the national level, for a set time period (e.g. over the next five years). It outlines to all stakeholders where the State aviation authorities should target resources over the coming years. 8.3.6.22 A national aviation safety plan allows the State to clearly communicate its strategy for improving safety at the national level to all stakeholders, including other government branches and the travelling public. It provides a transparent means to disclose how the CAAs and other entities involved in civil aviation will work to identify hazards and manage operational safety risks and other safety issues. It also illustrates how planned SEIs will help the State meet established goals. The national aviation safety plan emphasizes the State’s commitment to aviation safety. 8.3.6.23 Each State should produce a national aviation safety plan. If a State already has an state safety program in place, the national aviation safety plan may be addressed by Component 1: State safety policy, objectives and resources. The national aviation safety plan may be published as a separate high level document to facilitate communication with the public and other entities external to the CAA. state safety program Documentation 8.3.6.24 The State should describe its state safety program in a document to ensure that all relevant personnel have a common understanding. The document should include its structure and associated programmes, how its various components work together, as well as the roles of the different State aviation authorities. The documentation should complement existing processes and procedures and broadly describe how the various state safety program sub programmes work together to improve safety. Cross references to safety responsibilities and accountabilities of authorities in supporting documentation may also be included. The State should choose a means of documentation and dissemination that would best serve its environment, for example in a physical document or on an appropriately controlled website. Regardless of the communication channel, the aim is to facilitate a common understanding of the state safety program by all relevant personnel. 8.3.7 Qualified technical personnel 8.3.7.1 Guidance on qualified technical personnel performing safety-related functions (CE-4) can be found in Doc 9734, Part A. General guidance 8.3.7.2 States will need to identify and address the competencies required for effective implementation of SSP, taking into account the roles and responsibilities under the state safety program performed by their personnel. These competencies are in addition to those required for the conduct of compliance oversight and may be addressed by training existing staff or by hiring additional staff and include, but are not limited to: a) enhanced leadership skills; b) understanding of business processes; c) experience and judgement required to assess performance and effectiveness; d) safety risk-based surveillance; e) safety data collection and analysis; f) safety performance measurement and monitoring; and g) safety promotion activities. 8.3.7.3 Guidance on the development and maintenance of a strong inspectorate workforce can be found in the Manual on the Competencies of Civil Aviation Safety Inspectors (Doc 10070). 8.3.7.4 The State should determine the most appropriate training for personnel with different roles and responsibilities in the organization. The following are examples of training that should be considered: a) briefings or familiarization training for senior management on SSP, SMS, safety policy, objectives and ALoSP; b) training for inspectors on the state safety program and safety management system principles, how to carry out safety management system assessments, how to evaluate a service provider’s SPIs for acceptance and how to generally oversee the service provider in a safety management environment; c) soft skills training (effective communication skills, negotiation skills, conflict resolution, etc.) to support inspectors in working collaboratively with service providers to improve safety performance while ensuring continued compliance with established regulations; d) training for personnel responsible for data analysis, safety objectives, SPIs and SPTs; e) training for aviation medical examiners and medical assessors; f) protection of safety data, safety information and related sources and enforcement policy training for legal personnel, etc.; and g) state safety program and safety management system training for service provider safety investigators. 8.3.7.5 Safety training programmes for personnel involved in SSP-related duties should be coordinated among State organizations, as appropriate. The scope of state safety program and safety management system training or familiarization should reflect the actual state safety program processes, and the state safety program itself as it evolves and matures. Initial state safety program and safety management system training may be limited to generic state safety program elements or safety management system framework elements and guidance. 8.3.7.6 To ensure all relevant technical staff are properly qualified, the State should: a) develop internal training policies and procedures; and b) develop an state safety program and safety management system training programme for relevant staff. Priority should be given to SSP-SMS implementation personnel and operational/field inspectors involved in service providers’ safety management system surveillance / monitoring; (including State-specific state safety program processes and their relevance). 8.3.7.7 Many different types of state safety program and safety management system training are available, including online courses, classroom courses, workshops, etc. The type and amount of training provided should ensure that relevant staff develop the competence needed to perform their roles and understand their contribution to the SSP. The aim is to ensure a person or team addresses each aspect of the SSP, and that they are trained to perform the allocated role. 8.3.7.8 Appropriate and sufficient training for inspectors will ensure consistent surveillance and required capabilities to be effective in a safety management environment. States should consider the following: a) Surveillance and monitoring of service providers’ safety management system will require competencies that may not have been critical before safety management system requirements were introduced. Inspectors will need to complement their existing technical knowledge with additional skills to assess the suitability and effectiveness of the service providers’ safety management system implementation. This approach requires working in partnership with industry; to gain the trust of service providers to facilitate sharing of safety data and safety information. States will need to provide the appropriate training to ensure that personnel responsible for interaction with the industry have the competencies and flexibility to perform the surveillance activities in an safety management system environment. A training needs analysis can be used to identify the appropriate training. b) The training should also provide staff with an awareness of the role and contributions of other departments within their aviation authority and other State aviation authorities. This will allow inspectors as well as staff from different State aviation authorities to have a consistent approach. It will also facilitate a better understanding of safety risks across various sectors. Inspectors can also better understand how they contribute to achieving the State safety objectives. 8.3.8 Technical guidance, tools and provision of safety-critical information 8.3.8.1 Guidance on Technical guidance, tools and the provision of safety-critical information (CE-5) can be found in Doc 9734, Part A. 8.3.8.2 The State should consider providing guidance to their inspectors and service providers to help with the interpretation of safety management regulations. This will promote a positive safety culture and airport information desk the service provider in meeting their safety objectives, and consequently, the State’s safety objectives, which are often achieved through regulation. The assessment of safety management system may require additional tools to determine both the compliance and performance of the service providers’ SMS. Any tools developed will require training for affected staff before being implemented. 8.4 COMPONENT 2: STATE SAFETY RISK MANAGEMENT 8.4.1 States need to identify potential safety risks to the aviation system. The State should augment its traditional methods of analysing the causes of an accident or incident with proactive processes to achieve this. Proactive processes enable the State to identify and address precursors and contributors of accidents, and strategically manage safety resources to maximize safety improvements. States should: a) require that their service providers implement safety management system to manage and improve the safety of their aviationrelated activities; b) establish means to determine whether service providers’ safety risk management is acceptable; and c) review and ensure that the service provider’s safety management system remains effective. 8.4.2 The State safety risk management component includes the implementation of safety management system by service providers, including hazard identification processes and the management of associated safety risks. 8.4.3 States should also apply the principles of safety risk management to their own activities. These include activities such as the development of regulations and prioritization of surveillance activities based on assessed risk. 8.4.4 An area often overlooked by service providers and regulators is the safety risk induced through interfaces with other entities. The interface between state safety program and SMS(s) may pose a particular interface challenge for States and service providers. The State should consider highlighting the importance of the safety management system interface risk management through its regulations and supporting guidance. Examples of interface risk include: a) Dependency — organization A is dependent on organization B to provide goods or services. Organization B is not clear about the expectation and organization A’s dependency and fails to deliver. b) Control — interfacing organizations often have minimal control of the quality or effectiveness of the interfacing organization(s). 8.4.5 In both of these instances, interface risk management can illuminate the risk, clarify the mutual expectations and mitigate unwanted consequences through mutually agreed boundary checks. Additional information on interfaces between service providers can be found in Chapter 2. 8.4.6 Licensing, certification, authorization and approval obligations 8.4.6.1 Guidance on licensing, certification, authorization and approval obligations (CE-6) can be found in Doc 9734, Part A. 8.4.6.2 Licensing, certification, authorization and approval obligations are important components of the State safety risk control strategy. They provide the State with assurance that service providers and other pertinent industry representative organizations have achieved the required standards to operate safely within the aviation system. Some States have established common operating regulations to facilitate the recognition or acceptance of licences, certificates, authorizations and approvals issued by other States. Such arrangements do not absolve the State from its obligations under the Chicago Convention. 8.4.7 Safety management system obligations safety management system regulatory requirements 8.4.7.1 In accordance with Annex 19, the State shall require that service providers and international general aviation operators implement SMS. The requirements address the safety management system framework found in Annex 19, Appendix 2 and the supporting guidance found in Chapter 9 of this manual. How these requirements are established will depend on the regulatory framework of the State. 8.4.7.2 States should institute a process that ensures the safety management system is acceptable to the State. One approach is to establish timelines and milestones at the State level that represent the required safety management system implementation progress. Additional guidance for service providers about how to develop and perform an safety management system gap analysis and implementation plan can be found in Chapter 9. 8.4.7.3 The State’s safety management system regulatory requirements and safety management system guidance material should be periodically reviewed. The review should take into consideration: industry feedback, periodic review of the State safety risk profile, current status, and applicability of international civil aviation organization safety management system standard and recommended practices and guidance material. International general aviation 8.4.7.4 safety management system provisions for international general aviation (IGA) are addressed with some flexibility in Annex 19 and are therefore not included in the list of service providers. This sector of aviation is expected to implement the safety management system framework. The difference between this and other sectors is that, in this case, States are allowed a degree of flexibility with how they establish the requirements. Consistent with other provisions found in Annex 6, Part II — International General Aviation — Aeroplanes, the State of Registry shall establish criteria for IGA operators to implement an SMS. 8.4.7.5 The establishment of the criteria should require the application of the safety management system framework as described in Annex 19, but this might be achieved in a number of ways: a) criteria is established within the existing specific operating regulations for IGA; b) publication of requirements within the regulatory framework in a legal instrument other than specific operating regulations that defines the criteria; or c) making references within the regulatory framework to an safety management system industry code of practice that is recognized by the State. 8.4.7.6 In selecting the best approach for the establishment of the safety management system criteria for IGA, the State of Registry should consider how the monitoring of the safety management system will be performed, including possible delegation of oversight to a third party. As with service providers’ SMS, when determining the acceptability of the SMS, the State of Registry should allow for scalability based on the size, operational environment and complexity of the operation. 8.4.7.7 In the case of large or turbojet aircraft under multiple States of Registry that are issued an air operator certificate (AOC) in accordance with Annex 6, Part I, the operator would be considered a service provider and treated as such with the safety management system to be made acceptable to the State of the Operator. safety management system acceptance 8.4.7.8 Many service providers have certificates, authorizations or approvals from more than one State or conduct operations in more than one State. There is no Annex 19 requirement to oversee the safety management system of a service provider that is outside of the State’s responsibility. However, harmonization of safety management system requirements does facilitate acceptance of safety management system between States. Harmonization reduces oversight duplication and the need for service providers to comply with similar safety management system obligations through (potentially) dissimilar requirements. States should be conscious of policies that increase the administrative and financial burden for certificate holders without adding demonstrable safety value. Importantly, for service providers that do not benefit from the common acceptance of their certification, authorization or approval, the introduction of safety management system has exacerbated the situation. States should try to achieve the benefits of implementation without imposing additional undue burden on service providers. 8.4.7.9 Further, States are encouraged to apply the requirements equally when granting certificates, authorizations or approvals to other States’ service providers, without excessive technical, legal, and administrative burdens. Many service providers need additional resources for initial acceptance by multiple States, and to support periodic monitoring or audits from States who have accepted their SMS. Additional effort is also required when requirements vary, are interpreted differently or are in conflict. 8.4.7.10 Annex 19 provides safety management system framework requirements. States transpose the requirements into the State’s regulatory framework. The performance of any organizational system or process, in practice, depends on how the requirements are implemented. There are two major components involved with safety management system equivalence and the implications of safety management system acceptance among States. 8.4.7.11 The first component is the formal aspects of recognition or acceptance of SMS. Some States have addressed this though bilateral or multilateral agreements that involve a mixture of diplomatic, legal, and technical arrangements between States. In some cases, the acceptance is mutual, but not in all circumstances. 8.4.7.12 The second component is technical equivalence. Technical equivalence can be divided into five areas: a) Common requirements. While not sufficient to establish equivalence, use of a common set of requirements provides structure and efficiency for technical evaluations. These have been established in the various international civil aviation organization Annexes. b) Implementation expectations. Each State identifies specific expectations for processes, programmes, methods, and tools for the other authority to demonstrate implementation and performance. c) Acceptance methodology. Methods States use to evaluate how processes and management capabilities vary between States. This is usually a function of the State’s safety oversight system (CE-6, licensing, certification, authorization and approval obligations). d) Performance measurement. The methodology used by each State to measure safety performance of certificated and approved organizations is aimed at improving the State’s understanding of the performance potential and status of each organization. e) Monitoring policies and methods. Monitoring must assure the performance status of organizations and their SMSs. This is an aspect of the State’s surveillance obligations. Each State must develop an understanding and confidence in the methods used by another authority to oversee their SMSs. This supports acceptance or recognition of the SMSs. 8.4.7.13 Service providers’ safety management system must be made acceptable to the relevant State authority. Service providers are expected to conduct a gap analysis and develop a workable implementation plan (including acceptance by the State as a planned task). safety management system implementations are generally conducted in three or four stages. Early collaboration between the service provider and the State authorities will likely lead to a smoother development and acceptance process. For information about safety management system implementation see Chapter 9. Acceptance of SPIs and SPTs 8.4.7.14 Service providers’ proposed SPIs are reviewed and accepted by the relevant State regulatory authority as part of the safety management system acceptance. States might consider planning the acceptance of a service provider’s SPIs later in the implementation process. This is especially practical for service providers at initial certification as they often do not have enough data to develop meaningful indications. The regulator may be satisfied that the proposed SPIs are appropriate and pertinent to the individual service provider’s aviation activities. Some of the service provider’s SPIs and SPTs may link to the State SPIs and SPTs for measuring and monitoring the ALoSP. This need not be the case for all SPIs and SPTs. More information on safety performance measurement is found in Chapter 4. 8.4.7.15 The acceptance of the service provider’s SPTs may be addressed after the SPIs have been monitored over a period of time. This establishes the baseline performance. It may be based on targets established at the State, regional or global level. Achievement of State SPTs will require the coordination of safety risk mitigation actions with the service provider. One safety management system across multiple service providers 8.4.7.16 Organizations with multiple service provider certifications may choose to include them all under the scope of one safety management system to capitalize on the benefits of safety management system and better address interface aspects. The State regulator should consider the following when assessing the safety management system of these parent organizations or the implementation of safety management system requirements for service providers which are included in the scope of a wider SMS: a) Ensure that safety management system monitoring policies and processes are consistently applied throughout the State, in particular where inspectors from different organizations within the regulator are responsible for the oversight and monitoring of different service providers: 1) there is evidence of management commitment for the consistent interpretation of regulations and application of oversight and monitoring; 2) all oversight and monitoring personnel have been provided standardized training; ideally including participants from different disciplines; 3) common policies, procedures, and auditing tools need to be developed and implemented when there are different oversight and monitoring organizations; 4) there is consistent and frequent communication between the responsible inspectors assigned to each service provider; 5) there are mechanisms in place which monitor the degree of standardization of the oversight and monitoring activities. Any issues identified should be addressed; 6) it is recognized that the service provider’s activities may be addressed by the safety management system at the corporate (“parent”) level. This might include activities that require safety management system and activities that are outside of Annex 19 applicability. 7) the parent organization has documented: i) its policies and procedures for how safety data and safety information are shared, communications are relayed, decisions are made, and resources are allocated across the different activity areas and, where applicable, with different regulatory authorities; ii) the roles and responsibilities associated with its safety management system and the accountability framework for the SMS; and iii) the organizational structure and interfaces between different systems and activities in its system description. b) Ensure awareness that parent organizations holding multiple certificates - some of which include certificates from foreign regulators - may elect to implement one safety management system across the multiple service providers. 1) recognize that the scope of an safety management system is clearly defined in the system description and details the individual activities. The service provider can demonstrate the compatibility between their safety management system processes and the corporate SMS. 2) be aware that this scenario can induce additional challenges when the parent organization holds both domestic and international approvals, such as the acceptance of the safety management system by different regulatory authorities. An agreement should be made with the other regulatory authorities on how oversight and monitoring will be shared, delegated or maintained separately (duplicated) where arrangements for safety management system acceptance have not yet been established. Integrated management systems 8.4.7.17 The regulator should consider the following when assessing service providers which have integrated their safety management system with other management systems: a) drafting a policy that clarifies the scope of their authority (they may not be responsible for oversight of the related management systems); and b) resources necessary to assess and monitor an integrated management system (this could include staff with appropriate expertise, processes, procedures and tools). 8.4.7.18 There are benefits for the service provider in the integration of their safety management system with other management systems. The integration should be completed to the satisfaction of the CAA, and in a way that the civil aviation authority can effectively “see” and monitor the SMS. Guidance for service providers implementing safety management system as part of an integrated management system is available in Chapter 9. 8.4.8 Accident investigation 8.4.8.1 The accident investigation authority (AIA) must be functionally independent from any other organization. Independence from the civil aviation authority of the State is of particular importance. The interests of the civil aviation authority could conflict with the tasks entrusted to the AIA. The rationale for the independence of this function from those of other organizations is that accident causation can be linked to regulatory or SSP-related factors. Also, such independence enhances the viability of the AIA and avoids real or perceived conflicts of interest. 8.4.8.2 The accident investigation process has a pivotal role in the SSP. It enables the State to identify contributing factors and any possible failure within the aviation system, and to generate the necessary countermeasures to prevent recurrence. This activity contributes to the continuous improvement of aviation safety by discovering active failures and contributing factors of accidents/incidents and providing reports on any lessons learned from analysis of events. This can support development of corrective actions decisions and corresponding allocation of resources and may identify necessary improvements to the aviation system. Refer to international civil aviation organization Annex 13 and related guidance for more information. 8.4.8.3 There are many safety occurrences that do not require an official investigation in accordance with Annex 13. These occurrences and identified hazards may be indicative of systemic problems. These problems can be revealed and remedied by a safety investigation led by the service provider. For information about service provider safety investigations, refer to Chapter 9. 8.4.9 Hazard identification and safety risk assessment General guidance 8.4.9.1 One of the most important roles of aviation authorities is to identify hazards and emerging trends across the aviation system. This is often achieved by analysing safety data aggregated from multiple sources. The level of complexity and sophistication of a State’s safety risk management process will vary based on the size, maturity, and complexity of the aviation system in the State. General guidance on the safety risk management process can be found in Chapter 2. 8.4.9.2 Collection of internal and external safety data and safety information is essential to achieving an effective SSP. Non-complex aviation systems may produce limited data. In this case, collection and exchange of external data should be a priority. External data is often available from other States, such as: investigation reports; annual safety reports (including information and analysis on incidents); safety alerts; safety bulletins; safety studies; iSTARS; etc. At a regional level, international civil aviation organization groups (e.g., RASGs, planning and implementation regional groups (PIRGs), etc.) may also provide a good source of safety information. The State’s safety data collection and processing system (SDCPS) should include procedures for the submission of accident and incident reports to ICAO, which will facilitate the collection and sharing of global safety information. 8.4.9.3 The primary goal of safety risk management is to identify and control the potential consequences of hazards using the available safety data. The principles for safety risk management are the same for States and service providers. 8.4.9.4 Service providers have access to their own safety data. States have access to safety data from multiple service providers. Therefore, the State implementing common taxonomies to classify safety data it collects will greatly improve the effectiveness of the State safety risk management process. This also allows data gathered from multiple sources across different aviation sectors to be analysed more efficiently. The data analysis process inputs and outputs are depicted in Figure 8-2 below. 8.4.9.5 Inputs can be received from any part of the aviation system, including: accident investigations; service provider safety investigations; continuing airworthiness reports; medical assessment results, safety risk assessments; audit findings and audit reports; and safety studies and reviews. 8.4.9.6 When necessary, outputs or safety risk controls are applied to eliminate the hazard or reduce the level of safety risk to an acceptable level. A few of the many mitigation options available to the State include: airworthiness directives; providing input to refined oversight and monitoring of the service provider(s); amendments to certification, rulemaking or safety policies; safety promotion programme; facilitation of lessons learned workshops. The chosen action will obviously depend on the severity and type of issue being addressed. Hazard identification 8.4.9.7 Hazard identification is predicated on collection of representative data. It may be appropriate to combine or aggregate data from multiple sectors to ensure a comprehensive understanding of each hazard. The process depicted in Figure 8-2 is equally valid for reactive or proactive hazard identification. Analysing the hazards identified during an incident or accident investigation is an example of a reactive methodology. A proactive one might include hazards identified during audits or inspections, or from mandatory reports. It could include being alerted to early signs of safety performance degradation from day-by-day system reliability monitoring. 8.4.9.8 Hazards exist at all levels in the State’s aviation system. Accidents or incidents occur when hazards interact with certain triggering factors. As a result, hazards should be identified before they lead to accidents, incidents or other safety-related occurrences. 8.4.9.9 States are encouraged to appoint an individual or team to gather, aggregate and analyse available data. The State safety analyst should analyse data to identify and document potential hazards as well as corresponding effects or consequences. The detail required in the hazard identification process depends on the complexity of the process under consideration. 8.4.9.10 A systematic process should be developed to ensure effective hazard identification. It should include the following elements: a) access to the data sources necessary to support the management of safety risk in the State; b) safety analysis team with appropriate analytical skills and operational experience, and training and experience in a variety of hazard analysis techniques; and c) hazard analysis tool(s), appropriate for the data being collected (or to be collected) and the scope of aviation activities in the State. Hazard identification triggers 8.4.9.11 There are many situations where hazard identification should be initiated. Some of the major ones are: a) System design: Hazard identification starts before the beginning of operations with a detailed description of the particular aviation system and its environment. The safety analysis team identifies the various potential hazards associated with the system as well as impacts to other interfacing systems. b) System change: Hazard identification starts before introducing a change in the system (operational or organizational) and includes a detailed description of the particular change to the aviation system. The safety analysis team then identifies the potential hazards associated with the proposed change as well as impacts to other interfacing systems. c) On demand and continuous monitoring: Hazard identification is applied to existing systems in operation. Data monitoring is used to detect changes in the hazard situation. For example, hazard manifestation may be more frequent or more severe than expected, or the agreed mitigation strategies are less effective than expected. Continuous monitoring and analysis can be established with notification thresholds based on a set of critical items of interest. Safety risk assessment 8.4.9.12 General guidance on safety risk assessment can be found in Chapter 2. It should be noted that safety risk can be viewed and controlled across an aviation sector or a region. 8.4.9.13 There are many different tools to analyse data and use different safety risk modelling approaches. When selecting or developing safety risk assessment, States should ensure that the process works well for their environment. 8.4.10 Management of safety risks 8.4.10.1 Guidance on resolution of safety issues (CE-8) can be found in Doc 9734, Part A. 8.4.10.2 The objective of the management of safety risks is to ensure safety risks are controlled and an ALoSP is achieved. The appropriate State aviation authority develops, documents, and recommends appropriate safety risk mitigation or safety risk control strategies. Examples include: direct intervention with a service provider, implementing additional policies or regulations; issuing operational directives or influencing through safety promotional activities. 8.4.10.3 An evaluation of each proposed safety risk control should be performed as a next step. Ideal safety risk control candidates are cost effective, easy to perform, quickly implemented, effective, and do not introduce unintended consequences. Since most situations do not meet these ideals, candidate safety risk controls should be evaluated and selected based on balancing the attributes of effectiveness, cost, timeliness of implementation, and complexity. Once safety risk controls have been selected and implemented, they should be monitored and validated to ensure the intended goals have been achieved. 8.4.10.4 Many of the safety risk controls require action by service provider(s). States should direct the service provider(s) to accomplish effective implementation. States may need to monitor the effectiveness of the safety risk controls and their impact on service providers’, and collectively, States’ safety performance. Safety risk mitigation approaches are outlined in Chapter 2. 8.5 COMPONENT 3: STATE SAFETY ASSURANCE 8.5.1 State safety assurance activities aim to assure the State that their functions are achieving their intended safety objectives and targets. Service providers are required to implement a safety assurance process as part of their SMS. The safety management system assurance capability assures each service provider that their safety processes are functioning effectively, and they are on target to achieve their safety objectives. Similarly, State safety assurance activities, as part of their SSP, provide the State with assurance that its safety processes are functioning effectively and the State is on target to achieve its safety objectives via the collective efforts of the State’s aviation industry. 8.5.2 Surveillance activities and safety data/information collection, analysis, sharing and exchange mechanisms ensure that regulatory safety risk controls are appropriately integrated into a service provider’s SMS. This provides confidence that the system is being practiced as designed, and the regulatory controls are having the intended effect on SRM. States can collect aviation safety data/information from many sources, including through surveillance processes and safety reporting programmes. The data should be analysed at various levels, and the conclusions drawn from the analysis should be used as the basis for well-informed safety decision-making with regard to surveillance activities and safety in the State’s aviation system. 8.5.3 Surveillance obligations 8.5.3.1 Guidance on Surveillance obligations (CE-7) related to compliance monitoring can be found in Doc 9734, Part A. Prioritizing surveillance activities 8.5.3.2 A safety risk-based surveillance (SRBS) approach enables prioritization and allocation of a State’s safety management resources commensurate with the safety risk profile of each sector or individual service provider. States gain experience and familiarity with each service provider by monitoring the steadily developing maturity of their safety assurance process, and in particular, their management of safety performance. Over time the State will accumulate a clear picture of the service provider’s safety abilities, particularly their management of safety risk. The State may choose to amend the scope and/or frequency of surveillance as their confidence and evidence of the service provider’s safety capability develops. 8.5.3.3 SRBS is most appropriate for organizations with a mature SMS. SRBS may also be applicable to organizations where safety management system has not yet been implemented. The foundation of effective SRBS is reliable enough and meaningful data. Without reliable and meaningful data, it is difficult to defend adjustments to the surveillance scope or frequency. 8.5.3.4 States should develop or reinforce their data management capabilities to ensure they have reliable and comprehensive data upon which to base their (data-driven) decisions. Individual sector safety risk analyses may also allow the State to evaluate common safety risks that affect multiple service providers with similar types of operations (for example, short-haul airlines). This facilitates safety risk ranking among service providers within a specific aviation sector or across sectors, and supports the allocation of surveillance resources to sectors or activities with greatest safety effect. 8.5.3.5 Analyses at the sector level allow the State to view the aviation system in context: how the parts contribute to the whole. They empower the State to identify which sector(s) will benefit from higher levels of support or intervention, and which sectors are the best candidates for a more collaborative approach. This gives the State assurance that regulation across the aviation system is commensurate and targeted at the areas with greatest need. It is easier to identify where changes to specific regulations are needed to achieve maximum regulatory effectiveness with minimal interference. 8.5.3.6 SRBS comes at a cost. It requires ongoing interactions between the State and the aviation community beyond compliance-based audits and inspections. An SRBS approach uses the safety risk profile of the service provider to adapt its surveillance activities. The output of internal reviews, analysis and decision-making within the service provider’s system becomes a targeted action plan addressing key safety risks and the mitigations that effectively address them. The analysis from both the State and the service provider define the priority areas of safety concern, and outline the most effective means of addressing them. 8.5.3.7 Importantly, safety risk-based surveillance may not necessarily reduce the amount of surveillance conducted or the resources; the quality of the surveillance and the quality of the interaction between the regulator and the service provider will, however, improve greatly. Service provider organizational safety risk profiles 8.5.3.8 States may wish to develop organizational safety risk profiles that are consistent across each aviation sector to support the process of modifying the scope and frequency of their surveillance activities. Such tools should aim to capture and aggregate information that should already be available for service providers and may include factors such as: a) the financial health of the organization; b) number of years in operation; c) turnover rate of the key personnel such as the accountable executive and safety manager; d) competence and performance of the accountable executive; e) competence and performance of the safety manager; (for more information about accountable executive or safety manager competence, see Chapter 9) f) results of previous audits; g) timely and effective resolution of previous findings; h) measures of relative level of activity (exposure to safety risk); i) indicators of the relative scope and complexity of the activities being performed; j) maturity of the hazard identification and safety risk assessment process; and k) measures of safety performance from State safety data analysis and performance monitoring activities. 8.5.3.9 An example of a process that can be used to modify the scope or frequency of the surveillance of a service provider is shown in Figure 8-3. 8.5.4 Monitoring a service provider’s safety performance The State should periodically review each service provider’s SPIs and SPTs. The review should take into consideration the performance and effectiveness of each SPI and SPT. The review may show the need to make adjustments to support the continuous safety improvement. 8.5.5 State safety performance 8.5.5.1 For general information on safety performance management, refer to Chapter 4. Acceptable level of safety performance 8.5.5.2 States are required to establish the acceptable level of safety performance (ALoSP) to be achieved through their SSP. This can be achieved through: a) implementation and maintenance of the state safety program and; b) implementation and maintenance of SPIs and SPTs showing that safety is being effectively managed. 8.5.5.3 The ALoSP expresses the safety levels the State expects of its aviation system, including the targets that each sector needs to achieve and maintain in relation to safety, as well as measures to determine the effectiveness of their own activities and functions that impact safety. ALoSP, then, is a reflection of what the State considers important and is agreed on by the State level aviation stakeholders. ALoSP should not be developed in isolation. Rather, it should be defined having regard for higher level strategic guidance (from the GASP, Regional Plans, etc.) and the safety objectives established in the SSP. Establishing the ALoSP 8.5.5.4 The responsibility for establishing the ALoSP rests with the State’s aviation authorities, and will be expressed through the set of SPIs for the State, sectors and service providers under their authority. The goal is to maintain or continuously improve the safety performance of the entire aviation system measurement process outlined in Chapter 4. This enables the State to understand how it is doing with regard to safety and to act to impact the situation when necessary. The acceptance of service providers’ SPIs and targets is part of this process. 8.5.5.5 ALoSP represents the agreement between all State aviation authorities of the expected level of safety performance that its aviation system should deliver and demonstrates to internal and external stakeholders how the State is managing aviation safety. It includes, but is not limited to, the expectations for safety performance for each sector and service provider under the State’s authority. Establishing an ALoSP does not replace or supersede a State’s obligation to abide by the Convention on International Civil Aviation, including the implementation of all applicable SARPs. 8.5.5.6 Figure 8-4 outlines the concept of ALoSP based on SPIs and SPTs. Further information on safety objectives, SPIs and SPTs can be found in Chapter 4 and the subsequent paragraphs. Safety performance indicators and safety performance targets 8.5.5.7 Meaningful SPIs should reflect the specific operational environment and serve to highlight conditions that can be used to identify how safety risks are being controlled. The State monitoring and measurement strategy should include a set of SPIs that encompass all areas of the aviation system for which the State is responsible. It should reflect both outcomes (e.g. accidents, incidents, regulatory violations) as well as functions and activities (operations where the safety risk mitigations in place performed as expected). This combination allows safety performance to be evaluated by not only what does not work (i.e. outcomes), but also with consideration of what does work (i.e. activities where safety risk mitigations produced the expected results). In practical terms, this approach encompasses the consideration of SPIs reflecting two distinct types of safety risks: a) Operational safety risks (depicted on the left-hand side of the diagram) focuses on conditions that could lead to an unwanted outcome. These are the conditions associated with accidents, incidents, failures and defects. Operational safety risk is essentially a by-product of the delivery of services. For this reason, SPIs focused on operational safety risk will be mostly linked – indirectly – to service providers’ SMS. Although Figure 8-4 depicts three operational safety risks, the actual number should be based on the situation in each State. These SPIs reflect mainly operational safety issues identified by the safety risk management process of service providers. The State’s safety risk management process may also be used as an input, reflecting operational safety issues across the State aviation system derived from aggregation of service provider operational safety risk SPIs. There frequently will be a one-to-many relationship between an operational safety issue and related SPIs. That is, one operational safety issue may be indicated by several SPIs. b) Process implementation safety risks (depicted on the right-hand side of the diagram) focuses on the means and resources necessary for operational safety risk to be managed. Management of safety risk from a process implementation perspective starts with the evaluation of international civil aviation organization standard and recommended practices implementation status (safety-related national laws and regulations), the implementation of safety management system processes within the industry, and the implementation of state safety program at the State level (which includes effective oversight and monitoring of the industry). If improvements to any of the above are necessary, the activities to achieve them should be planned, implemented and monitored, and adequate resources should be allocated for these activities. SPIs are then developed that allow tracking of the planning, implementation and/or effectiveness of the changes. SPIs focused on “process implementation safety risk” provide the State an alternative means other than strict compliance to monitor the adequacy of safety management system institutional arrangement and implementation of SRM/safety assurance processes by service providers. These SPIs may also be established with reference to needed improvements, as shown by universal safety oversight program analyses and state safety program continuous improvement activities. The results of universal safety oversight program audits, aggregation of safety management system evaluations, and state safety program continuous improvement information determine potential areas for improvement. These should be prioritized according to greatest benefit. This will contribute to improvement in the State aviation system’s safety performance. These SPIs should be distinct from operational safety risk SPIs. 8.5.5.8 SPIs for both the operational and process implementation safety risks become a key part of the State’s safety assurance process. The aggregation of operational safety risk SPIs and process implementation safety risk SPIs broadens the feedback source for establishing the State ALoSP. Periodic review of safety performance indicators 8.5.5.9 A periodic review is essential once the State SPIs are established. Initially the identification of the top safety risks is an activity aided by analysis based on historical data. However, the aviation system is dynamic and constantly changing. New safety issues may arise, processes within the State may change, and so on. Periodic review of State operational safety issues and processes supports the update and refinement of the State safety objectives and consequently the SPIs and SPTs. Periodic review of ALoSP 8.5.5.10 The senior management team responsible for the original ALoSP agreement should determine the continued appropriateness of the ALoSP. The periodic review of the ALoSP should focus on: a) identifying critical safety issues within aviation sectors, ensuring inclusion of SPIs that allow safety performance management in these areas; b) identifying SPTs that define the safety performance level to be maintained or the desired improvement to be achieved for relevant SPI in each sector, with a view to enhancing safety performance management throughout the entire aviation system of the State; c) identifying triggers (if appropriate) when an SPI reaches a point that requires some action; and d) reviewing SPIs to determine whether modifications or additions to existing SPIs, SPTs and triggers (if appropriate) are needed to achieve the agreed ALoSP. 8.5.5.11 A result of the periodic review of the State’s top risks is a better understanding of the nature of each operational safety issue in as much detail as the data allows. The State should consider its hazards and their potential consequences at all levels of the State aviation system. It should also analyse how State processes (licensing, certification, authorization, approval, surveillance and so forth) contribute to SRM. Each operational safety risk is evaluated to identify the safety risk mitigations required. These actions are monitored through SPIs that measure their effectiveness. 8.5.5.12 Improving safety performance of operational safety risk tends to be reactive, while improving safety risk management processes tends to be proactive. Improving State processes that better support management of safety risk enables the identification and control of hazards before they manifest as negative outcomes. Achieving the ALoSP 8.5.5.13 A State’s safety performance as indicated by its SPIs and SPTs demonstrate the ALoSP achieved. If any of the SPTs are not met, an evaluation may be needed to better understand why and to determine what actions should be taken. It could be because: a) the targets were not achievable or realistic; b) the actions taken to achieve the target were not appropriate or deviated from the original intent (practical drift); c) changes in other safety risk priorities diverted resources away from meeting a particular target; or d) emerging risks occurred that had not been considered when the targets were set. 8.5.5.14 For the targets that were not met, there will be a need to understand why and for a management decision on whether the safety improvement is sufficient even if the target has not been met, and what further actions are required. This may require additional analysis that could identify some risk factors that were not addressed or maybe some risk mitigations in place that are not effective. 8.5.6 Management of change: State perspective 8.5.6.1 Annex 19 does not explicitly require a State to establish formal activities for the management of change under the SSP. However, changes are an ever-present fact in the contemporary aviation system. When changes are introduced into a system, the established safety risk picture of the system will change. Changes may introduce hazards that may impact the effectiveness of existing defences. This could result in new risk or changes to existing safety risks. States should evaluate and manage the impact of change in their aviation systems. 8.5.6.2 An state safety program should develop procedures to assess the impact of changes at a State level. The procedures should allow a State to proactively identify the safety impact of change in the aviation system before they are implemented, and plan and execute proposed changes in a structured way. 8.5.6.3 When changes are planned, the State should analyse the impact of the change on the existing system and, using the existing safety risk management process, analyse, assess and if appropriate mitigate any new or altered safety risks. No operation should take place in a changed system or operational context until all safety risks are evaluated. 8.5.6.4 A State will face two types of change under its SSP: organizational change (for example, reallocation of responsibilities or restructuring within State aviation authorities) and operational change (for example, a change in airspace usage). The management of change under state safety program should focus on those changes that could have a significant impact on the State’s ability to fulfil its legal obligations (process change) and on the State safety management capabilities. This might include a combination of process and operational changes. 8.5.6.5 Examples of changes with potential for significant impact to the safety risks of the State include, but are not limited to: a) reorganization of State aviation authorities (including downsizing); b) changes in the state safety program processes, including changes in methodology such as SRBS, safety risk management and safety assurance processes. c) changes in the regulatory environment, such as changes in existing State safety policies, programmes, and regulations; d) changes in the operational environment, such as introduction of new technologies, changes in infrastructure, equipment and services; e) rapidly changing industry (expanding, contracting, morphing) and its potential impact on the State oversight and performance monitoring capabilities. 8.5.6.6 Communicating the changes is fundamental to the effectiveness of the management of change. It is essential that effected personnel within the State and affected service provider(s) are well aware of the change, its timing and impacts. 8.6 COMPONENT 4: STATE SAFETY PROMOTION 8.6.1 From a State perspective, the need to implement internal and external State safety promotion action is established in Annex 19 as one of the components in States’ safety management responsibilities. Internally, CAAs and other aviation authorities involved with the state safety program should establish mechanisms to provide relevant safety information to its personnel to support the development of a culture that fosters an effective and efficient SSP. The communication of its safety policies, safety plans, as well as other important state safety program documentation can also improve awareness and collaboration among their staff, so that safety management processes put in place by States remain effective. 8.6.2 The improvement of safety performance within a State or a specific aviation sector is highly dependent on its safety culture. Actions related to the management of safety tend to be more effective when the organization has a positive safety culture. When visibly supported by upper- and middle management, frontline employees tend to feel a sense of shared responsibilities towards achieving their safety objectives. 8.6.3 Among other actions for the improvement of safety culture within an aviation system, the need for communication stands out for its importance. By constantly communicating its priorities, best practices, risks that standout in a particular operation, a State can foster a positive safety culture and maximise the potential of achieving its safety objectives, be it among the professionals of CAAs or service providers. Further details on safety culture can be found in Chapter 3. 8.6.4 Once employees embrace and understand their responsibilities towards safety performance, it is expected they will actively seek means and information that can be used for effectively accomplishing their responsibilities towards a safe aviation. This is an opportunity for safety promotion to play a key role in safety management. Externally, the establishment of communication channels with service providers should enable the sharing of lessons learned, best practices, SPIs and the provision of information on specific safety risks. This should support the implementation of safety management practices within service providers, supporting the development of a positive safety culture among peer organizations. Also, the establishment of routine communication efforts with service providers may increase general awareness on aviation safety issues and encourage further collaboration in identifying safety enhancement initiatives. 8.6.5 As States make decisions or take actions to improve aviation safety (e.g., establishing regulations or implementing changes to surveillance methods) it is also important they communicate internally as well as externally. This can strengthen the perception of the State commitment throughout the aviation community. This in turn may contribute to achievement of the State safety objectives. 8.6.6 Many resources and tools are available to support States in establishing their safety promotion actions. One way of structuring the many promotion actions a State can adopt is establishing a communications plan. Such a plan could include, at a minimum, the mapping of interested members of the aviation community, the messages and information conveyed to each of its groups, and the means by which this information will be transmitted. The communication plan may also act as a roadmap supporting the civil aviation authority to effectively develop the capability and channels to communicate with these internal and external audiences. This can be instrumental to States building a safety culture as well as in providing the necessary data and tools required by successful safety management, both from States’ perspective as well as service providers’. 8.6.7 Some information can be communicated through less formal bulletins and posts using social media, while others are better addressed in dedicated meetings or seminars. It is the role of the State to implement the adequate safety promotion channels and media they believe will achieve best results in developing a positive safety culture within the State and ultimately achieve an effective state safety program and a safer civil aviation system within the State. 8.6.8 Internal communication and dissemination of information Note.— Safety information from voluntary safety reporting systems shall be protected, unless a principle of protection applies. This can be extended to safety information from a mandatory reporting system. Please see Chapter 7 for more details on the protection of safety data, safety information and related sources. 8.6.8.1 Safety promotion actions and publications can also improve coordination and collaboration among different organizations involved with safety oversight within a State. The state safety program document and its associated State safety and enforcement policies are fundamental to achieving the integration of training, communication and the dissemination of related information. State regulatory authorities responsible for the different aviation sectors as well as other independent administrative entities such as the AIA should have an integrated approach to their respective roles in State safety promotion. States should establish formal communication channels between the members of the state safety program Coordination Group (State entities involved in implementing and maintaining the SSP). 8.6.8.2 From an operational perspective, it is important that state safety program operational strategies, including harmonized safety management system requirements and monitoring of the respective service providers are shared, communicated and coordinated amongst the State aviation authorities. An open communication channel may avoid the creation of conflicting safety management system requirements or acceptance criteria for different aviation sectors. 8.6.8.3 Examples of information States should address in their internal communication and dissemination include: a) state safety program documentation, policies, and procedures; b) SPIs; c) sector safety performance information; d) sector organizational safety risks profiles; e) communication of system safety responsibility; f) lessons learned from accidents and incidents; and g) concepts and best practices of safety management. 8.6.8.4 There is a particular need for open lines of safety communication when service providers are approved by more than one State. 8.6.8.5 There are several means State organizations may adopt to convey safety communication internally, such as newsletters, bulletins, leaflets, publications, seminars, meetings, training, websites, mailing lists, publications on social media, discussions in collaboration groups, among others. 8.6.8.6 When assessing which type of media should be used to convey a particular message, the organization should assess which one is more appropriate to each message and its targeted audience. state safety program documents may be posted on a website that is readily available to personnel when they are needed. Other information such as lessons learned and best practices may be more suitable for a periodic bulletin or newsletter. 8.6.8.7 Establishing campaigns to address a particular concern or hazard using multiple media may be effective in increasing awareness of the issue and changing personnel attitude. 8.6.9 External communication and dissemination of safety information 8.6.9.1 The State should establish appropriate communication platforms or media to facilitate safety management system implementation and improve system-wide safety culture. 8.6.9.2 When communicating and disseminating safety information externally with the aviation industry, in addition to the items presented in the previous section, States should also consider including: a) guidance material for the implementation of SMS; b) importance of reporting; c) identification of available safety training for the aviation community; d) promote the exchange of safety information: 1) with and among service providers; and 2) between States. 8.6.9.3 The State’s state safety program documentation and its related safety and enforcement policies should also be made available to service providers as appropriate. 8.6.9.4 Essentially, the same support media used for internal communications can be used externally as long as the content is useful for both audiences. For external communication, however, special attention may be given to solutions that reach larger audiences such as social media, mailing list bulletins, seminars, creating industry communities for the exchange of safety information, thus multiplying the messages’ outreach. 8.6.9.5 States should promote the establishment of safety information sharing or exchange networks among the aviation community, unless national law provides otherwise. 8.7 state safety program IMPLEMENTATION As with any major project implementation exercise, state safety program implementation involves many tasks and subtasks to be completed within a set timeframe. The number of tasks, as well as the scope of each task, is dependent upon the maturity of the State’s safety oversight system. In most States, several organizations and entities are involved in the development and implementation of an SSP. Development of an implementation plan can help to facilitate this process. This chapter lays out the steps from developing a comprehensive system description, considerations related to scalability, performing a gap analysis, and developing an implementation plan that includes ensuring that a solid state safety program foundation is established. This section also addresses the ongoing assessment of the maturity of an SSP. 8.7.1 State’s civil aviation system description and scalability considerations 8.7.1.1 The understanding of the size and complexity of a State’s aviation system and the interactions between the elements is fundamental to planning the SSP. A State is required to implement an SSP, but how the requirements are met will depend on the size and complexity of the aviation system. More information about scalability can be found in Chapter 1. 8.7.1.2 The state safety program will also have regard for the number of service providers in each aviation domain, their size and complexity and regional environment. States with a small number of service providers should consider establishing regional partnerships. Regional partnerships with other States or through RSOOs, and sharing lessons learned and safety risk information will minimise the impact while maximising the benefits of state safety program implementation. 8.7.1.3 The State should describe the aviation system and the various State aviation authorities in a civil aviation system description. This should include an overview of organizational structures and interfaces. This is part of the state safety program implementation planning process. Such a review should include a description of the following: a) the structure of the existing aviation regulatory framework, including the various State aviation authorities; b) safety management roles and accountabilities of the various regulatory authorities; c) platform or mechanism for coordination of the state safety program among the organizations; and d) an internal review mechanism at the State level and within each organization. 8.7.2 state safety program gap analysis and implementation plan state safety program gap analysis 8.7.2.1 A gap analysis should be conducted before developing an state safety program implementation plan. The gap analysis aims to gain a detailed understanding of the gap between the existing State structures and processes, and those required for an effective state safety program implementation in the State. For many States, the gap analysis reveals that considerable safety management capability already exists. The challenge, typically, is to refine, realign and bolster these existing capabilities. The elements or processes identified as requiring action form the basis of the state safety program implementation plan. state safety program foundation 8.7.2.2 It is essential that States establish a mature foundation to support effective state safety program implementation. The GASP objectives call for States to progressively implement effective safety oversight systems, SSPs and advanced safety management capabilities necessary to support future aviation systems. This foundation is comprised of the aspects of a safety oversight system that are needed to support a more performance-based approach. 8.7.2.3 Data collected through the international civil aviation organization Universal Safety Oversight Audit Programme (USOAP) can be used to identify deficiencies in this foundation. Addressing any unsatisfactory universal safety oversight program protocol questions related to issues that are linked to effective state safety program implementation (e.g. mandatory reporting systems), should be the first step in implementing SSP. state safety program implementation plan 8.7.2.4 The state safety program implementation aims to progressively enhance the existing SSO and safety management processes. The appropriate tasks/subtasks are prioritized and documented in an action plan. An state safety program implementation plan, together with the state safety program top-level (exposition) document, provide the “blueprints” which guides the State’s journey toward effective SSP, and continuous improvement of safety performance. These two key documents should be made readily accessible to all relevant personnel to ensure everyone involved is aware of the state safety program and its plans for implementation. 8.7.3 state safety program maturity assessment Background and purpose 8.7.3.1 The assessment of the SSP’s maturity should be conducted using a tool that reflects international civil aviation organization standard and recommended practices and guidance material, developed by the State to meet its needs. The tool should be used by States to perform internal audits for the continuous improvement of the SSP. They should also be referred to by international civil aviation organization and other external entities as appropriate. The tool should be based on a series of questions (or expectations) that can be used by the State to assess the effectiveness of its SSP. The state safety program maturity assessment will benefit from interactions, such as face-to-face discussions and interviews, with a cross section with all interested parties. The tool should be flexible and account for the size and complexity of the State’s aviation system. Assessment 8.7.3.2 Once the basic aspects of the state safety program are installed, an assessment of the documentation can be conducted. The assessment aims to discover whether or not the compliance and performance expectations of the state safety program are present and suitable. Evidence should be collected to support the assessment. At a later stage, the state safety program can be assessed to understand how well it is operating and how effective it is at achieving its objectives. Effectiveness is achieved when the outcome produces the desired result each time. A team with appropriate state safety program competence and technical expertise normally conducts the assessment and collects the evidence. It is important to structure the assessment in a way that allows interaction with a number of people at different levels of the organization to determine effectiveness throughout the organization. For example, determining the extent that the safety policy has been promulgated and understood by staff will require interaction with a cross section of personnel. Ongoing monitoring and continuous improvement 8.7.3.3 The State may utilize the same tool to assess the effectiveness of its state safety program during ongoing monitoring and continuous improvement. The assessment will likely identify changes to the aviation system. For most States, state safety program will take time to implement and several years to mature to a level where all the elements are working effectively. Figure 8-5 illustrates the different levels of state safety program maturity as a State implements and develops its SSP. 8.7.3.4 An state safety program assessment can be carried out at various stages, looking initially for the presence and suitability of key elements. At a later stage, the state safety program can be assessed to understand how well it is operating and how effective it is at achieving its objectives. States can continue to perform assessments periodically to support the continuous improvement towards excellence. Chapter 9 SAFETY MANAGEMENT SYSTEMS (SMS) 9.1 INTRODUCTION 9.1.1 This chapter provides guidance for service providers on the implementation of an safety management system framework in accordance with Annex 19 and guidance for States on the oversight of SMS. 9.1.2 The purpose of an safety management system is to provide service providers with a systematic approach to managing safety. It is designed to continuously improve safety performance through: the identification of hazards, the collection and analysis of safety data and safety information, and the continuous assessment of safety risks. The safety management system seeks to proactively mitigate safety risks before they result in aviation accidents and incidents. It allows service providers to effectively manage their activities, safety performance and resources, while gaining a greater understanding of their contribution to aviation safety. An effective safety management system demonstrates to States the service provider’s ability to manage safety risks and provides for effective management of safety at the State level. 9.1.3 International general aviation operators should determine the safety management system criteria for the aircraft they are operating, as established by the State of Registry, and ensure their safety management system is acceptable to the State of Registry. To facilitate the acceptability of the SMS, international general aviation operators should ask the State of Registry if the use of an industry code of practice is permitted. 9.1.4 Operators of large or turbojet aeroplanes under multiple States of Registry with an air operator certificate issued in accordance with Annex 6, Part I, are considered to be service providers, therefore, the safety management system must be made acceptable to the State of the Operator. 9.2 safety management system FRAMEWORK 9.2.1 Annex 19 specifies the framework for the implementation and maintenance of an SMS. Regardless of the service provider’s size and complexity, all elements of the safety management system framework apply. The implementation should be tailored to the organization and its activities. 9.2.2 The international civil aviation organization safety management system framework is made up of the following four components and twelve elements: 1. Safety policy and objectives 1.1 Management commitment 1.2 Safety accountability and responsibilities 1.3 Appointment of key safety personnel 1.4 Coordination of emergency response planning 1.5 safety management system documentation 2. Safety risk management 2.1 Hazard identification 2.2 Safety risk assessment and mitigation 3. Safety assurance 3.1 Safety performance monitoring and measurement 3.2 The management of change 3.3 Continuous improvement of the safety management system 4. Safety promotion 4.1 Training and education 4.2 Safety communication 9.3 COMPONENT 1: SAFETY POLICY AND OBJECTIVES 9.3.1 The first component of the safety management system framework focuses on creating an environment where safety management can be effective. It is founded on a safety policy and objectives that set out senior management’s commitment to safety, its goals and the supporting organizational structure. 9.3.2 Management commitment and safety leadership is key to the implementation of an effective safety management system and is asserted through the safety policy and the establishment of safety objectives. Management commitment to safety is demonstrated through management decision-making and allocation of resources; these decisions and actions should always be consistent with the safety policy and objectives to cultivate a positive safety culture. 9.3.3 The safety policy should be developed and endorsed by senior management, and is to be signed by the accountable executive. Key safety personnel, and where appropriate, staff representative bodies (employee forums, trade unions) should be consulted in the development of the safety policy and safety objectives to promote a sense of shared responsibility. 9.3.4 Management commitment Safety policy 9.3.4.1 The safety policy should be visibly endorsed by senior management and the accountable executive. “Visible endorsement” refers to making management’s active support of the safety policy visible to the rest of the organization. This can be done via any means of communication and through the alignment of activities to the safety policy. 9.3.4.2 It is the responsibility of management to communicate the safety policy throughout the organization to ensure all personnel understand and work in accordance with the safety policy. 9.3.4.3 To reflect the organization’s commitment to safety, the safety policy should include a commitment to: a) continuously improve the level of safety performance; b) promote and maintain a positive safety culture within the organization; c) comply with all applicable regulatory requirements; d) provide the necessary resources to deliver a safe product or service; e) ensure safety is a primary responsibility of all managers; and f) ensure it is understood, implemented and maintained at all levels. 9.3.4.4 The safety policy should also make reference to the safety reporting system to encourage the reporting of safety issues and inform personnel of the disciplinary policy applied in the case of safety events or safety issues that are reported. 9.3.4.5 The disciplinary policy is used to determine whether an error or rule breaking has occurred so that the organization can establish whether any disciplinary action should be taken. To ensure the fair treatment of persons involved, it is essential that those responsible for making that determination have the necessary technical expertise so that the context of the event may be fully considered. 9.3.4.6 A policy on the protection of safety data and safety information, as well as reporters, can have a positive effect on the reporting culture. The service provider and the State should allow for the de-identification and aggregation of reports to allow meaningful safety analyses to be conducted without having to implicate personnel or specific service providers. Because major occurrences may invoke processes and procedures outside of the service provider’s SMS, the relevant State authority may not permit the early de-identification of reports in all circumstances. Nonetheless, a policy allowing for the appropriate de-identification of reports can improve the quality of data collected. Safety objectives 9.3.4.7 Taking into consideration its safety policy, the service provider should also establish safety objectives to define what it aims to achieve in respect of safety outcomes. Safety objectives should be short, high-level statements of the organization’s safety priorities and should address its most significant safety risks. Safety objectives may be included in the safety policy (or documented separately), and defines what the organization intends to achieve in terms of safety. Safety performance indicators (SPIs) and safety performance targets (SPTs) are needed to monitor the achievement of these safety objectives and are further elaborated on later in this Chapter under Component 3. 9.3.4.8 The safety policy and safety objectives should be periodically reviewed to ensure they remain current (a change in the accountable executive would require its review for instance). 9.3.5 Safety accountability and responsibilities Accountable executive 9.3.5.1 The accountable executive, typically the chief executive officer, is the person who has ultimate authority over the safe operation of the organization. The accountable executive establishes and promotes the safety policy and safety objectives that instil safety as a core organizational value. They should: have the authority to make decisions on behalf of the organization, have control of resources, both financial and human, be responsible for ensuring appropriate actions are taken to address safety issues and safety risks, and they should be responsible for responding to accidents and incidents. 9.3.5.2 There might be challenges for the service provider to identify the most appropriate person to be the accountable executive, especially in large complex organizations with multiple entities and multiple certificates, authorizations or approvals. It is important the person selected is organizationally situated at the highest level of the organization, thus ensuring the right strategic safety decisions are made. 9.3.5.3 The service provider is required to identify the accountable executive, placing the responsibility for the overall safety performance at a level in the organization with the authority to take action to ensure the safety management system is effective. Specific safety accountabilities of all members of management should be defined and their role in relation to the safety management system should reflect how they can contribute towards a positive safety culture. The safety responsibilities, accountabilities and authorities should be documented and communicated throughout the organization. The safety accountabilities of managers should include the allocation of the human, technical, financial or other resources necessary for the effective and efficient performance of the SMS. Note.— The term “accountability” refers to obligations which cannot be delegated. The term “responsibilities” refers to functions and activities which may be delegated. 9.3.5.4 In the case where an safety management system applies to several different certificates, authorizations or approvals that are all part of the same legal entity, there should be a single accountable executive. Where this is not possible, individual accountable executives should be identified for each organizational certificate, authorization or approval and clear lines of accountability defined; it is also important to identify how their safety accountabilities will be coordinated. 9.3.5.5 One of the most effective ways the accountable executive can be visibly involved, is by leading regular executive safety meetings. As they are ultimately responsible for the safety of the organization, being actively involved in these meetings allows the accountable executive to: a) review safety objectives; b) monitor safety performance and the achievement of safety targets; c) make timely safety decisions; d) allocate appropriate resources; e) hold managers accountable for safety responsibilities, performance and implementation timelines; and f) be seen by all personnel as an executive who is interested in, and in charge of, safety. 9.3.5.6 The accountable executive is not usually involved in the day-to-day activities of the organization or the problems faced in the workplace and should ensure there is an appropriate organizational structure to manage and operate the SMS. Safety management responsibility is often delegated to the senior management team and other key safety personnel. Although responsibility for the day-to-day operation of the safety management system can be delegated, the accountable executive cannot delegate accountability for the system nor can decisions regarding safety risks be delegated. For example, the following safety accountabilities cannot be delegated: a) ensuring safety policies are appropriate and communicated; b) ensuring necessary allocation of resources (financing, personnel, training, acquisition); and c) setting of the acceptable safety risk limits and resourcing of necessary controls. 9.3.5.7 It is appropriate for the accountable executive to have the following safety accountabilities: a) provide enough financial and human resources for the proper implementation of an effective SMS; b) promote a positive safety culture; c) establish and promote the safety policy; d) establish the organization’s safety objectives; e) ensure the safety management system is properly implemented and performing to requirements; and f) see to the continuous improvement of the SMS. 9.3.5.8 The accountable executive’s authorities include, but are not limited to, having final authority: a) for the resolution of all safety issues; and b) over operations under the certificate, authorization or approval of the organization, including the authority to stop the operation or activity. 9.3.5.9 The authority to make decisions regarding safety risk tolerability should be defined. This includes who can make decisions on the acceptability of risks as well as the authority to agree that a change can be implemented. The authority may be assigned to an individual, a management position or a committee. 9.3.5.10 Authority to make safety risk tolerability decisions should be commensurate with the manager's general decision-making and resource allocation authority. A lower level manager (or management group) may be authorized to make tolerability decisions up to a certain level. Risk levels that exceed the manager's authority must be escalated for consideration to a higher management level with greater authority. Accountability and responsibilities 9.3.5.11 Accountabilities and responsibilities of all personnel, management and staff, involved in safety-related duties supporting the delivery of safe products and operations should be clearly defined. The safety responsibilities should focus on the staff member's contribution to the safety performance of the organization (the organizational safety outcomes). The management of safety is a core function; as such every senior manager has a degree of involvement in the operation of the SMS. 9.3.5.12 All defined accountabilities, responsibilities and authorities should be stated in the service provider’s safety management system documentation and should be communicated throughout the organization. The safety accountabilities and responsibilities of each senior manager are integral components of their job descriptions. This should also capture the different safety management functions between line managers and the safety manager (see 9.3.6 for further details). 9.3.5.13 Lines of safety accountability throughout the organization and how they are defined will depend on the type and complexity of the organization, and their preferred communication methods. Typically, the safety accountabilities and responsibilities will be reflected in organizational charts, documents defining departmental responsibilities, and personnel job or role descriptions. 9.3.5.14 The service provider should aim to avoid conflicts of interest between staff members’ safety responsibilities and their other organizational responsibilities. They should allocate their safety management system accountabilities and responsibilities, in a way that minimizes any overlaps and/or gaps. Accountability and responsibilities and in respect to external organizations 9.3.5.15 A service provider is responsible for the safety performance of external organizations where there is an safety management system interface. The service provider may be held accountable for the safety performance of products or services provided by external organizations supporting its activities even if the external organizations are not required to have an SMS. It is essential for the service provider’s safety management system to interface with the safety systems of any external organizations that contribute to the safe delivery of their product or services. 9.3.6 Appointment of key safety personnel 9.3.6.1 Appointment of a competent person or persons to fulfil the role of safety manager is essential to an effectively implemented and functioning SMS. The safety manager may be identified by different titles. For the purposes of this manual, the generic term “safety manager” is used and refers to the function, not necessarily to the individual. The person carrying out the safety manager function is responsible to the accountable executive for the performance of the safety management system and for the delivery of safety services to the other departments in the organization. 9.3.6.2 The safety manager advises the accountable executive and line managers on safety management matters, and is responsible for coordinating and communicating safety issues within the organization as well as with external members of the aviation community. Functions of the safety manager include, but are not limited to: a) manage the safety management system implementation plan on behalf of the accountable executive (upon initial implementation); b) perform/facilitate hazard identification and safety risk analysis; c) monitor corrective actions and evaluate their results; d) provide periodic reports on the organization’s safety performance; e) maintain safety management system documentation and records; f) plan and facilitate staff safety training; g) provide independent advice on safety matters; h) monitor safety concerns in the aviation industry and their perceived impact on the organization’s operations aimed at product and service delivery; and i) coordinate and communicate (on behalf of the accountable executive) with the State’s civil aviation authority and other State authorities as necessary on issues relating to safety. 9.3.6.3 In most organizations, an individual is appointed as the safety manager. Depending on the size, nature and complexity of the organization, the safety manager role may be an exclusive function or it may be combined with other duties. Moreover, some organizations may need to allocate the role to a group of persons. The organization must ensure that the option chosen does not result in any conflicts of interest. Where possible, the safety manager should not be directly involved in the product or service delivery but should have a working knowledge of these. The appointment should also consider potential conflicts of interest with other tasks and functions . Such conflicts of interest could include: a) competition for funding (e.g. financial manager being the safety manager); b) conflicting priorities for resources; and c) where the safety manager has an operational role and the ability to assess the safety management system effectiveness of the operational activities the safety manager is involved in. 9.3.6.4 In cases where the function is allocated to a group of persons, (e.g. when service providers extend their safety management system across multiple activities) one of the persons should be designated as “lead” safety manager, to maintain a direct and unequivocal reporting line to the accountable executive. 9.3.6.5 The competencies for a safety manager should include, but not be limited to, the following: a) safety/quality management experience; b) operational experience related to the product or service provided by the organization; c) technical background to understand the systems that support operations or the product/service provided; d) interpersonal skills; e) analytical and problem-solving skills; f) project management skills; g) oral and written communications skills; and h) an understanding of human factors. 9.3.6.6 Depending on the size, nature and complexity of the organization, additional staff may support the safety manager. The safety manager and supporting staff are responsible for ensuring the prompt collection and analysis of safety data and appropriate distribution within the organization of related safety information such that safety risk decisions and controls, as necessary, can be made. 9.3.6.7 Service providers should establish appropriate safety committees that support the safety management system functions across the organization. This should include determining who should be involved in the safety committee and frequency of the meetings. 9.3.6.8 The highest-level safety committee, sometimes referred to as a safety review board (SRB), includes the accountable executive and senior managers with the safety manager participating in an advisory capacity. The SRB is strategic and deals with high-level issues related to safety policies, resource allocation and organizational performance. The SRB monitors the: a) effectiveness of the SMS; b) timely response in implementing necessary safety risk control actions; c) safety performance against the organization’s safety policy and objectives; d) overall effectiveness of safety risk mitigation strategies; e) effectiveness of the organization’s safety management processes which support: 1) the declared organizational priority of safety management; and 2) promotion of safety across the organization. 9.3.6.9 Once a strategic direction has been developed by the highest-level safety committee, implementation of safety strategies should be coordinated throughout the organization. This may be accomplished by creating safety action groups (SAGs) that are more operationally focused. SAGs are normally composed of managers and front-line personnel and are chaired by a designated manager. SAGs are tactical entities that deal with specific implementation issues in accordance with the strategies developed by the SRB. The SAGs: a) monitor operational safety performance within their functional areas of the organization and ensure that appropriate safety risk management activities are carried out; b) review available safety data and identify the implementation of appropriate safety risk control strategies and ensure employee feedback is provided; c) assess the safety impact related to the introduction of operational changes or new technologies; d) coordinate the implementation of any actions related to safety risk controls and ensure that actions are taken promptly; and e) review the effectiveness of specific safety risk controls. 9.3.7 Coordination of emergency response planning 9.3.7.1 By definition, an emergency is a sudden, unplanned situation or event requiring immediate action. Coordination of emergency response planning refers to planning for activities that take place within a limited period of time during an unplanned aviation operational emergency situation. An emergency response plan (ERP) is an integral component of a service provider’s safety risk management process to address aviation-related emergencies, crises or events. Where there is a possibility of a service provider’s aviation operations or activities being compromised by emergencies such as a public health emergency/pandemic, these scenarios should also be addressed in its ERP as appropriate. The ERP should address foreseeable emergencies as identified through the safety management system and include mitigating actions, processes and controls to effectively manage aviation-related emergencies. 9.3.7.2 The overall objective of the ERP is the safe continuation of operations and the return to normal operations as soon as possible. This should ensure an orderly and efficient transition from normal to emergency operations, including assignment of emergency responsibilities and delegation of authority. It includes the period of time required to re-establish “normal” operations following the emergency. The ERP identifies actions to be taken by responsible personnel during an emergency. Most emergencies will require coordinated action between different organizations, possibly with other service providers and with other external organizations such as non-aviation-related emergency services. The ERP should be easily accessible to the appropriate key personnel as well as to the coordinating external organizations. 9.3.7.3 Coordination of emergency response planning applies only to those service providers required to establish and maintain an ERP. Annex 19 does not require the creation or development of an ERP; emergency response planning is applicable only to specific service providers as established in the relevant international civil aviation organization Annexes (different terms for provisions related to dealing with emergency situations may be used in other Annexes). This coordination should be exercised as part of the periodic testing of the ERP. 9.3.8 safety management system Documentation 9.3.8.1 The safety management system documentation should include a top-level “SMS manual”, which describes the service provider’s safety management system policies, processes and procedures to facilitate the organization’s internal administration, communication and maintenance of the SMS. It should help personnel to understand how the organization’s safety management system functions, and how the safety policy and objectives will be met. The documentation should include a system description that provides the boundaries of the SMS. It should also help clarify the relationship between the various policies, processes, procedures and practices, and define how these link to the service provider’s safety policy and objectives. The documentation should be adapted and written to address the day-to-day safety management activities that can be easily understood by personnel throughout the organization. 9.3.8.2 The safety management system manual also serves as a primary safety communication tool between the service provider and key safety stakeholders (e.g. civil aviation authority for the purpose of regulatory acceptance, assessment and subsequent monitoring of the SMS). The safety management system manual may be a stand-alone document, or it may be integrated with other organizational documents (or documentation) maintained by the service provider. Where details of the organization’s safety management system processes are already addressed in existing documents, appropriate cross-referencing to such documents is enough. This safety management system document must be kept up to date. civil aviation authority agreement may be required before significant amendments are made to the safety management system manual, as it is a controlled manual. 9.3.8.3 The safety management system manual should include a detailed description of the service provider’s policies, processes and procedures including: a) safety policy and safety objectives; b) reference to any applicable regulatory safety management system requirements; c) system description; d) safety accountabilities and key safety personnel; e) voluntary and mandatory safety reporting system processes and procedures; f) hazard identification and safety risk assessment processes and procedures; g) safety investigation procedures; h) procedures for establishing and monitoring safety performance indicators; i) safety management system training processes and procedures and communication; j) safety communication processes and procedures; k) internal audit procedures; l) management of change procedures; m) safety management system documentation management procedures; and n) where applicable, coordination of emergency response planning. 9.3.8.4 safety management system documentation also includes the compilation and maintenance of operational records substantiating the existence and ongoing operation of the SMS. Operational records are the outputs of the safety management system processes and procedures such as the safety risk management and safety assurance activities. safety management system operational records should be stored and kept in accordance with existing retention periods. Typical safety management system operational records should include: a) hazards register and hazard/safety reports; b) SPIs and related charts; c) record of completed safety risk assessments; d) safety management system internal review or audit records; e) internal audit records; f) records of SMS/safety training records; g) SMS/safety committee meeting minutes; h) safety management system implementation plan (during the initial implementation); and i) gap analysis to support implementation plan. 9.4 COMPONENT 2: SAFETY RISK MANAGEMENT 9.4.1 Service providers should ensure they are managing their safety risks. This process is known as safety risk management (SRM), which includes hazard identification, safety risk assessment and safety risk mitigation. 9.4.2 The safety risk management process systematically identifies hazards that exist within the context of the delivery of its products or services. Hazards may be the result of systems that are deficient in their design, technical function, human interface or interactions with other processes and systems. They may also result from a failure of existing processes or systems to adapt to changes in the service provider’s operating environment. Careful analysis of these factors can often identify potential hazards at any point in the operation or activity life cycle. 9.4.3 Understanding the system and its operating environment is essential for the achievement of high safety performance. Having a detailed system description that defines the system and its interfaces will help. Hazards may be identified throughout the operational life cycle from internal and external sources. Safety risk assessments and safety risk mitigations will need to be continuously reviewed to ensure they remain effective. Figure 9-1 provides an overview of the hazard identification and safety risk management process for a service provider. Note.— Detailed guidance on hazard identification and safety risk assessment procedures is addressed in Chapter 2. 9.4.4 Hazard identification Hazard identification is the first step in the safety risk management process. The service provider should develop and maintain a formal process to identify hazards that could impact aviation safety in all areas of operation and activities. This includes equipment, facilities and systems. Any aviation safety-related hazard identified and controlled is beneficial for the safety of the operation. It is important to also consider hazards that may exist as a result of the safety management system interfaces with external organizations. Sources for hazard identification 9.4.4.1 There are a variety of sources for hazard identification, internal or external to the organization. Some internal sources include: a) Normal operations monitoring; this uses observational techniques to monitor the day-to-day operations and activities such as line operations safety audit (LOSA). b) Automated monitoring systems; this uses automated recording systems to monitor parameters that can be analysed such as flight data monitoring (FDM). c) Voluntary and mandatory safety reporting systems; this provides everyone, including staff from external organizations, with opportunities to report hazards and other safety issues to the organization. d) Audits; these can be used to identify hazards in the task or process being audited. These should also be coordinated with organizational changes to identify hazards related to the implementation of the change. e) Feedback from training; training that is interactive (two way) can facilitate identification of new hazards from participants. f) Service provider safety investigations; hazards identified in internal safety investigation and follow-up reports on accidents/incidents. 9.4.4.2 Examples of external sources for hazard identification include: a) Aviation accident reports; reviewing accident reports; this may be related to accidents in the same State or to a similar aircraft type, region or operational environment. b) State mandatory and voluntary safety reporting systems; some States provide summaries of the safety reports received from service providers. c) State oversight audits and third-party audits; external audits can sometimes identify hazards. These may be documented as an unidentified hazard or captured less obviously within an audit finding. d) Trade associations and information exchange systems; many trade associations and industry groups are able to share safety data that may include identified hazards. Safety reporting system 9.4.4.3 One of the main sources for identifying hazards is the safety reporting system, especially the voluntary safety reporting system. Whereas the mandatory system is normally used for incidents that have occurred, the voluntary system provide an additional reporting channel for potential safety issues such as hazards, near misses or errors. They can provide valuable information to the State and service provider on lower consequence events. 9.4.4.4 It is important that service providers provide appropriate protections to encourage people to report what they see or experience. For example, enforcement action may be waived for reports of errors, or in some circumstances, rule-breaking. It should be clearly stated that reported information will be used solely to support the enhancement of safety. The intent is to promote an effective reporting culture and proactive identification of potential safety deficiencies. 9.4.4.5 Voluntary safety reporting systems should be confidential, requiring that any identifying information about the reporter is known only to the custodian to allow for follow-up action. The role of custodian should be kept to a few individuals, typically restricted to the safety manager and personnel involved in the safety investigation. Maintaining confidentiality will help facilitate the disclosure of hazards leading to human error, without fear of retribution or embarrassment. Voluntary safety reports may be de-identified and archived once necessary follow-up actions are taken. De-identified reports can support future trending analyses to track the effectiveness of risk mitigation and to identify emerging hazards. 9.4.4.6 Personnel at all levels and across all disciplines are encouraged to identify and report hazards and other safety issues through their safety reporting systems. To be effective, safety reporting systems should be readily accessible to all personnel. Depending on the situation, a paper-based, web-based or desktop form can be used. Having multiple entry methods available maximizes the likelihood of staff engagement. Everyone should be made aware of the benefits of safety reporting and what should be reported. 9.4.4.7 Anybody who submits a safety report should receive feedback on what decisions or actions have been taken. The alignment of reporting system requirements, analysis tools and methods can facilitate exchange of safety information as well as comparisons of certain safety performance indicators. Feedback to reporters in voluntary reporting schemes also serves to demonstrate that such reports are considered seriously. This helps to promote a positive safety culture and encourage future reporting. 9.4.4.8 There may be a need to filter reports on entry when there are a large number of safety reports. This may involve an initial safety risk assessment to determine whether further investigation is necessary and what level of investigation is required. 9.4.4.9 Safety reports are often filtered through the use of a taxonomy, or a classification system. Filtering information using a taxonomy can make it easier to identify common issues and trends. The service provider should develop taxonomies that cover their type(s) of operation. The disadvantage of using a taxonomy is that sometimes the identified hazard does not fit cleanly into any of the defined categories. The challenge then is to use taxonomies with the appropriate degree of detail; specific enough that hazards are easy to allocate, yet generic enough that the hazards are valuable for analysis. Some States and international trade associations have developed taxonomies that could be used. Chapter 5 contains additional information on taxonomies. 9.4.4.10 Other methods of hazard identification include workshops or meetings in which subject matter experts conduct detailed analysis scenarios. These sessions benefit from the contributions of a range of experienced operational and technical personnel. Existing safety committee meetings (SRB, SAG, etc.) could be used for such activities; the same group may also be used to assess associated safety risks. 9.4.4.11 Identified hazards and their potential consequences should be documented. This will be used for safety risk assessment processes. 9.4.4.12 The hazard identification process considers all possible hazards that may exist within the scope of the service provider’s aviation activities including interfaces with other systems, both within and external to the organization. Once hazards are identified, their consequences (i.e. any specific events or outcomes) should be determined. Investigation of hazards 9.4.4.13 Hazard identification should be continuous and part of the service provider’s ongoing activities. Some conditions may merit more detailed investigation. These may include: a) instances where the organization experiences an unexplained increase in aviation safety-related events or regulatory non-compliance; or b) significant changes to the organization or its activities. 9.4.5 Service provider safety investigation 9.4.5.1 Effective safety management depends on quality investigations to analyse safety occurrences and safety hazards, and report findings and recommendations to improve safety in the operating environment. 9.4.5.2 There is a clear distinction between accident and incident investigations under Annex 13 and service provider safety investigations. Investigation of accidents and serious incidents under Annex 13 are the responsibility of the State, as defined in Annex 13. This type of information is essential to disseminate lessons learned from accidents and incidents. Service provider safety investigations are conducted by service providers as part of their safety management system to support hazard identification and risk assessment processes. There are many safety occurrences that fall outside of Annex 13 that could provide a valuable source of hazard identification or identify weaknesses in risk controls. These problems might be revealed and remedied by a safety investigation led by the service provider. 9.4.5.3 The primary objective of the service provider safety investigation is to understand what happened, and how to prevent similar situations from occurring in the future by eliminating or mitigating safety deficiencies. This is achieved through careful and methodical examination of the event and by applying the lessons learned to reduce the probability and/or consequence of future recurrences. Service provider safety investigations are an integral part of the service provider's SMS. 9.4.5.4 Service provider investigations of safety occurrences and hazards are an essential activity of the overall risk management process in aviation. The benefits of conducting a safety investigation include: a) gaining a better understanding of the events leading up to the occurrence; b) identifying contributing human, technical and organizational factors; c) identifying hazards and conducting risk assessments; d) making recommendations to reduce or eliminate unacceptable risks; and e) identifying lessons learned that should be shared with the appropriate members of the aviation community. Investigation triggers 9.4.5.5 A service provider safety investigation is usually triggered by a notification (report) submitted through the safety reporting system. Figure 9-2 outlines the safety investigation decision process and the distinction between when a service provider safety investigation should take place and when an investigation under Annex 13 provisions should be initiated. 9.4.5.6 Not all occurrences or hazards can or should be investigated; the decision to conduct an investigation and its depth should depend on the actual or potential consequences of the occurrence or hazard. Occurrences and hazards considered to have a high-risk potential are more likely to be investigated and should be investigated in greater depth than those with lower risk potential. Service providers should use a structured decision-making approach with defined trigger points. These will guide the safety investigation decisions: what to investigate and the scope of the investigation. This could include: a) the severity or potential severity of the outcome b) regulatory or organizational requirements to carry out an investigation; c) safety value to be gained; d) opportunity for safety action to be taken; e) risks associated with not investigating; f) contribution to targeted safety programmes; g) identified trends; h) training benefit; and i) resources availability. Assigning an investigator 9.4.5.7 If an investigation is to commence, the first action will be to appoint an investigator or where the resources are available, an investigation team with the required skills and expertise. The size of the team and the expertise profile of its members depend on the nature and severity of the occurrence being investigated. The investigating team may require the assistance of other specialists. Often, a single person is assigned to carry out an internal investigation, with support from operations and safety office experts. 9.4.5.8 Service provider safety investigators are ideally organizationally independent from the area associated with the occurrence or identified hazard. Better results will be obtained if the investigator(s) are knowledgeable (trained) and skilled (experienced) in service provider safety investigations. The investigators would ideally be chosen for the role because of their knowledge, skills and character traits, which should include: integrity, objectivity, logical thinking, pragmatism, and lateral thinking. The investigation process 9.4.5.9 The investigation should identify what happened and why it happened and this may require root cause analysis to be applied as part of the investigation. Ideally, the people involved in the event should be interviewed as soon as possible after the event. The investigation should include: a) establishing timelines of key events, including the actions of the people involved; b) review of any policies and procedures related to the activities; c) review of any decisions made related to the event; d) identifying any risk controls that were in place that should have prevented the event occurring; and e) reviewing safety data for any previous or similar events. 9.4.5.10 The safety investigation should focus on the identified hazards and safety risks and opportunities for improvement, not on blame or punishment. The way the investigation is conducted, and most importantly, how the report is written, will influence the likely safety impact, the future safety culture of the organization, and the effectiveness of future safety initiatives. 9.4.5.11 The investigation should conclude with clearly defined findings and recommendations that eliminate or mitigate safety deficiencies. 9.4.6 Safety risk assessment and mitigation 9.4.6.1 The service provider must develop a safety risk assessment model and procedures which will allow a consistent and systematic approach for the assessment of safety risks. This should include a method that will help determine what safety risks are acceptable or unacceptable and to prioritize actions. 9.4.6.2 The safety risk management tools used may need to be reviewed and customized periodically to ensure they are suitable for the service provider’s operating environment. The service provider may find more sophisticated approaches that better reflect the needs of their operation as their safety management system matures. The service provider and civil aviation authority should agree on a methodology. 9.4.6.3 More sophisticated approaches to safety risk classification are available. These may be more suitable if the service provider is experienced with safety management or operating in a high-risk environment. 9.4.6.4 The safety risk assessment process should use whatever safety data and safety information is available. Once safety risks have been assessed, the service provider will engage in a data-driven decision-making process to determine what safety risk controls are needed. 9.4.6.5 Safety risk assessments sometimes have to use qualitative information (expert judgement) rather than quantitative data due to unavailability of data. Using the safety risk matrix allows the user to express the safety risk(s) associated with the identified hazard in a quantitative format. This enables direct magnitude comparison between identified safety risks. A qualitative safety risk assessment criterion such as “likely to occur” or “improbable” may be assigned to each identified safety risk where quantitative data is not available. 9.4.6.6 For service providers that have operations in multiple locations with specific operating environments, it may be more effective to establish local safety committees to conduct safety risk assessments and safety risk control identification. Advice is often sought from a specialist in the operational area (internal or external to the service provider). Final decisions or control acceptance may be required from higher authorities so that the appropriate resources are provided. 9.4.6.7 How service providers go about prioritizing their safety risk assessments and adopting safety risk controls is their decision. As a guide, the service provider should find the prioritization process: a) assesses and controls highest safety risk; b) allocates resources to highest safety risks; c) effectively maintains or improves safety; d) achieves the stated and agreed safety objectives and SPTs; and e) satisfies the requirements of the State's regulations with regard to control of safety risks. 9.4.6.8 After safety risks have been assessed, appropriate safety risk controls can be implemented. It is important to involve the “end users” and subject matter experts in determining appropriate safety risk controls. Ensuring the right people are involved will maximize the practicality of safety risk chosen mitigations. A determination of any unintended consequences, particularly the introduction of new hazards, should be made prior to the implementation of any safety risk controls. 9.4.6.9 Once the safety risk control has been agreed and implemented, the safety performance should be monitored to assure the effectiveness of the safety risk control. This is necessary to verify the integrity, efficiency and effectiveness of the new safety risk controls under operational conditions. 9.4.6.10 The safety risk management outputs should be documented. This should include the hazard and any consequences, the safety risk assessment and any safety risk control actions taken. These are often captured in a register so they can be tracked and monitored. This safety risk management documentation becomes a historical source of organizational safety knowledge which can be used as reference when making safety decisions and for safety information exchange. This safety knowledge provides material for safety trend analyses and safety training and communication. It is also useful for internal audits to assess whether safety risk controls and actions have been implemented and are effective. 9.5 COMPONENT 3: SAFETY ASSURANCE 9.5.1 Annex 19, Appendix 2, 3.1.1 requires that service providers develop and maintain the means to verify the safety performance of the organization and to validate the effectiveness of safety risk controls. The safety assurance component of the service provider’s safety management system provides these capabilities. 9.5.2 Safety assurance consists of processes and activities undertaken to determine whether the safety management system is operating according to expectations and requirements. This involves continuously monitoring its processes as well as its operating environment to detect changes or deviations that may introduce emerging safety risks or the degradation of existing safety risk controls. Such changes or deviations may then be addressed through the safety risk management process. 9.5.3 Safety assurance activities should include the development and implementation of actions taken in response to any identified issues having a potential safety impact. These actions continuously improve the performance of the service provider’s SMS. 9.5.4 Safety performance monitoring and measurement To verify the safety performance and validate the effectiveness of safety risk controls requires the use of a combination of internal audits and the establishment and monitoring of SPIs. Assessing the effectiveness of the safety risk controls is important as their application does not always achieve the results intended. This will help identify whether the right safety risk control was selected and may result in the application of a different safety risk control strategy. Internal audit 9.5.4.1 Internal audits are performed to assess the effectiveness of the safety management system and identify areas for potential improvement. Most aviation safety regulations are generic safety risk controls that have been established by the State. Ensuring compliance with the regulations through the internal audit is a principle aspect of safety assurance. 9.5.4.2 It is also necessary to ensure that any safety risk controls are effectively implemented and monitored. The causes and contributing factors should be investigated and analysed where non-conformances and other issues are identified. The main focus of the internal audit is on the policies, processes and procedures that provide the safety risk controls. 9.5.4.3 Internal audits are most effective when conducted by persons or departments independent of the functions being audited. Such audits should provide the accountable executive and senior management with feedback on the status of: a) compliance with regulations; b) compliance with policies, processes and procedures; c) the effectiveness of safety risk controls; d) the effectiveness of corrective actions; and e) the effectiveness of the SMS. 9.5.4.4 Some organizations cannot ensure appropriate independence of an internal audit, in such cases, the service provider should consider engaging external auditors (e.g. independent auditors or auditors from another organization). 9.5.4.5 Planning of internal audits should take into account the safety criticality of the processes, the results of previous audits and assessments (from all sources), and the implemented safety risk controls. Internal audits should identify non-compliance with regulations and policies, processes and procedures. They should also identify system deficiencies, lack of effectiveness of safety risk controls and opportunities for improvement. 9.5.4.6 Assessing for compliance and effectiveness are both essential to achieving safety performance. The internal audit process can be used to determine both compliance and effectiveness. The following questions can be asked to assess compliance and effectiveness of each process or procedure: a) Determining compliance 1) Does the required process or procedure exist? 2) Is the process or procedure documented (inputs, activities, interfaces and outputs defined)? 3) Does the process or procedure meet requirements (criteria)? 4) Is the process or procedure being used? 5) Are all affected personnel following the process or procedure consistently? 6) Are the defined outputs being produced? 7) Has a process or procedure change been documented and implemented? b) Assessing effectiveness 1) Do users understand the process or procedure? 2) Is the purpose of the process or procedure being achieved consistently? 3) Are the results of the process or procedure what the “customer” asked for? 4) Is the process or procedure regularly reviewed? 5) Is a safety risk assessment conducted when there are changes to the process or procedure? 6) Have process or procedure improvements resulted in the expected benefits? 9.5.4.7 In addition, internal audits should monitor progress in closing previously identified non-compliances. These should have been addressed through root cause analysis and the development and implementation of corrective and preventive action plans. The results from analysis of cause(s) and contributing factors for any non-compliance should feed into the service provider’s safety risk management processes. 9.5.4.8 The results of the internal audit process become one of the various inputs to the safety risk management and safety assurance functions. Internal audits inform the service provider’s management of the level of compliance within the organization, the degree to which safety risk controls are effective and where corrective or preventive action is required. 9.5.4.9 CAAs may provide additional feedback on the status of compliance with regulations, and the effectiveness of the safety management system and industry associations or other third parties selected by the service provider to audit their organization and processes. Results of such second- and third-party audits are inputs to the safety assurance function, providing the service provider with indications of the effectiveness of their internal audit processes and opportunities to improve their SMS. Safety performance monitoring 9.5.4.10 Safety performance monitoring is conducted through the collection of safety data and safety information from a variety of sources typically available to an organization. Data availability to support informed decision-making is one of the most important aspects of the SMS. Using this data for safety performance monitoring and measurement are essential activities that generate the information necessary for safety risk decision-making. 9.5.4.11 Safety performance monitoring and measurement should be conducted observing some basic principles. The safety performance achieved is an indication of organizational behaviour and is also a measure of the effectiveness of the SMS. This requires the organization to define: a) safety objectives, which should be established first to reflect the strategic achievements or desired outcomes related to safety concerns specific to the organization’s operational context; b) SPIs, which are tactical parameters related to the safety objectives and therefore are the reference for data collection; and c) SPTs, which are also tactical parameters used to monitor progress towards the achievement of the safety objectives. 9.5.4.12 A more complete and realistic picture of the service provider’s safety performance will be achieved if SPIs encompass a wide spectrum of indicators. This should include: a) low probability/high severity events (e.g. accidents and serious incidents); b) high probability/low severity events (e.g. uneventful operational events, non-conformance reports, deviations etc.): and c) process performance (e.g. training, system improvements and report processing). 9.5.4.13 SPIs are used to measure operational safety performance of the service provider and the performance of their SMS. SPIs rely on the monitoring of data and information from various sources including the safety reporting system. They should be specific to the individual service provider and be linked to the safety objectives already established. 9.5.4.14 When establishing SPIs service providers should consider: a) Measuring the right things: Determine the best SPIs that will show the organization is on track to achieving its safety objectives. Also consider what are the biggest safety issues and safety risks faced by the organization, and identify SPIs which will show effective control of these. b) Availability of data: Is there data available which aligns with what the organization wants to measure? If there isn’t, there may be a need to establish additional data collection sources. For small organizations with limited amounts of data, the pooling of data sets may also help to identify trends. This may be supported by industry associations who can collate safety data from multiple organizations. c) Reliability of the data: Data may be unreliable either because of its subjectivity or because it is incomplete. d) Common industry SPIs: It may be useful to agree on common SPIs with similar organizations so that comparisons can be made between organizations. The regulator or industry associations may enable these. 9.5.4.15 Once SPIs have been established the service provider should consider whether it appropriate to identify SPTs and alert levels. SPTs are useful in driving safety improvements but, implemented poorly, they have been known to lead to undesirable behaviours – that is, individuals and departments becoming too focused on achieving the target and perhaps losing sight of what the target was intended to achieve – rather than an improvement in organizational safety performance. In such cases it may be more appropriate to monitor the SPI for trends. 9.5.4.16 The following activities can provide sources to monitor and measure safety performance: a) Safety studies are analyses to gain a deeper understanding of safety issues or better understand a trend in safety performance. b) Safety data analysis uses the safety reporting data to uncover common issues or trends that might warrant further investigation. c) Safety surveys examine procedures or processes related to a specific operation. Safety surveys may involve the use of checklists, questionnaires and informal confidential interviews. Safety surveys generally provide qualitative information. This may require validation via data collection to determine if corrective action is required. Nonetheless, surveys may provide an inexpensive and valuable source of safety information. d) Safety audits focus on assessing the integrity of the service provider’s safety management system and supporting systems. Safety audits can also be used to evaluate the effectiveness of installed safety risk controls or to monitor compliance with safety regulations. Ensuring independence and objectivity is a challenge for safety audits. Independence and objectivity can be achieved by engaging external entities or internal audits with protections in place - policies, procedures, roles, communication protocols. e) Findings and recommendations from safety investigations can provide useful safety information that can be analysed against other collected safety data. f) Operational data collection systems such as FDA, radar information can provide useful data of events and operational performance. 9.5.4.17 The development of SPIs should be linked to the safety objectives and be based on the analysis of data that is available or obtainable. The monitoring and measurement process involves the use of selected safety performance indicators, corresponding SPTs and safety triggers. 9.5.4.18 The organization should monitor the performance of established SPIs and SPTs to identify abnormal changes in safety performance. SPTs should be realistic, context specific and achievable when considering the resources available to the organization and the associated aviation sector. 9.5.4.19 Primarily, safety performance monitoring and measurement provides a means to verify the effectiveness of safety risk controls. In addition, they provide a measure of the integrity and effectiveness of safety management system processes and activities. 9.5.4.20 The State may have specific processes for the acceptance of SPIs and SPTs that will need to be followed. Therefore, during development of SPIs and SPTs, the service provider should consult with the organization’s regulatory authority or any related information that the State has published. 9.5.4.21 For more information about safety performance management, refer to Chapter 4. 9.5.5 The management of change 9.5.5.1 Service providers experience change due to a number of factors including, but not limited to: a) organizational expansion or contraction; b) business improvements that impact safety; these may result in changes to internal systems, processes or procedures that support the safe delivery of the products and services; c) changes to the organization’s operating environment; d) changes to the safety management system interfaces with external organizations; and e) external regulatory changes, economic changes and emerging risks. 9.5.5.2 Change may affect the effectiveness of existing safety risk controls. In addition, new hazards and related safety risks may be inadvertently introduced into an operation when change occurs. Hazards should be identified and related safety risks assessed and controlled as defined in the organization’s existing hazard identification or safety risk management procedures. 9.5.5.3 The organization’s management of change process should take into account the following considerations: a) Criticality. How critical is the change? The service provider should consider the impact on their organization’s activities, and the impact on other organizations and the aviation system. b) Availability of subject matter experts. It is important that key members of the aviation community are involved in the change management activities; this may include individuals from external organizations. c) Availability of safety performance data and information. What data and information is available that can be used to give information on the situation and enable analysis of the change? 9.5.5.4 Small incremental changes often go unnoticed, but the cumulative effect can be considerable. Changes, large and small, might affect the organization’s system description, and may lead to the need for its revision. Therefore, the system description should be regularly reviewed to determine its continued validity, given that most service providers experience regular, or even continuous, change. 9.5.5.5 The service provider should define the trigger for the formal change process. Changes that are likely to trigger formal change management include: a) introduction of new technology or equipment; b) changes in the operating environment; c) changes in key personnel; d) significant changes in staffing levels; e) changes in safety regulatory requirements; f) significant restructuring of the organization; and g) physical changes (new facility or base, aerodrome layout changes etc.). 9.5.5.6 The service provider should also consider the impact of the change on personnel. This could affect the way the change is accepted by those affected. Early communication and engagement will normally improve the way the change is perceived and implemented. 9.5.5.7 The change management process should include the following activities: a) understand and define the change; this should include a description of the change and why it is being implemented; b) understand and define who and what it will affect; this may be individuals within the organization, other departments or external people or organizations. Equipment, systems and processes may also be impacted. A review of the system description and organizations’ interfaces may be needed. This is an opportunity to determine who should be involved in the change. Changes might affect risk controls already in place to mitigate other risks, and therefore change could increase risks in areas that are not immediately obvious; c) identify hazards related to the change and carry out a safety risk assessment; this should identify any hazards directly related to the change. The impact on existing hazards and safety risk controls that may be affected by the change should also be reviewed. This step should use the existing organization’s safety risk management processes; d) develop an action plan; this should define what is to be done, by whom and by when. There should be a clear plan describing how the change will be implemented and who will be responsible for which actions, and the sequencing and scheduling of each task; e) sign off on the change; this is to confirm that the change is safe to implement. The individual with overall responsibility and authority for implementing the change should sign the change plan; and f) assurance plan; this is to determine what follow-up action is needed. Consider how the change will be communicated and whether additional activities (such as audits) are needed during or after the change. Any assumptions made need to be tested. 9.5.6 Continuous improvement of the safety management system 9.5.6.1 Annex 19, Appendix 2, 3.3 requires that… “the service provider monitor and assess its safety management system processes to maintain or continuously improve the overall effectiveness of the SMS.” Maintenance and continuous improvement of the service provider’s safety management system effectiveness is supported by safety assurance activities that include the verification and follow up of actions and the internal audit processes. It should be recognized that maintaining and continuously improving the safety management system is an ongoing journey as the organization itself and the operational environment will be constantly changing. 9.5.6.2 Internal audits involve assessment of the service provider’s aviation activities that can provide information useful to the organization’s decision-making processes. The internal audit function includes evaluation of all of the safety management functions throughout the organization. 9.5.6.3 safety management system effectiveness should not be based solely on SPIs; service providers should aim to implement a variety of methods to determine its effectiveness, measure outputs as well as outcomes of the processes, and assess the information gathered through these activities. Such methods may include: a) Audits; this includes internal audits and audits carried out by other organizations. b) Assessments; includes assessments of safety culture and safety management system effectiveness. c) Monitoring of occurrences: monitor the recurrence of safety events including accidents and incidents as well as errors and rule-breaking situations. d) Safety surveys; including cultural surveys providing useful feedback on staff engagement with the SMS. It may also provide an indicator of the safety culture of the organization. e) Management reviews; examine whether the safety objectives are being achieved by the organization and are an opportunity to look at all the available safety performance information to identify overall trends. It is important that senior management review the effectiveness of the SMS. This may be carried out as one of the functions of the highest-level safety committee. f) Evaluation of SPIs and SPTs; possibly as part of the management review. It considers trends and, when appropriate data is available, can be compared to other service providers or State or global data. g) Addressing lessons learnt; from safety reporting systems and service provider safety investigations. These should lead to safety improvements being implemented. 9.5.6.4 In summary, the monitoring of the safety performance and internal audit processes contributes to the service provider’s ability to continuously improve its safety performance. Ongoing monitoring of the SMS, its related safety risk controls and support systems assures the service provider and the State that the safety management processes are achieving their desired safety performance objectives. 9.6 COMPONENT 4: SAFETY PROMOTION 9.6.1 Safety promotion encourages a positive safety culture and helps achieve the service provider’s safety objectives through the combination of technical competence that is continually enhanced through training and education, effective communication, and information-sharing. Senior management provides the leadership to promote the safety culture throughout an organization. 9.6.2 Effective safety management cannot be achieved solely by mandate or strict adherence to policies and procedures. Safety promotion affects both individual and organizational behaviour, and supplements the organization’s policies, procedures and processes, providing a value system that supports safety efforts. 9.6.3 The service provider should establish and implement processes and procedures that facilitate effective two-way communication throughout all levels of the organization. This should include clear strategic direction from the top of the organization and the enabling of “bottom-up” communication that encourages open and constructive feedback from all personnel. 9.6.4 Training and education 9.6.4.1 Annex 19 requires that “the service provider shall develop and maintain a safety training programme that ensures that personnel are trained and competent to perform their safety management system duties.” It also requires that “the scope of the safety training programme be appropriate to each individual’s involvement in the SMS.” The safety manager is responsible for ensuring there is a suitable safety training programme in place. This includes providing appropriate safety information relevant to specific safety issues met by the organization. Personnel who are trained and competent to perform their safety management system duties, regardless of their level in the organization, is an indication of management’s commitment to an effective SMS. The training programme should include initial and recurrent training requirements to maintain competencies. Initial safety training should consider, as a minimum, the following: a) organizational safety policies and safety objectives; b) organizational roles and responsibilities related to safety; c) basic safety risk management principles; d) safety reporting systems; e) the organization’s safety management system processes and procedures; and f) human factors. 9.6.4.2 Recurrent safety training should focus on changes to the safety management system policies, processes and procedures, and should highlight any specific safety issues relevant to the organization or lessons learned. 9.6.4.3 The training programme should be tailored to the needs of the individual’s role within the SMS. For example, the level and depth of training for managers involved in the organization's safety committees will be more extensive than for personnel directly involved with delivery of the organization’s product or services. Personnel not directly involved in the operations may require only a high level overview of the organization’s SMS. Training needs analysis 9.6.4.4 For most organizations, a formal training needs analysis (TNA) is necessary to ensure there is a clear understanding of the operation, the safety duties of the personnel and the available training. A typical TNA will normally start by conducting an audience analysis, which usually includes the following steps: a) Every one of the service provider’s staff will be affected by the implementation of the SMS, but not in the same ways or to the same degree. Identify each staff grouping and in what ways they will interact with the safety management processes, inputs and outputs - in particular with safety duties. This information should be available from the position/role descriptions. Normally groupings of individuals will start to emerge that have similar learning needs. The service provider should consider whether it is valuable to extend the analysis to staff in external interfacing organizations; b) Identify the knowledge and competencies needed to perform each safety duty and required by each staff grouping. c) Conduct an analysis to identify the gap between the current safety skill and knowledge across the workforce and those needed to effectively perform the allocated safety duties. d) Identify the most appropriate skills and knowledge development approach for each group with the aim of developing a training programme appropriate to each individual or group’s involvement in safety management. The training programme should also consider the staff’s ongoing safety knowledge and competency needs; these needs will typically be met through a recurrent training programme. 9.6.4.5 It is also important to identify the appropriate method for training delivery. The main objective is that, on completion of the training, personnel are competent to perform their safety management system duties. Competent trainers are usually the single most important consideration; their commitment, teaching skills and safety management expertise will have a significant impact on the effectiveness of the training delivered. The safety training programme should also specify responsibilities for development of training content and scheduling as well as training and competency records management. 9.6.4.6 The organization should determine who should be trained and to what depth, and this will depend on their involvement in the SMS. Most people working in the organization have some direct or indirect relationship with aviation safety, and therefore have some safety management system duties. This applies to any personnel directly involved in the delivery of products and services, and personnel involved in the organization's safety committees. Some administrative and support personnel will have limited safety management system duties and will need some safety management system training, as their work may still have an indirect impact on aviation safety. 9.6.4.7 The service provider should identify the safety management system duties of personnel and use the information to examine the safety training programme and ensure each individual receives training aligned with their involvement with SMS. The safety training programme should specify the content of safety training for support staff, operational personnel, managers and supervisors, senior managers and the accountable executive. 9.6.4.8 There should be specific safety training for the accountable executive and senior managers that includes the following topics: a) specific awareness training for new accountable executives and post holders on their safety management system accountabilities and responsibilities; b) importance of compliance with national and organizational safety requirements; c) management commitment; d) allocation of resources; e) promotion of the safety policy and the SMS; f) promotion of a positive safety culture; g) effective interdepartmental safety communication; h) safety objective, SPTs and alert levels; and i) disciplinary policy. 9.6.4.9 The main purpose of the safety training programme is to ensure that personnel, at all levels of the organization, maintain their competence to fulfil their safety roles; therefore competencies of personnel should be reviewed on a regular basis. 9.6.5 Safety communication 9.6.5.1 The service provider should communicate the organization’s safety management system objectives and procedures to all appropriate personnel. There should be a communication strategy that enables safety communication to be delivered by the most appropriate method based on the individual’s role and need to receive safety related information. This may be done through safety newsletters, notices, bulletins, briefings or training courses. The safety manager should also ensure that lessons learned from investigations and case histories or experiences, both internally and from other organizations, are distributed widely. Safety communication therefore aims to: a) ensure that staff are fully aware of the SMS; this is a good way of promoting the organization’s safety policy and safety objectives. b) convey safety-critical information; Safety critical information is specific information related to safety issues and safety risks that could expose the organization to safety risk. This could be from safety information gathered from internal or external sources such as lessons learned or related to safety risk controls. The service provider determines what information is considered safety critical and the timeliness of its communication. c) raise awareness of new safety risk controls and corrective actions; The safety risks faced by the service provider will change over time, and whether this is a new safety risk that has been identified or changes to safety risk controls, these changes will need to be communicated to the appropriate personnel. d) provide information on new or amended safety procedures; when safety procedures are updated it is important that the appropriate people are made aware of these changes. e) promote a positive safety culture and encourage personnel to identify and report hazards; safety communication is two-way. It is important that all personnel communicate safety issues to the organization through the safety reporting system. f) provide feedback; provide feedback to personnel submitting safety reports on what actions have been taken to address any concerns identified. 9.6.5.2 Service providers should consider whether any of the safety information listed above needs to be communicated to external organizations. 9.6.5.3 Service providers should assess the effectiveness of their safety communication by checking personnel have received and understood any safety critical information that has been distributed. This can be done as part of the internal audit activities or when assessing the safety management system effectiveness. 9.6.5.4 Safety promotion activities should be carried out throughout the life cycle of the SMS, not only at the beginning. 9.7 IMPLEMENTATION PLANNING 9.7.1 System description 9.7.1.1 A system description helps to identify the organizational processes, including any interfaces, to define the scope of the SMS. This provides an opportunity to identify any gaps related to the service provider’s safety management system components and elements and may serve as a starting point to identify organizational and operational hazards. A system description serves to identify the features of the product, the service or the activity so that safety risk management and safety assurance can be effective. 9.7.1.2 Most organizations are made up of a complex network of interfaces and interactions involving different internal departments as well as different external organizations that all contribute to the safe operation of the organization. The use of a system description enables the organization to have a clearer picture of its many interactions and interfaces. This will enable better management of safety risk and safety risk controls if they are described, and help in understanding the impact of changes to the safety management system processes and procedures. 9.7.1.3 When considering a system description, it is important to understand that a “system” is a set of things working together as parts of an interconnecting network. In an SMS, it is any of an organization’s products, people, processes, procedures, facilities, services, and other aspects (including external factors), which are related to, and can affect, the organization’s aviation safety activities. Often, a “system” is a collection of systems, which may also be viewed as a system with subsystems. These systems and their interactions with one another make up the sources of hazards and contribute to the control of safety risks. The important systems include both those which could directly impact aviation safety and those which affect the ability or capacity of an organization to perform effective safety management. 9.7.1.4 An overview of the system description and the safety management system interfaces should be included in the safety management system documentation. A system description may include a bulleted list with references to policies and procedures. A graphic depiction, such as a process flow chart or annotated organization chart, may be enough for some organizations. An organization should use a method and format that works for that organization. 9.7.1.5 Because each organization is unique, there is no “one size fits all” method for safety management system implementation. It is expected that each organization will implement an safety management system that works for its unique situation. Each organization should define for itself how it intends to go about fulfilling the fundamental requirements. To accomplish this, it is important that each organization prepare a system description that identifies its organizational structures, processes, and business arrangements that it considers important to safety management functions. Based on the system description, the organization should identify or develop policy, processes, and procedures that establish its own safety management requirements. 9.7.1.6 When an organization elects to make a significant or substantive change to the processes identified in the system description, the changes should be viewed as potentially affecting its baseline safety risk assessment. Thus, the system description should be reviewed as part of the management of change processes. 9.7.2 Interface management Safety risks faced by service providers are affected by interfaces. Interfaces can be either internal (e.g. between departments) or external (e.g. other service providers or contracted services,). By identifying and managing these interfaces the service provider will have more control over any safety risks related to the interfaces. These interfaces should be defined within the system description. 9.7.3 Identification of safety management system interfaces 9.7.3.1 Initially service providers should concentrate on interfaces in relation to its business activities. The identification of these interfaces should be detailed in the system description that sets out the scope of the safety management system and should include internal and external interfaces. 9.7.3.2 Figure 9-3 is an example of how a service provider could map out the different organizations it interacts with to identify any safety management system interfaces. The objective of this review is to produce a comprehensive list of all interfaces. The rationale for this exercise is that there may be safety management system interfaces which an organization is not necessarily fully aware of. There may be interfaces where there are no formal agreements in place, such as with the power supply or building maintenance companies. 9.7.3.3 Some of the internal interfaces may be with business areas not directly associated with safety, such as marketing, finance, legal and human resources. These areas can impact safety through their decisions which impact on internal resources and investment, as well as through agreements and contracts with external organizations, and may not necessarily address safety. 9.7.3.4 Once the safety management system interfaces have been identified, the service provider should consider their relative criticality. This enables the service provider to prioritize the management of the more critical interfaces, and their potential safety risks. Things to consider are: a) what is being provided; b) why it is needed; c) whether the organizations involved has an safety management system or another management system in place; and d) whether the interface involves the sharing of safety data / information. Assessing safety impact of interfaces 9.7.3.5 The service provider should then identify any hazards related to the interfaces and carry out a safety risk assessment using its existing hazard identification and safety risk assessment processes. 9.7.3.6 Based on the safety risks identified, the service provider may consider working with the other organization to determine and define an appropriate safety risk control strategy. By involving the other organization, they may be able to contribute to identifying hazards, assessing the safety risk as well as determining the appropriate safety risk control. This collaborative effort is needed because the perception of safety risks may not be the same for each organization. The risk control could be carried out by either the service provider or the external organization. 9.7.3.7 It is also important to recognize that each organization involved has the responsibility to identify and manage hazards that affect their own organization. This may mean the critical nature of the interface is different for each organization as they may apply different safety risk classifications and have different safety risk priorities (in term of safety performance, resources, time, etc.). Managing and monitoring interfaces 9.7.3.8 The service provider is responsible for managing and monitoring the interfaces to ensure the safe provision of their services and products. This will ensure the interfaces are managed effectively and remain current and relevant. Formal agreements are an effective way to accomplish this as the interfaces and associated responsibilities can be clearly defined. Any changes in the interfaces and associated impacts should be communicated to the relevant organizations. 9.7.3.9 Challenges associated with the service provider’s ability to manage interface safety risks include: a) one organization’s safety risk controls are not compatible with the other organizations’; b) willingness of both organizations to accept changes to their own processes and procedures; c) insufficient resources or technical expertise available to manage and monitor the interface; and d) number and location of interfaces. 9.7.3.10 It is important to recognize the need for coordination between the organizations involved in the interface. Effective coordination should include: a) clarification of each organization’s roles and responsibilities; b) agreement of decisions on the actions to be taken (e.g. safety risk control actions and timescales); c) identification of what safety information needs to be shared and communicated; d) how and when coordination should take place (task force, regular meetings, ad hoc or dedicated meetings); and e) agreeing on solutions that benefit both organizations but that do not impair the effectiveness of the SMS. 9.7.3.11 All safety issues or safety risks related to the interfaces should be documented and made accessible to each organization for sharing and review. This will allow the sharing of lessons learned and the pooling of safety data that will be valuable for both organizations. Operational safety benefits may be achieved through an enhancement of safety reached by each organization as the result of shared ownership of safety risks and responsibility. 9.7.4 safety management system Scalability 9.7.4.1 The organization’s SMS, including the policies, processes and procedures, should reflect the size and complexity of the organization and its activities. It should consider: a) the organizational structure and availability of resources; b) size and complexity of the organization (including multiple sites and bases); and c) complexity of the activities and the interfaces with external organizations. 9.7.4.2 The service provider should carry out an analysis of its activities to determine the right level of resources to manage the SMS. This should include the determination of the organizational structure needed to manage the SMS. This would include considerations of who will be responsible for managing and maintaining the SMS, what safety committees are needed, if any, and the need for specific safety specialists. Safety risk considerations 9.7.4.3 Regardless of the size of the service provider, scalability should also be a function of the inherent safety risk of the service provider’s activities. Even small organizations may be involved in activities that may entail significant aviation safety risks. Therefore, safety management capability should be commensurate with the safety risk to be managed. Safety data and safety information and its analysis 9.7.4.4 For small organizations, the low volume of data may mean that it is more difficult to identify trends or changes in the safety performance. This may require meetings to raise and discuss safety issues with appropriate experts. This may be more qualitative than quantitative but will help identify hazards and risks for the service provider. Collaborating with other service providers or industry associations can be helpful, since these may have data that the service provider does not have. For example, smaller service providers can exchange with similar organizations/operations to share safety risk information and identify safety performance trends. Service providers should adequately analyse and process their internal data even though it may be limited. 9.7.4.5 Service providers with many interactions and interfaces will need to consider how they gather safety data and safety information from multiple organizations. This may result in large volumes of data being collected to be collated and analysed later. These service providers should utilize an appropriate method of managing such data. Consideration should also be given to the quality of the data collected and the use of taxonomies to help with the analysis of the data. 9.7.5 Integration of management systems 9.7.5.1 Safety management should be considered as part of a management system (and not in isolation). Therefore, a service provider may implement an integrated management system that includes the SMS. An integrated management system may be used to capture multiple certificates, authorizations or approvals or to cover other business management systems such as quality, security, occupational health and environmental management systems. This is done to remove duplication and exploit synergies by managing safety risks across multiple activities. For example, where a service provider holds multiple certificates it may choose to implement a single management system to cover all of its activities. The service provider should decide the best means to integrate or segregate its safety management system to suit its business or organizational needs. 9.7.5.2 A typical integrated management system may include a: a) quality management system (QMS); b) safety management system (SMS); c) security management system (SeMS), further guidance may be found in the Aviation Security Manual (Doc 8973 — Restricted); d) environmental management system (EMS); e) occupational health and safety management system (OHSMS); f) financial management system (FMS); g) documentation management system (DMS); and h) fatigue risk management system (FRMS). 9.7.5.3 A service provider may choose to integrate these management systems based on their unique needs. Risk management processes and internal audit processes are essential features of most of these management systems. It should be recognized that the risks and risk controls developed in any of these systems could have an impact on other systems. In addition, there may be other operational systems associated with the business activities that may also be integrated, such as supplier management, facilities management, etc. 9.7.5.4 A service provider may also consider applying the safety management system to other areas that do not have a current regulatory requirement for an SMS. Service providers should determine the most suitable means to integrate or segregate their management system to suit their business model, operating environment, regulatory, and statutory requirements as well as the expectations of the aviation community. Whichever option is taken, it should still ensure that it meets the safety management system requirements. Benefits and challenges of management system integration 9.7.5.5 Integrating the different areas under a single management system will improve efficiency by: a) reducing duplication and overlapping of processes and resources; b) reducing potentially conflicting responsibilities and relationships; c) considering the wider impacts of risks and opportunities across all activities; and d) allowing effective monitoring and management of performance across all activities. 9.7.5.6 Possible challenges of management system integration include: a) existing systems may have different functional managers who resist the integration; this could result in conflict; b) there may be resistance to change for personnel impacted by the integration as this will require greater cooperation and coordination; c) impact on the overall safety culture within the organization as there may be different cultures in respect of each system; this could create conflicts; d) regulations may prevent such an integration or the different regulators and standards bodies may have diverging expectations on how their requirements should be met; and e) integrating different management systems (such as quality management system and SMS) may create additional work to be able to demonstrate that the separate requirements are being met. 9.7.5.7 To maximize the benefits of integration and address the related challenges, senior management commitment and leadership is essential to manage the change effectively. It is important to identify the person who has overall responsibility for the integrated management system. 9.7.6 safety management system and quality management system integration 9.7.6.1 Some service providers have both an safety management system and QMS. These sometimes are integrated into a single management system. The quality management system is generally defined as the organizational structure and associated accountabilities, resources, processes and procedures necessary to establish and promote a system of continuous quality assurance and improvement while delivering a product or service. 9.7.6.2 Both systems are complementary; the safety management system focuses on managing safety risks and safety performance while the quality management system focuses on compliance with prescriptive regulations and requirements to meet customer expectations and contractual obligations. The objectives of an safety management system are to identify hazards, assess the associated safety risk and implement effective safety risk controls. In contrast, the quality management system focuses on the consistent delivery of products and services that meet relevant specifications. Nonetheless, both the safety management system and the QMS: a) should be planned and managed; b) involve all organizational functions related to the delivery of aviation products and services; c) identify ineffective processes and procedures; d) strive for continuous improvement; and e) have the same goal of providing safe and reliable products and services to customers. 9.7.6.3 The safety management system focuses on: a) identification of safety-related hazards facing the organization; b) assessment of the associated safety risk; c) implementation of effective safety risk controls to mitigate safety risks; d) measuring safety performance; and e) maintaining an appropriate resource allocation to meet safety performance requirements. 9.7.6.4 The quality management system focuses on: a) compliance with regulations and requirements; b) consistency in the delivery of products and services; c) meeting the specified performance standards; and d) delivery of products and services that are “fit for purpose” and free of defects or errors. 9.7.6.5 Monitoring compliance with regulations is necessary to ensure that safety risk controls, applied in the form of regulations, are effectively implemented and monitored by the service provider. The causes and contributing factors of any non-compliance should also be analysed and addressed. 9.7.6.6 Given the complementary aspects of safety management system and QMS, it is possible to integrate both systems without compromising each function. This can be summarized as follows: a) an safety management system is supported by quality management system processes such as auditing, inspection, investigation, root cause analysis, process design, and preventive actions; b) a quality management system may identify safety issues or weaknesses in safety risk controls; c) a quality management system may foresee safety issues that exist despite the organization’s compliance with standards and specifications; d) quality principles, policies and practices should be aligned with the objectives of safety management; and e) quality management system activities should consider identified hazards and safety risk controls for the planning and performance of internal audits. 9.7.6.7 In conclusion, in an integrated management system with unified goals and decision-making that considers the wider impacts across all activities, quality management and safety management processes will be highly complementary and will support the achievement of the overall safety goals. 9.7.7 safety management system gap analysis and implementation 9.7.7.1 Before implementing an SMS, the service provider should carry out a gap analysis. This compares the service provider’s existing safety management processes and procedures with the safety management system requirements as determined by the State. It is likely that the service provider already has some of the safety management system functions in place. The development of an safety management system should build upon existing organizational policies and processes. The gap analysis identifies the gaps that should be addressed through an safety management system implementation plan that defines the actions needed to implement a fully functioning and effective SMS. 9.7.7.2 The safety management system implementation plan should provide a clear picture of the resources, tasks and processes required to implement the SMS. The timing and sequencing of the implementation plan may depend on a variety of factors that will be specific to each organization, such as: a) regulatory, customer and statutory requirements; b) multiple certificates held (with possibly different regulatory implementation dates); c) the extent to which the safety management system may build upon existing structures and processes; d) the availability of resources and budgets; e) interdependencies between different steps (a reporting system should be implemented before establishing a data analysis system); and f) the existing safety culture. 9.7.7.3 The safety management system implementation plan should be developed in consultation with the accountable executive and other senior managers, and should include who is responsible for the actions along with timelines. The plan should address coordination with external organizations or contractors where applicable. 9.7.7.4 The safety management system implementation plan may be documented in different forms, varying from a simple spread sheet to specialized project management software. The plan should be monitored regularly and updated as necessary. It should also clarify when a specific element can be considered successfully implemented. 9.7.7.5 Both the State and the service provider should recognize that achieving an effective safety management system may take several years. Service providers should refer to their State as there may be requirements for a phased approach for safety management system implementation.