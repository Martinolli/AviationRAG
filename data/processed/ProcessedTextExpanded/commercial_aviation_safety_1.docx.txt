Title: Commercial Aviation Safety– Chapter 1 Author(s): Stephen K. Cusick; Antonio I. Cortes; Clarence C. Rodrigues Category: Aircraft, Certification, Regulations Tags: Regulations, Safety, Airworthiness, Certification, Accidents Signs of safety are all around us. Speed limits and the types of lines painted on roads are set according to conditions presented by different stretches of road. Fire extinguishers, sprinklers, and exit signs are ubiquitous in buildings. Sneeze protectors cover salad bards to promote food safety. Cars have antilock brakes and airbags. Maintenance staff put up " wet floor" signs to warn people of slippery floors. Signs of security are also all around us. Passcodes on phones prevent others from accessing private information. Online accounts require passwords to access sensitive areas. Security at airports checks passengers to ensure they are not taking dangerous items onto planes. No matter what the context at hand is, safety is not an accident, and security requires constant vigilance. These topics are integral to any discussion, especially in the aviation industry. For example, minimum training standards are written for flight attendants to promote the prompt evacuation of passengers during cabin fires, ramp agents wear reflective vests to reduce the chance of being run over by vehicles, and some maintenance procedures require the use of eye protection to minimize the change or puncture injuries, pilot callouts help ensure that everyone on the flight deck is aware of emerging problems that may impact safety, fluid quantities are restricted in carryon bags, cockpit doors are reinforced to prevent forced entry, and passengers are screened to avoid weapons from being in aircraft cabins. In 2015, Chairman Calin Rovinescu of the International Air Transportation Association (lATA) said that safety is the number one priority for commercial aviation and will continue to be so. But is safety truly the most important issue in commercial aviation? After all, the word "commercial" implies that profit is essential. This book will depict the key elements of providing safe and secure operations, not as impediments to making a profit in the aviation industry, but as prerequisites! What exactly is commercial aviation safety ? First, let us examine what it involves. There are different sectors of aviation, all of which use aircraft and people for various tasks. The following categories sum up the major uses for such assets: • General aviation-civilian flying that excludes scheduled passenger airlines • Corporate aviation-air transportation specifically for the needs of company employees and executives Military aviation-use of aircraft for conducting aerial warfare and support operations • Commercial aviation-using aircraft to provide paid transportation or flight services to people and cargo. This book explores the aspects of safety in commercial aviation. To a lesser but important extent, security issues are also exposed. Ultimately, one of the major goals in these realms is enhancing the efficiency of aircraft operations while preventing events that cause injury to people or damage to equipment. The industry centers around rules and regulations aimed to seamlessly and safely transition aircraft, passengers, and workers through every phase of a flight. Focusing on the commercial sector is not meant to imply that huge strides in safety have not been made. Enormous improvements have turned commercial aviation into an extremely safe and mostly reliable transport. Similarly, focusing on commercial aviation does not mean that the concepts covered in the book do not apply to other realms of aviation or even to other types of industries. In fact, most topics covered apply to all aviation branches and, furthermore, a wide range of industries. For example, healthcare is very concerned with safety. The Institute of Medicine claims that 700,000 patients suffer from medical errors in the United States every year. Between 44,000 and 98,000 die from these mistakes, and some conservative calculations claim that medical mistakes are the eighth leading cause of death. We can put this figure into perspective for aviators, as it is comparable to having a fully loaded Boeing 747 crash every 3 days. Safety is and will continue to be an integral part of the discourse regardless of which industry we could name. Therefore, anyone desiring to pursue a career anywhere in the industry must understand the safety concepts presented in this book. We focus on commercial aviation because it is an ultra-safe high-risk industry (USHRI). Along with other industries, such as nuclear power and chemicals, commercial aviation accomplishes its mission while having less than one disastrous accident per 10 million events. Chris is described as facing very high risks constantly but somehow not succumbing to them except on rare occasions. Within these domains, the smallest mistake could have huge consequences and jeopardize safety for many. The excellent level of safety these industries see today has evolved, to a great extent, from crisis-laden events. When something disastrous, such as a death, shocks the community, people are moved to create regulations to prevent that event from occurring again. In USHRIs, accidents are understood to result from a combination of elements, whereas any of these elements alone would likely not cause an accident or serious incident. Compare these work environments to others that suffer less immediate and grave circumstances. Think of those who work in human resources, education, or clerical settings. Although mistakes in any setting can result in harm, the chances of small mistakes resulting in very grave harm are rare in such settings. Little mistakes do not cause great damage. Although USHRIs have drastically minimized errors compared to other industries, they have also worked on it for a while. They are benefiting today from the disasters and efforts of yesterday. Figure 1 - 1 shows a captain operating the flight guidance panel to maneuver a modern airliner near high mountains above South America. Over a century of safety improvements have made the commercial aviation industry ultrasafe, but is it safe enough? Before going any further into commercial aviation safety, it is important to understand that there is a difference between what is considered an incident and what types of events are termed an accident. The term incident is somewhat ambiguous because there is no general agreement on what it entails. The Federal Aviation Administration ( federal aviation administration ), National Transportation Safety Board (NTSB), and International Civil Aviation Organization (ICAO ) all have different definitions they use to describe incidents. Simply put, an incident is something that happened during the operation of an aircraft that did or could affect the safety of the operation but did not rise to the severity of an accident. An incident could include a crewmember not being able to perform normal flight duty because of injury or illness, an in-flight fire, or a flight control failure. In contrast, an accident is an occurrence that involves some degree of injury or damage related to the operation of an aircraft. There are different variations in the definition of an accident, but ICAO's definition is the most widely accepted in commercial aviation. There are four types of accidents identified for the commercial sector according to ICAO: • Major accidents-occur when an aircraft is destroyed, there are multiple fatalities, or there is a fatality coupled with a substantially damaged aircraft • Serious accidents-happen when there is either one fatality without substantial damage to an aircraft, or there was at least one serious injury and an aircraft was substantially damaged • Injury accidents-nonfatal accidents with at least one serious injury and without substantial damage to an aircraft • Damage accident-characterized by no one getting killed or seriously injured, but an aircraft receiving substantial damage. WHAT IS RISK? In the context of safety, risk is the combination of the severity of a dangerous condition or event and the probability or likelihood of that event occurring. For example, is it risky to walk barefoot across a field that has snakes? It is not risky at all if the field has nonvenomous or low-venom snakes, assuming you are not terrified of snakes and have a panic attack. However, the same act with highly poisonous snakes in the field, such as cobras, can greatly increase the severity and, therefore, the risk. That explains the severity of the situation, but what about the likelihood of injury? If there is one cobra in the field, and you only have to cross the field once, then the likelihood of injury is quite low. If there are a dozen cobras in the field and you have to cross the field once, the likelihood of injury may be deemed moderate. However, if there are a dozen cobras and you have to walk across the field to get to work every single day, then the likelihood of injury may be seen as very high. So the lowest risk is when there are no venomous snakes or low-venom snakes (low severity), and very few of us cross the field only once (low likelihood), and the riskiest situation has cobras (high severity) and many of us facing the cobras often (high likelihood ). If you can avoid walking across such a field in the first place, you have eliminated the risk. But if you must cross the field, perhaps you can change the severity or the likelihood so that it is in your favor . . . so that you lower the risk. To mitigate the risk, you can change the severity of the threat by wearing tall boots, and you can change the likelihood of injury by crossing the field less often. Aviation safety follows similar risk management principles. Let us take a regional airline operating in sub-Saharan Africa with service into an unpaved airfield. The airfield's eastern edge is very close to the shore of a large lake. However, there is a hazard posed by crocodiles that like to sun themselves on the runway. The larger crocodiles often hunt at night and like to sun themselves in the morning and early afternoon. The younger crocodiles are too intimidated by their larger kin and only sun on the runway when the larger crocs have left, which is usually around 5 pm when the larger crocs go back to the water for the night's hunt. The severity of the hazard is related to the speed at which the aircraft could impact a crocodile and the size of the crocodile. The likelihood of collision could be explained as the times when the aircraft comes close to impacting a crocodile when operating at the airfield. Imagine that you have been hired by the airline, and the vice president of operations calls a meeting to discuss safety. He asks the question, how can we improve safety at the crocodile airfield? Some of the airline employees, when faced with such a question, may answer, " That's easy, we just shouldn't fly there ." But safety is not about impeding a task; it is about mitigating risk or doing it better. After all, the population in the area near the airfield depends on the scheduled air service for medicine, supplies, and personal transportation. What would you suggest to the vice president? Suppose you understand the concept of severity and likelihood of risk. In that case, you may recommend any of the following or all of the following: • Reduce the likelihood of an encounter by contracting a local to scare the crocodiles off the runway for your time of landing and takeoff. That may require a brave employee! • If winds allow, land and take off from the western part of the runway to reduce the likelihood of running into crocodiles. • Operate into the airfield after 1 7 0 0 hours but before sunset so that you reduce the severity of any collision with crocodiles since you will probably only hit the small crocs and not the large ones. It is prudent to operate only during daylight hours so that you can see any crocodiles on the runway. As you can see in the previous example, aviation safety is nuanced and requires significant study in order to be used effectively as a way to enhance operations versus as a way to say "no" to operations. Given the size and complexity of commercial aviation, it is no wonder safety is a major topic. Looking at some statistics helps break down just how large aviation operations are and just how many opportunities there are for safety to decay. lATA reported that 3 . 3 billion people flew in 2 0 1 4 and projected this number would increase to 3.5 billion on more than 50,000 routes in 2015. Every day, i t means that over 8 million people are in the sky on more than 100,000 flights. There are more than just people moving through the sky, as pilots transported 50 million tons of cargo. Transporting people and goods resulted in a $2.4 trillion international economic footprint that supported 5 8 million jobs globally. When taking all those numbers into consideration, it is astonishing that in 2 0 1 4, there was only one major accident for every 4.4 million flights. How is it possible to operate so safely? The growth of the aviation industry is not forecasted to slow down, either. The international civil aviation organization Regional Aviation Group expects the Latin America and Caribbean airline industry to grow 5-9 % yearly into the foreseeable future. Currently, the airline industry in this region creates $ 158 billion in revenue and 4 . 9 million jobs, with an anticipated growth of $2 8 9 billion and 9 . 8 million, respectively, by 2032. Likewise, Airbus predicts that current airline traffic will more than double by 2034 for the Asia-Pacific region. Worldwide, in 2014, there were 47 aviation megacities, with locations that had more than 1 0,000 daily flights between 6 and 12 hours. In 2034, this number may rise to 91 megacities. Most importantly, it is essential to understand why we care about commercial aviation safety. First and foremost, human life is involved, often in significant numbers, and it also often involves not just passengers but also bystanders on the ground. Ensuring people do not get hurt is a main priority. Second, when safety deteriorates, it comes with financial implications. These can come in the form of lawsuits, insurance claims, and stock instability. Nothing illustrates this point better than the story of the Boeing 787 Dreamliner. The aircraft contained a lithium-ion battery unit in the aft electrical bay. The battery was designed to start the auxiliary power unit and provide backup lighting for the aircraft. In January 2013, there were several instances of this battery catching fire. It was a relatively minor problem, but when paired with a brand-new aircraft type that was trying to gain purchase orders, major consequences followed. Within hours of the news about the battery, Boeing lost $ 2.6 billion of its company value in the stock market as jittery investors started worrying about the future sales of the aircraft. That is " billion" with a " B." Some companies and governments will incur huge financial impacts just in order to prevent safety from degrading or to prevent the appearance of not taking safety seriously. When Iceland's Eyj air force jet allaj Okull Volcano erupted in April 2010, the industry canceled around 1 7,000 flights per day due to unsafe flying conditions. In turn, this resulted in $200 million losses a day. However, one aircraft loss would have been far more. SAFETY PHILOSOPHY Philosophy studies reality, existence, and the nature of knowledge. Although it does not take a philosopher with deep thoughts to define safety philosophy, there are quite a few concepts about the nature of safety that are not obvious. Unfortunately, there are industry professionals who believe, quite incorrectly, that safety is merely common sense. At its core, safety is about making life better by addressing unacceptable risks. Something seemingly so simple turns out to have many nuances. Let us debunk some common myths about safety: • Accidents happen to stupid people. People may think, "I'm not stupid, so I have nothing to worry about." Wrong! Accidents can happen to anyone if the right conditions are there because often external factors outside of one's control combine to work against an individual. For example, a ramp agent may say that the engine area is clear and prompt the pilot to start an engine for departure, only to realize when it is too late that a baggage cart was too close to the engine intake and was sucked into the engine, causing millions of dollars worth of damage. If it isn't broken, don't fix it. Very often, we may think something is not broken, but there are often numerous unknown factors at work that may not be optimal condition. For example, when asked about the condition of their aircraft prior to a flight, some pilots think they are funny by saying, "Well, I figure if it flew in, it will fly out! " Such a statement shows a pilot's ignorance of the many unknown factors that can prove the statement wrong, such as fluid leaks, ramp collisions, and ground icing, any of which could result in a fatal crash of the aircraft after take off. • If it hasn't been a problem before, then it isn't a problem. This mindset is a slippery slope. Just because a certain factor has not been an issue before does not mean we should ignore it. There is always a first for everything. For example, modern engines are designed to minimize failures that affect the rest of the aircraft, other than the loss of power. Furthermore, one system failing should not cause another system to fail. But in November 2002, the pilots of Qantas Flight 3 2, flying an Airbus 3 8 0, experienced an uncontained engine failure that also severed electrical wires, hydraulic lines, and a fuel tank. • You have been sufficiently trained. If employees are sufficiently trained to do everything, we would be training our whole life and never have time to move passengers around the world. Determining what situations to include in the training curriculum for airline professionals is extremely challenging since we cannot be sure of what situations may be faced. For example, in September 2 0 1 0 the captain of UPS Flight 6, flying a Boeing 747-4 00, had an oxygen mask failure while attempting to manage an inflight fire. Both pilots perished in the ensuing crash. It is inevitable that we will face situations we are not expecting. • Safety is our top priority. Safety should always be on our minds, and we should strive to operate safely at all times, but let us not kid around; the top priority of any commercial venture is profit. The stockholders and managers of an airline do not place safety as the top priority because the best way to guarantee that an airline is safe is not to fly. Well, that would not make much business sense, would it? The question is not how to achieve safety; the question is how to operate and achieve profit objectives in a safe manner. Having said that, we must remember the story of the Boeing stock price plunge due to a safety event and acknowledge that there is a direct link between safety and profit. • Accidents are impossible to predict. Although Chapter 14 will address research efforts underway to create a short-term prediction of accidents, it is currently outside of our capability to predict specific accidents with any degree of accuracy. However, that is not to say that we cannot recognize developing accident chains by noticing the presence of undesirable factors. It is not uncommon after an accident for certain employees to comment, " Yes, it was obviously an accident waiting to happen." In the minds of such employees, the factors that created the accident were obvious to them, yet nothing was done to address them, and an accident ensued. Often, we see a threat but rationalize that it does not pertain to us, leaving the threat lingering. Some threats are obvious, while some threats are not. The same threat may create an accident in one flight, just an incident in another, and have no adverse impact to another flight. So types of accidents and their causal factors are not impossible to predict, but specific accidents to include when and where they will occur are outside of current predictive capabilities. • Weather is a leading cause of accidents. This myth creates much debate in the aviation industry. Adverse weather is often a factor in accidents. However, those who are purists about accident causation stress that weather cannot be deemed a causal factor in accidents. That is because in accident theory, as shall be covered in the next chapter, accident investigations should produce prompt, remedial recommendations written to prevent future recurrence. For example, if wind shear was a factor in an aircraft accident, we cannot write a recommendation against the wind shear because weather cannot be prevented. So instead of determining weather as a cause it is often the human role in reporting or avoiding weather that is deemed causal. For example, if an aircraft crashes on approach due to wind shear, and the crew was completely unaware of wind-shear conditions due to a malfunctioning wind-shear warning device at the airport, the cause of the accident would not be the wind shear itself but may be faulty inspection protocols for the reporting equipment. • There is often a single cause behind an accident. This is a blatantly false myth. In fact, t the opposite is true. Accidents are complex events stemming from multiple causes. It is quite challenging to think of any accident that only had one cause. Anyone who says so probably has not looked into the factors that contributed to what they believe is the single cause. Historically, accidents were often conveniently written off by deeming the cause to be " pilot error " or " maintenance error " and taking minimal further action. The public was relieved to know that a single " bad apple " had created the problem, and the aviation world could return to business as usual. Clearly more is going on to cause accidents than j ust bad pilots. In fact, a series of negative factors combine to create accidents. Often the flight crew is only the last link in the chain of factors prior to an accident. Over the past few decades, investigators have shown that accidents usually have more than one cause, and each cause carries the same amount of importance. In fact, in 1 994, the national transportation safety board began listing probable causes in the accident report, thus the genesis of the multi-causality concept. Digging deeper into the causes allows investigators to determine the root cause of why things happened the way they did. One byproduct of this investigative expose has been the decreased use of the myth of pilot error and realizing that there are flaws in the whole system. • Accidents are "Acts of God." Above we mentioned that many people tend to think that accidents are impossible to foresee. For so long, we thought accidents j ust happen. They were mysterious occurrences that no one could control. In many parts of the world, to this day, after accidents people can be heard claiming that the event was an " act of God." Doing so brings psychological comfort because it removes ties to the truth that most accidents are preventable if the right people are provided the right tools at the right time. Those tools may come in the form of information, technology, training, or procedures. As humans, we need to embrace the concept that we are masters of our own safety destiny by relying on scientific tools such as forensics and logic to understand accidents and then apply the lessons learned from prevention. Yet corners of the planet still embrace the purported inevitability of accidents, and such archaic thoughts do not just stem from the uneducated. For example, managers of Nepal's state-run airline 2007 sacrificed two goats to Akash Bhairab, the Hindu sky God, in order to resolve a technical problem with a Boeing 757. After the ritual, a senior airline official reported that " the snag in the plane has now been fixed, and the aircraft has resumed its flights," without explaining what the actual problem had been. In stark contrast to simply shrugging shoulders and leaving safety up to nonhuman forces, modern aviation professionals should be trained to actively search for negative factors that are coming together that could potentially create an accident. There are several challenges, however. We are constantly surrounded by such signals. Recognizing which signals should be acted upon can be challenging. Nevertheless, there are several conditions that are often notorious precursors to accidents, as listed below. There are many other such preconditions, but for now, we will only address these five: • Distraction. Aviation professionals can let other things affect their concentration, such as checking personal text messages during a preflight check. • Rushing. Someone may take a shortcut. When we do this, we are not giving our personal best, and we risk missing key information and skipping items that may not seem important now but that could prove critical in a few moments. • Operating outside one's training. Accidents can occur when we find ourselves doing something outside what we are trained to do. We often know that it is something we have not been trained to do and make a conscious decision to do it anyway. • Desensitization. It is easy to tune out warning signs when they occur frequently and have not resulted in problems in the past. The problem is that the context may be different today, and therefore, today may be the day that the warning applies. • Ignoring your instinct. That expression may not sound very scientific, but it essentially means that something does not feel right. Professionals should not feel uncomfortable when they are doing a task. If something does not feel right, it may be our protective instinct kicking in and recognizing that an unresolved discrepancy or problem is lurking in the background, ready to ruin your whole day. SAFETY ETHICS A discussion of safety philosophy would not be complete without delving into ethics. As aviation professionals, detecting precursors is an ethical obligation to making decisions. When an accident occurs, it is not uncommon to hear someone say," That was an accident waiting to happen ! " However, that very expression means that conditions had previously been recognized as favorable for an accident. If we knew the possibility existed, why did we not do anything? One key philosophy shared through this book is the need for aviation professionals to develop a mindset that each person can make a difference in safety. When we see conditions developing that can result in an accident, it is important to address the situation immediately or notify the proper personnel who can take action. Everyone must watch for dangerous conditions and have the proper safety ownership to report problems to management, and every manager should be trained on what to do when such a report is received. It takes a team effort by all for safety to be present in commercial aviation. Accidents do not happen out of the blue, instead, there are precursors that are usually detectable by one means or another. The National Academy of Engineering defines precursors as an event or group of events that must occur for an accident to occur in a given scenario. As such precursors linger unaddressed, they form part of what some safety professionals call a disaster incubation period. Although there is no such thing as absolute safety, certain risks can be managed to the extent that they are no longer a significant problem. Where that line lies, that fuzzy line between acceptable and unacceptable risk, is often hotly debated and varies from risk to risk and with operational context. There are limits as to how low we can reduce certain risks without severely impacting operations, and there is a point in which introducing more safety measures significantly outweighs the safety benefit. Safety managers are tasked with the challenging task of reducing risks to as low as reasonably practicable, which is a concept known by the acronym ALARP. Keep as low as reasonably possible in mind as you read the book, especially when safety management is addressed in Chapter 12. Another element of safety ethics is the need to be respectful when we discuss people having been hurt, such as when we talk about commercial aviation accidents. Ethics is important because human beings are not objects, and everyone has intrinsic worth. A part of this is acknowledging that we are all beings with human feelings. Therefore, it is important to use the appropriate tone when talking about accidents, as we realize that some accidents involve human suffering and death. There are a few antiquated mindsets about the victims of an accident that deserve discussion. One thinks it is the victim's fault that something happened. This is sometimes known as " blaming the victim syndrome." After all, no one plans to have an accident. With accidents being multicausal, it is unfair to hold the persons involved entirely responsible for what went wrong. Psychologists explain that there is a natural human tendency to " blame the victim" because whenever we differentiate ourselves from those who suffer, we create comfort in the knowledge that we do not have to worry about the situation happening to us. The explanation is called " distancing through differencing." For example, when we hear of an automobile fatality, we often search for factors that make us feel safe. Perhaps the accident happened at night, and the casualty was not wearing a seat belt. Knowing such facts, we may be tempted to say, "Well, I never drive at night and always wear a seatbelt, so such an event would never happen to me." As aviation professionals we must bear in mind that blaming the victim usually accomplishes nothing more than bringing us comfort. It certainly does not add to the safety value chain. As Mark Twain purportedly once said, " It is curious-curious that physical courage should be so common in the world, and moral courage so rare ." Making ethical decisions and taking ethical action can be complicated and difficult. It involves multiple layers: figuring out the facts, interpreting the facts, and overlaying a set of values on the situation. The right thing to do may require an action that frightens us, such as standing up to a superior or admitting we were wrong. In aviation, when people's lives are at stake, we must always have the moral courage to act in the name of safety. There is a good story of an aviation professional demonstrating ethics for the sake of safety. In 2 0 0 7 Comair, a subsidiary of Delta which has now been shut down, fired pilot Shane Sitts for refusing to fly an aircraft that had a broken power device that assists in opening and closing the main cabin door. The malfunction required that the door be opened and closed by hand. Sitts said it was the fifth time in 5 years that he had seen the problem, which raised questions about the integrity of the plane in flight. Sitts also noted that ground crews were constantly endangered by the broken doors since the doors would fall open heavily onto the ramp area if the wrong technique was used to open the door in the broken condition. After being fired, Sitts sued Comair and won the case because he was within his rights to refuse to fly due to safety concerns. Although Sitts may have been deemed a whistleblower by coworkers, he stood up for something that gave him an uneasy feeling. Through doing so, he embodied the epitome of moral courage and ethics. However, before every reader goes out and tries to be morally courageous to improve safety, we must remember that safety management is a science-based endeavor that requires very careful orchestration. One key aspect that safety managers must consider before attempting to solve problems is the so-called " law of unintended consequences." Every initiative must be assessed for potential negative outcomes before operations are changed. Sometimes, we act on goodwill to make something better, but in reality, it worsens a situation. Here are some examples from the world of safety: • Airbags initially caused serious injury or death to small people when activated for collisions that otherwise would not have caused injury. • Making LED bulbs the new standard for aircraft warning panels removed the ability to collect forensic evidence about which lights were illuminated during impact on accident investigations. • A Johns Hopkins University 2013 study of 2323 medical interns to assess safety after reducing duty hours from 30 hours to 1 6 hours actually revealed the presence of more cumulative mistakes, not less, due to increased handoff errors and decreased variety of training. • In an effort to reduce landings from unstable approaches, some airlines mandated that pilots perform go-arounds from all unstable approaches but do not provide increased training on how to perform the go-around procedure, which can sometimes consist of numerous complex steps in rapid succession while close to the ground and close to stall speed. In essence, such a situation removes one risk but possibly replaces it with an even greater risk. • In some aircraft operations, altimeter and navigational accuracy were greatly enhanced in order to operate with less separation from other aircraft, but aircraft collision warning systems were not increased. In at least one case, such a situation led to two aircraft fatally colliding with each other at 35,000 feet when flying in opposite directions at precisely the same altitude and airway. One aircraft was flying at an altitude that was inappropriate for the direction of flight. SAFETY VS. SECURITY It is impossible to fly in the airline system today without being aware of security. Although many travelers complain about having to take off shoes and discarding liquids when going through security, most understand that the requirements are the result of measures taken to prevent the recurrences of previous terrorist and criminal acts involving commercial aviation. Since the September 11 attacks of 2001, in which commercial flights were hijacked and crashed into New York City's Twin Towers, the Pentagon in Washington, D. C . , and a field in Pennsylvania, aviation security has received much attention. Many travelers tend to use " safety" and "security " interchangeably when they speak. In some languages, the same word is actually used to mean both safety and security, but most English-speaking aviation safety professionals make a clear distinction between both terms. Safety entails the prevention of unintended negative outcomes and therefore, safety specialists attempt to detect those conditions that could lead to personal harm or material damage. However, security entails the prevention of intentional negative outcomes, often associated with terrorism and criminal acts. Security specialists focus on intelligence to detect efforts that are underway to harm people and property and also on physical security measures to impede plans once they are underway. The primary difference between safety and security is intent. The same harm or damage can be produced due to safety or security issues, but it is the intentional human act of producing harm or damage that makes the difference. Let us look at a hypothetical situation to understand this distinction. Imagine a ramp worker who drives a fuel truck into the wing of an airplane. Was it a safety event or a security event? Well, that determination depends on the intent of the driver. We must ask questions. What were the circumstances behind this event? Did the driver do this because she was angry about having to work on Christmas day, or did she drive into the wing unknowingly because she was distracted when answering a text message from her boyfriend? It is necessary to determine whether malice or distraction caused the crash because it dictates the type of investigation that will be conducted and what specific measures can be recommended to prevent the situation from happening again in the future. If the fuel truck driver acted intentionally, then it was criminal activity, and law enforcement authorities need to assess blame and levy the proper charges . However, if distraction was the cause, then the crash was an accident, and safety authorities will investigate the causes and draft appropriate recommendations . We care about this difference because distinct skills sets are required to investigate the event depending on whether it was intentional or not. One type will require trained investigators in human error while the other needs a law enforcement background to explore the criminal intent. Looking at changes Boeing has implemented in aircraft design helps illustrate this difference. Since human error is involved in many if not all accidents, in some form or fashion, Boeing focuses on studying human factors, such as flight deck design, cognitive psychology, ergonomics, and human performance. By understanding these disciplines, engineers can improve the interaction between human and machines, thus improving the safety of flight. Aside from safety, on the security side, Boeing is designing enhanced security flight deck doors for the 747, 767, and 777 planes. These new doors will have a better ability to withstand bullets, explosives, and blunt force. Additionally, there will be an electronic lock that will give pilots the ability to allow or deny access to flight deck. As one can see, the differences between designing for safety and designing for security have very different goals and require different solutions. Lastly, it should be pointed out again that the confusion between the terms safety and security can be accentuated when dealing with other languages where the terms are synonymous. For example, in Spanish the word seguridad refers to both safety and security, therefore out of convention when seguridad is used alone it refers to security but when it is modified with an operational suffix, as in seguridad operacional, it means safety. TENERIFE AcciDENT Sometimes, security and safety actually affect each other. The worst accident in aviation history provides a perfect example of how a security situation led to a safety event. The example also helps us understand the distinction between security and safety. In 1 9 77, a bomb exploded at Gran Canaria Airport, which is on one of the Spanish Canary Islands in the Atlantic Ocean off the coast of North Africa. Fearing the possibility of a second explosive device, planes inbound to the airport were diverted to Los Rodeos Airport in Tenerife, which is another of the Canary Islands. Due to the high volume of traffic at Los Rodeos, air traffic controllers were parking airplanes on the taxiway, thus blocking it. Crews operating into Los Rodeos as a diversionary field were in unfamiliar territory and had to contend with irregular operations on the airfield due to the unusually high volume of traffic. While waiting to reopen Gran Canaria, a dense fog developed, reducing visibility. When Gran Canaria reopened, two Boeing 74 7s, one from Pan Am and one from KLM, were parked on the taxiway waiting to depart and started moving as part of the departure sequence. The fog prevented both of the aircraft from seeing each other, and air traffic control was not able to see either of the aircraft, so all relied on voice communication to determine position along the airfield. As the result of several very unfortunate misunderstandings, the KLM flight tried to take off while the Pan Am aircraft was still using the runway to taxi. The two aircraft collided, killing 5 8 3 people. Figure 1 -2 shows the tragic results of the accident. This story exemplifies how an attempt to address a security concern at one airport actually caused a safety disaster at another. AVIATION SA FETY HISTORY At the very start of the 20th century, the first fatal accident occurred in 1 9 0 8 and involved one of the aircraft of the Wright Brothers. Because the aircraft was on a military demonstration flight and killed the military observer who was aboard to assess the flying, the U . S . Army convened an investigation. The Investigation The board concluded that a propeller contacted a wire from the rudder, causing the wire eventually to come off its socket. This caused the rudder to fold sideways, and consequently, the pilot lost control of the plane. Figures 1 -3 show the scene at the accident site moments after the event. Accidents in the military and in civilian aviation continued to happen. In 1921 The U.S. Army was the first to keep statistics on aviation accidents. They recorded that 3 6 1 major accidents occurred in 77,000 hours of flight during 1 year alone. That is 467 accidents per 1 0 0,000 hours! To put this very high rate of accidents into perspective for operations today, that would equate to losing several thousand airliners per day across the world. Pretty soon, we would be out of aircraft to fly! Unfortunately, the U . S . Army did not have a Chief Aviator who understood safety philosophy, as evidenced by the order that he issued to his aviation commanders: " There will be no more accidents! " One shrewd commander sent back a response that said, " Then there will be no more flying," since he understood that the only way to reduce risk to zero was to halt operations altogether. Two key events helped shed light on the importance of safety in aviation. During the early part of the 2 0th century, civilian aviation in the United States was not regulated. Many professionals thought that aviation could not reach its full potential in the commercial sector without more stringent safety standards. President Calvin Coolidge appointed a board to explore this issue. The board's report agreed that there needed to be more federal safety regulations. As a result, the Air Commerce Act became law in 1926 and established the requirements for investigating accidents in response to the aircraft surge during World War I. The second key event occurred 9 years later in 1 93 7. A German passenger airship known as the Hindenberg was attempting to dock at the Lakehurst Naval Air Station in Manchester Township, New Jersey, after a flight from Germany. It caught fire and was destroyed, claiming 35 lives with it, and the entire sequence was transmitted over radio, much to the horror of a large listening audience. This accident was so dramatic that it ended the airship industry, which was a very large commercial aviation base. Imagine the impact that one single accident had on the public consciousness. It was such a profound event that it ended an entire industry ! Figure 1 -4 shows the shocking scene of the Hindenburg accident as it was unfolding. SIGNIFICANT AVIATION ACCIDENTS In the airplane segment of commercial aviation, there is also a history of significant accidents, as well as malicious acts such as terrorist attacks that do not count as accidents. Some accidents and attacks have had such profound significance that they have prompted action. Those actions have shaped the current commercial aviation industry. The list of accidents and attacks that follow is impressive but, unfortunately, is by no means exhaustive. The list contains only the most significant events that have helped create a safer world for air travel and transport. Some of the events are referred to in conversations by industry professionals to this day and also during efforts to craft modern legislation in aviation, so the reader is urged to become familiar with the contents of the compilation. Each event has a very long investigation report associated with it, and the details contained in the reports are always of great interest. This list only provides the bare essentials. • June 30, 1956. A United Airlines Douglas D C-7 struck a Trans World Airlines Lockheed Constellation in a midair collision over the Grand Canyon. There were 1 2 8 fatalities, and the first airline crash to result in more than 1 00 deaths. The crash led to drastic changes in how flights are controlled in the United States. • December 16, 1966. A United Airlines Douglas DC - 8 heading toward Idlewild Airport in New York City collided with a Trans World Airlines Constellation over Staten Island. There were 1 2 8 fatalities, including six on the ground. The result of this accident was the introduction of a speed limit of 250, which indicated knots when flying below 10,000 feet, which is still in effect today. • December 1, 1974. Trans World Airlines Flight 5 1 4, a Boeing 727, was flying to Washington National Airport but had to divert to Washington Dulles Airport due to strong crosswinds. The plane was cleared for approach but resulted in a controlled flight into the terrain. There were 92 fatalities. As a result, the federal aviation administration mandated ground proximity warning systems, and the Aviation Safety Reporting System (ASRS ) was also created in 1976 . • March 27, 1977. A t t h e L o s Rodeos Airport in Tenerife, o n e of t h e Spanish The Canary Islands, KLM Flight 4 8 0 5 and Pan Am Flight 1736 , both Boeing 74 7s, were taxiing out for takeoff after diverting to the airport due to a security threat at their intended airport of use on the island of Gran Canaria. Heavy fog was in the area, and KLM Flight 4 8 0 5 did not see and collided with Pan Am Flight 1 73 6 during the takeoff roll. There were 5 8 3 fatalities. To this day, the event remains the worst aviation accident the world has experienced. It should be noted that security events are not considered accidents thus tragedies such as the September 2001 terrorist attacks do not count as an accident. As a result of the Tenerife accident, an increased emphasis was put on using standardized phraseology between air traffic controllers and pilots, although some of the factors that helped produce the accident have still not been successfully addressed by the industry. • August 2, 1985. Delta Airlines Flight 191 , an L-1011 TriStar, slammed into the ground as it encountered wind shear on final approach into the Dallas-Fort Worth Airport on August 2. There were 1 3 5 fatalities. This accident prompted maj or changes in federal aviation administration training and improvements in D Doppler radar weather technology. • December 12, 1985. A military-chartered Douglas DC-8, Arrow Air Flight 1285, crashed on takeoff from Gander, Canada, due to icing. There were 2 5 6 fatalities. The flight was transporting members of the U.S. Army's 101st Airborne Division. From Egypt back to Kentucky. The accident drew attention to the hazards of ground icing and the reliance on commercial aviation charters for travel by the U.S. military. • August 16, 1987. Northwest Airlines Flight 2 5 5, a McDonnell Douglas MD- 8 2, crashed after liftoff from Detroit Metropolitan Wayne County International The airport was affected by the flight crew's failure to use the checklist to ensure the flaps and slats were extended for takeoff. There were 1 5 6 fatalities, including 2 on the ground. Aircraft manufacturers and airline flight operations managers learned the importance of checklist design and flight deck procedures that foster checklist item completion. • April 28, 1988. Aloha Airlines Flight 243, a Boeing 73 7, suffered an explosive decompression caused by metal fatigue and corrosion, but was able to land safely in Maui with only one fatality, a flight attendant who was ejected from the aircraft as a large opening was torn in the fuselage and was never found. As a result of the accident, the U . S . Congress passed the Aviation Safety Research Act of 1 9 8 8, which provided for enhanced research in the critical areas of aircraft maintenance and structural technology. Also, in 1 9 9 1, the Aging Aircraft Safety An act was passed, which called for the inspection and repair of certain components even if they show no visible signs of damage. • December 21, 1988. Pan Am Flight 1 0 3, a Boeing 747, suddenly exploded in the sky over Lockerbie, Scotland. All 2 5 9 persons on board were killed, plus an estimated 1 1 on the ground. When British investigators announced a week later that the aircraft was brought down by a bomb, the tragedy became the most deadly act of sabotage ever perpetrated against a U.S. airliner. • February 1, 1991. U.S. Air Flight 1 4 9 3, a Boeing 73 7, collided with a Skywest Metroliner on the runway while landing at Los Angeles International Airport ( LAX ) . Both planes were destroyed in the accident, which killed 3 4 people. The cause of the accident was an error made by an air traffic controller at this extremely busy airport. This type of accident is known as a " runway incursion," a type of accident that was on the list of the NTSB's most wanted safety improvements for many years. • March 3, 1991. All 2 5 people aboard United Airlines Flight 5 8 5, a Boeing 73 7, were killed when the plane crashed after the crew lost control of the aircraft in flight due to a rudder problem during the final approach to Colorado Springs. The aircraft was approximately 1 000 feet above the ground when the upset occurred. The Boeing 737 had an enviable safety record until that time, and the cause of this accident was undetermined by the national transportation safety board for a number of years. Similar Boeing 73 7 rudder problems near Pittsburgh and Richmond later on provided answers to solve the perplexing mystery of the Colorado Springs accident. As a result of the 54-month investigation, improvements have been made to the amount of data collected by crash-survivable flight data recorders so that investigators can arrive at the factors involved in similar accidents with greater efficiency. July 2, 1994. U . S . Air Flight 1 0 1 6, a Douglas D C-9 approaching Charlotte/ Douglas International Airport, with thunderstorm activity in the area, crashed when the crew encountered a wind shear and attempted to abort the landing. There were 37 fatalities, and 2 0 people on board survived the accident. This event brought to an end a 27-month period in which the major or U . S . scheduled airlines did not suffer a passenger fatality. The accident helped convince the federal aviation administration to pass the Sterile Cockpit Rule in 1981 . The rule promotes having only safety-related discussions between the pilots of airliners at certain points of a flight. • September 8, 1994. U.S. Air Boeing Flight 427, a Boeing 73 7, crashed while on Approach to the Greater Pittsburgh International Airport. All 1 3 2 people on board were killed, and the plane was destroyed by impact, making it one of the worst aviation accidents in U . S . history. This accident was extremely similar to the United Flight 5 8 5 rudder control problem which occurred in Colorado Springs. Again, national transportation safety board investigators were baffled at the cause of the uncontrolled rudder problem until another Boeing 73 7 survived a similar situation near Richmond in 1996 . A thermal shock test finally confirmed that the 737 rudders could be subject to a hard over-rudder reversal under certain conditions, and it was ultimately re-engineered to prevent similar recurrences. • October 31, 1994. A Simmons Airlines ATR-72, operating as American Eagle Flight 4184 crashed south of Roselawn, Indiana. The flight was en route from Indianapolis to Chicago's O ' Hare Airport and had been placed in a holding pattern for about 32 minutes because of traffic delays. The weather conditions during the period of holding were characterized by icing, a temperature near freezing, and visible moisture. All 64 passengers and four crewmembers were killed in the accident. The accident called attention to the limitations of autopilots and ice detection in aircraft. • May 11, 1996. ValuJet Flight 592, a Douglas D C-9, crashed into the Everglades shortly after takeoff from Miami International Airport en route to Atlanta. All 1 0 5 passengers and five crewmembers aboard were killed, and an extremely difficult recovery operation was required due to the accident site being in swampy land. This accident was caused by the improper packaging and storage of hazardous materials ( oxygen canisters ), which resulted in a serious aircraft fire and the ultimate bankruptcy of the airline. Partially as a result of the accident, airliners are now required to have fire detection and suppression systems in the cargo holds. • July 17, 1996. TWA Flight 8 00, a Boeing 74 7 on a regularly scheduled flight to Paris, France, crashed into the Atlantic Ocean off the coast of Long Island shortly after takeoff from John F. Kennedy International Airport. All 2 3 0 people on board the aircraft were killed. The cause of the accident was an explosion from a short circuit in a fuel tank onboard the aircraft, related to unusual heat experienced during an extended ground delay. When combined with the previously mentioned crash of ValuJet 595, these two disastrous crashes in 1996 resulted in i n the highest number of fatalities for a single year during the past two decades. The 1996 fatal accident rate per 100,000 departures for scheduled service increased from 0.025 to 0.038 , and the rate per 1 00,000 flight hours rose from 0.016 to 0.023 . As a result of the TWA Flight 800 crash, the industry turned its attention to wiring safety and the national transportation safety board and FBI increased their collaboration process during the early stages of such events, when it is initially unclear whether The crash was due to a safety or security situation. • January 31, 2000. Alaska Airlines Flight 261, a McDonnell Douglas MD-8 3 , en route from Puerto Vallarta, Mexico, to San Francisco, California, reported flight control problems with its horizontal stabilizer and a loss of stability before it crashed into the Pacific Ocean near Point Mugu, California. There were 8 8 fatalities . As a result of the accident, maintenance procedures were under scrutiny. • July 25, 2000. Air France Flight 4590, a Concorde supersonic aircraft, crashed on takeoff from Charles de Gaulle International Airport near Paris after striking a titanium metal strip on the runway that had fallen off of a Continental DC- 1 0. The metal strip punctured a tire of the Concorde, and debris ruptured a fuel tank, causing a serious fire from which the Concorde could not recover. This type of event is known as Foreign Object Debris (FOD) damage when it strikes another aircraft. There were 1 0 9 fatalities. This accident marked the beginning of the end of Concorde. The aircraft was retired 3 years later due to safety concerns and a lack of passengers in the wake of the 911 1 terrorist attacks in New York and Washington. Similar to the Hindenburg accident in 1 9 3 7, this accident helped eliminate an entire mode of air transport. After the Hindenburg accident, the use of airships ceased, and after the Concorde accident, the use of supersonic air travel stopped. • O October 31, 2000. Singapore Airlines Flight 006, a Boeing 74 7, crashed on takeoff in Taipei, Taiwan. There were 83 fatalities. The crew of this aircraft lost situational awareness in a rain storm and attempted to take off on a closed parallel runway, hitting several large pieces of construction equipment. The accident emphasized the need for pilots and air traffic controllers to confirm that a departing aircraft was lined up on the correct runway prior to takeoff. Unfortunately, this runway lesson would have to be repeated again at Lexington, Kentucky in 2006. • November 12, 2001. American Airlines Flight 587, an Airbus 300-600, experienced a loss of control upon initial climb after takeoff and crashed into a residential area in Queens, NY, killing 265. The accident was caused by excessive overuse of the rudder to counter a wake turbulence problem, resulting in a separation of the vertical stabilizer from the aircraft. The accident prompted significant reconsideration of how certain aerodynamic principles are taught to pilots. • May 7, 2002. China Northern Airlines Flight 6136 , a McDonnell Douglas MD- 82 from Beijing to Dalian, China, crashed after a troubled passenger set the cabin on fire with gasoline to obtain the proceeds from seven insurance policies. There were 1 1 2 fatalities. • May 25, 2002. China Airlines Flight 611, a Boeing 747 from Taiwan to Hong Kong broke up in flight and crashed due to a previous inadequate structural repair to the hull. There were 225 fatalities. January 3, 2004. Flash Airlines Flight 604, a Boeing 737 from Egypt to France, crashed in the Red Sea with 1 4 8 fatalities. The cause of the accident was the distraction of the pilot and spatial disorientation. • August 14, 2005. Helios Airways Flight 522, a Boeing 737 traveling from Cyprus to Greece, lost pressurization and crashed with 1 2 1 fatalities. The apparent cause The accident was caused by an improper setting of the cabin pressurization switch, which incapacitated the crew and passengers due to hypoxia caused by the depressurization of the aircraft. The plane crashed near Athens after fuel starvation of the engines. • Sep tem ber 5 , 2005. Mandala Flight 091, a Boeing 737, crashed on takeoff in Indonesia. There were 1 1 7 fatalities. The cause of the accident was a failure to use the checklist, resulting in the improper setting of the flaps and slats, which were not placed in the takeoff configuration. This accident was sadly reminiscent of the 1 9 8 7 MD- 8 2 Detroit accident covered previously in this list. • May 3, 2006. Armavia Flight 9 6 7, an Airbus 320, crashed into the Black Sea at night on a missed approach in poor weather near Adler/Sochi Airport in Russia. There were 1 1 3 fatalities. The cause of this accident was a controlled flight into terrain (water) while climbing out with weather conditions below established minima. The official investigative report cited the psycho-emotional stress level of the captain, poor cockpit resource management, and air traffic control problems. • July 9, 2006. In another domestic accident, S7 Airlines Flight 778, an Airbus 310 from Moscow, crashed in Siberia with 1 2 5 fatalities. The aircraft failed to decelerate on landing due to inadvertent movement of one throttle to the forward thrust position, which caused the plane to overrun the runway and crash into a concrete barricade. • August 27, 2006. Comair Flight 191, a CRJ- 100 crashed on takeoff from Lexington, Kentucky. The aircraft took off on the wrong ( short) runway due to a loss of situation awareness, and the crew's nonpertinent conversations were in violation of the federal aviation administration " Sterile Cockpit Rule." • September 29, 2006. GTA Flight 1 907, a new Boeing 737-800, suffered a midair collision at Flight Level 3 70 with an Embraer Legacy business jet on a domestic flight over the Brazilian Amazon jungle. There were 1 54 fatalities as the Boeing 7 3 7 plunged to the ground while the Legacy continued flying and was able to safely land. Although the Brazilian authorities initially charged the pilots of the Legacy with negligence, the national transportation safety board report cited a combination of air traffic control errors that placed both aircraft on the same airway at the same altitude. • July 17, 2007. Tam Airlines Flight 3054, an Airbus 320 on another domestic Brazilian flight overran the runway and crashed on landing at Congonhas Airport in Sao Paulo. There were 1 8 7 fatalities. The investigation indicated that the aircraft thrust reverser was deactivated, causing the plane to run off this short runway. August 20, 2008. Spanair Flight JK 5022, an MD-82, crashed on takeoff in Madrid, Spain. There were 1 54 fatalities. The investigation indicated that after an interruption, the aircraft tried to take off in the wrong configuration with the flaps and slats retracted. • January 15, 2009. The " Miracle on the Hudson." U.S. Airways Flight 1 549, an Airbus 320 successfully ditched in the Hudson River near New York City after takeoff from LaGuardia Airport. The aircraft was disabled by striking a flock of Canadian Geese and lost thrust in both engines during its initial climb out after takeoff. All 1 5 5 occupants safely evacuated the airliner. The national transportation safety board cited excellent crew resource management, safety equipment, and fast rescue response from ferry boat operators. • February 12, 2009. Colgan Air Flight 3407, a Bombardier Dash 8, stalled and crashed on final approach to Buffalo, NY. There were 49 fatalities. The investigation revealed that the crew failed to monitor the airspeed in icing conditions and took an inappropriate response to the stick shaker stall alarm system, as well as failure to comply with the federal aviation administration Sterile Cockpit rule. As a result of the accident, the federal aviation administration passed the Airline Safety and federal aviation administration Extension Act of 2010, which requires airline first officers to have an Airline Transport Pilot certificate. The rule essentially raises the experience level of new first officers since the certificate requires 1,500 hours of total flight time experience unless certain strict educational conditions have been met. • April 2015, 2009. Known as "Ash Thursday," Iceland's Eyj adj allay skull Volcano Erupted, halting planes traversing the Atlantic Ocean. There were no fatalities, but it resulted in $200 million in losses a day from canceled flights and closures. • Novem ber 4, 2009 . Qantas Flight 3 2 had an uncontained engine failure on engine number two. The pilots received 54 computer messages alerting them of the failure. Pilots had to make an emergency landing at the Singapore Changi Airport. The failure was the first of this kind in the Airbus 3 8 0, one of the largest passenger aircraft. • June 1, 2009. Air France Flight 447, an Airbus 3 3 0 from Rio de Janeiro to Paris, Crashed into the Atlantic Ocean. There were 228 fatalities. The aircraft crashed in bad weather after receiving unusual airspeed indications from the plane's Pitot Static System. • July 6, 2013. Asiana Flight 2 1 4, a Boeing 777, was landing at the San Francisco International Airport. There were three fatalities resulting from the accident. The plane crashed short of the runway, with the landing gear and the tail striking the sea wall. national transportation safety board experts found that the automation logic in the cockpit was not intuitive for the auto-throttle system, among other factors. Figure 1 - 5 shows the national transportation safety board is investigating the wreckage of Asiana Flight 214. • March 8, 2014. Malaysia Flight 370, a Boeing 777, departed Kuala Lumpur International Airport in Malaysia headed toward Beijing Capital International Airport. The flight deviated from its flight path and eventually fell off the radar. As of 206, the search for this plane is ongoing as its wreckage has yet to be found in the Indian Ocean. • July 17, 2014. While crossing over from Ukraine to Kuala Lumpur International Airport in Malaysia, Malaysia Flight 1 7, a Boeing 777, was shot down with a surface-to-air missile. There were 2 9 8 fatalities. The accident is covered in more detail in Chapter 14 of this book. • March 24, 2015. Germanwings 9525, an Airbus 320, flying from Barcelona, Spain, to Dusseldorf, Germany, was deliberately crashed in the Alps by a suicidal pilot. There were 1 5 0 fatalities. This crash has raised questions about examining and treating mental health issues for pilots and is covered in more detail in Chapter 14 of this book. Despite numerous accidents throughout the decades, there have been small milestone improvements in aviation safety along the way. In 1 9 65, the federal aviation administration stipulated stricter aircraft evacuation standards. Five years later, Congress enacted the Occupational Safety and Health Act (OSHA) governs workplace health and safety in both the federal government and private sector. The purpose of O system hazard analysis is to make sure employees are working in an environment that is free of hazards such as toxic materials, mechanical dangers, excessive noise levels, and unsanitary conditions. Although this act is not aviation-specific, it did focus the attention of the entire United States on safety and helped create awareness of the need for continuous improvement in commercial aviation safety, among other industries. Since safety is a broad term encompassing many facets, it is easy to be left wondering just how professionals quantify whether or not something is safe. It turns out that measuring safety is actually a difficult task. Although, at first glance, it may seem that accidents are an obvious way to measure safety, we should think twice. Does the fact that a company has not had an accident in the past 5 years mean that it is safe? If you are tempted to answer yes, consider that the company could have an accident tomorrow. If it does have the accident, does it mean that the company was not safe today? The question comes up constantly when safety managers attempt to justify the cost of certain initiatives that are being recommended, only to be met by the skeptical questions of those controlling the finances of an airline. Often, such leaders will look at a safety manager and ask, " Can you prove to me that this initiative will prevent an accident? " The answer to such a question, in short, is no. There is no way to prove such a relationship because if the initiative works, it will prevent the confirmatory evidence from being produced {there will be no accident). In the safety business, such a conundrum is called " trying to prove a negative." How in the world would one go about producing scientific evidence to prove a negative? The people controlling the purse strings want hard data that show the money they are investing will achieve a certain payoff, whether that be in terms of lives saved, dollars preserved, or safety improved. In reality, improving safety is hypothetical, with usually no hard evidence to justify initiatives, particularly when the ideas are based on non-accident data. The result is that it is often an arduous task to convince others of the monetary trade-off needed to implement a safety improvement. The challenges of measuring safety notwithstanding, it is certainly desirable to do so, and safety managers speak in terms of Safety Performance Indicators, or SPis. Such managers use SPis to get a quantitative feel for how healthy the safety of their operation is at any given time, to measure whether safety is improving or deteriorating, and to compare safety in different segments of a given operation. When properly designed and measured, SPis can provide the following data: • Early warnings that a serious incident or accident may be around the corner • How often are preset limits breached, or how often are they almost exceeded • How willing are employees to complete and submit voluntary safety reports • The frequency with which specific events are occurring • The effectiveness of new strategies and policies • Different benchmarks for current practices in order to measure future initiatives Measuring safety can paint either a big-picture view of what is going on in an organization or a micro view of performance, sometimes down to the individual level. Both depictions are useful for trying to understand what is going on in an organization. However, does SPIS capture all the data necessary to make decisions when managing a safety program? What is missed? Figures 1-6 show an example of a cavalier approach toward safety that sometimes never gets noticed but can cause significant problems. In the figure, a catering agent at a major airport is seen jumping between a truck and the galley door of an aircraft. The agent was in a rush and had parked the truck at an inappropriate angle. She did not realize the misalignment until she was attempting to walk across the ramp from the catering truck to the aircraft. Instead of taking the time to repark the truck so that the ramp and handrails could be properly placed to safely walk between the truck and the jet, the catering agent instead chose to leap back and forth numerous times as the jet was serviced. A small misstep could have resulted in a fall to the ramp some 20 feet below, severely injuring, if not killing, the agent and anyone on the ramp during the event. In the picture, the aircraft and catering truck symbols have been removed to protect the operators' identities. REACTIVE, PROACTIVE, AND PREDICTIVE SA FETY One of the key learning outcomes for anyone attempting to learn modern commercial aviation safety is to recognize the shift in philosophy for how safety is managed. The philosophy is anchored in the advice proffered by many parents to their children, "An ounce of prevention is worth a pound of cure." The question applies particularly well to how we face hazards as aviation professionals. Are we going to just cope with hazards as we become aware of them, or is there a more comprehensive approach for managing all the hazards that take aim at our operation? But how do we, as aviation professionals, follow such a philosophy on a day-to-day basis? The execution of the idea proves far trickier than the concept itself. All of us generally face aviation hazards actively. We recognize safety threats when they appear and do something to either avoid or mitigate the hazard. That type of active safety is pretty obvious and straightforward. For example, pilots may visually detect a weather buildup on climb-out and opt to make a 20-degree heading change to avoid the buildup. So, we use active safety all the time, but it is only one of several dimensions of safety where we can address hazards. After the first accident of the Wright Flyer in 1908, we realized that active safety alone was insufficient to fully detect hazards to flights. Relying on rather limited human perception to detect hazards in the highly complex arena of aviation will let us down time after time. The relatively low accident rate of today is largely the result of investigators who studied accidents to determine previously unknown or underpublicized hazards and who then offered practical recommendations to prevent future mishaps. Aviation is a dynamic industry, so we can never stay static in our processes. How we approach safety in this industry is a major part of adapting to and addressing hazards in the workplace. In the early days, knowledge and experiences were shared verbally. Word got around quickly, and everyone benefited from one aviator's " close call." Safety concerns were addressed as they occurred, a safety culture known as reactive safety. Today, we operate in a much more complex environment with barely any time to share our personal lessons learned with anyone beyond our crewmates, let alone a viable method in which to " get the word out." So, if we do not have time to " hangar fly" or " socialize" as aviators, how do we get the word out to others so they do not have to learn lessons the hard way? Many programs have been developed for commercial aviation use. The Aviation Safety Action Program (ASAP) and Aviation Safety Reporting System (ASRS) are similar programs that attempt to tackle the issue. Both programs entail written reports voluntarily submitted by pilots. ASAP is a proactive safety initiative promoted by the federal aviation administration and operated by each airline. aviation safety report system is managed by national aeronautics and space administration and is open to report submissions by all pilots, whether or not they are affiliated with an airline. Both programs are designed to capture hazards and errors detected by aviators and distribute that information throughout the industry so that all may benefit. ASAP and aviation safety report system also provide safety managers with evidence of risk that may otherwise be invisible so that risk management actions can be taken to improve safety. Aviation professionals make errors in all phases of flight or maintenance, regardless of experience. The details of a particular error are far more valuable than the results gained by any punitive measures, such as bad marks on personnel records or punishment. Thus, a healthy safety culture enthusiastically encourages the reporting of errors and hazards in this program. Another successful program is the Flight Operations Quality Assurance. (FOQA) . This program uses the analysis of routine flight data to detect, measure, and mitigate hazards while promoting the proper use of data for safety. It is about safety enhancement without the accident! In other words, much like ASAP, we do not have to wait for bad events to occur so that we can learn how to prevent them. The flight operations quality assurance process entails aggregating data from multiple flights before processing that data through software to search for trends that point to unsafe underlying conditions, such as poorly designed procedures, normalization of deviance, or unsafe external conditions. Generally, there is no need to investigate the individual data associated with a particular flight. However, determining the cause of a trend may require an evaluation of individual flights feeding that trend. A third noteworthy program is the Line Operations Safety Audit (LOSA), a nonpunitive, unobtrusive, peer-to-peer flight deck observation program that collects safety-related flight data during normal operations in order to assess safety margins and improvement measures. The purpose behind LOSA is to provide leaders with early warnings of systemic safety problems. Basically, it is a " safety" cholesterol check. It works by selecting and training highly qualified pilots to ride on flight deck jump seats during routine flights to record the threats encountered by aircrew, the types of errors committed, and how the crews managed those threats and errors in order to maintain safety. How crews manage threats and errors provides excellent insight into training and organizational culture. The Line Operations Safety Audit observers also study how pilots communicate and coordinate actions with each other, with cabin crewmembers, with ramp agents, with air traffic controllers and with airline dispatchers. LOSA observers can also perform a carefully structured interview to collect pilot input for safety improvement. Some benefits of using LOSA include systematically and scientifically identifying the strengths and weaknesses of normal operations, decreasing the frequency of undesirable events, assessing the quality and usability of procedures, detecting inappropriate techniques, identifying design issues with automation as evidenced through mode errors and aircrew use, and detecting normalization of deviance in the form of workarounds and shortcuts used by aircrew, air traffic controllers, and dispatchers. Recently, there has been talk of evolving the philosophy past production and into the realm of prediction. Predictive safety is the investigation of potential hazards that do not yet exist, but that might cause damage the very first time they make an appearance. Some air safety investigators believe that predictive safety is a key missing dimension of hazard management. They claim that any successful effort to further lower our accident rate, must attempt to attack hazards before they present themselves, in addition to relying on the active, reactive, and proactive dimensions of safety. An example of predictive safety is addressing potential hazards that may emerge when a flight department starts operating a new type of aircraft. If the flight department is used to operating small aircraft and decides to purchase a larger aircraft, predictive safety may uncover that current snow removal practices at the airport where the aircraft will be based will not provide sufficient wingtip clearance from snow banks on certain taxiways now that longer wingspans are involved. Such a predictive determination allows the operator to work with the airfield manager to adjust snow-clearing procedures prior to the delivery of the new aircraft. Continuing with our example, let us discuss what could happen without the use of predictive safety. If the crew of the newly purchased aircraft launches on their first wintry departure and stops their taxi due to insufficient wingtip clearance, the hazard is managed through the use of active safety. If the same crew mistakenly taxies their wingtip into the snow bank, perhaps due to poor visibility, then we learn about the hazard through reactive safety. If the same crew notices the growing snow bank during a snowstorm and reports that it does not yet pose a hazard but might do so to subsequent users of the taxiway, we are talking about proactive safety. Many aviators operate only in the active dimension of safety. That is a truly important dimension, but it is just one of several. If safety managers want to take full advantage of resources, then they should think across the entire spectrum of safety, including reactive investigations and proactive data feeds. Chapter 7 will discuss proactive safety in more detail, and Chapter 14 will discuss the emerging dimension of predictive safety to include how artificial intelligence may be used to open up the full power of short-term predictive safety. aviation safety report system EXAMPLES Everyone in the aviation community has the ability to affect safety. The examples below are taken from the aviation safety report system and show that there are many players in the safety value chain. These examples are provided throughout the book to illustrate safety issues in the actual words of those commercial aviation professionals who experienced a safety event. The italicized portions that follow are the actual words used by aviation professionals to report the situation that they faced and the outcome they experienced. Following each narrative there is a question posed to help the reader connect the report with the content of the chapter. MAINTENANCE Title: Hydraulic system: crossed pressure lines. While troubleshooting the cause of two previous replacements of an A-3 1 9 's hydraulic system reservoir pressurization manifold, a Maintenance Technician found that "crisscrossed " pneumatic pressure lines were preventing pressurization of the Blue hydraulic system. After discovering that we were going to install [an A-3 1 9 's] hydraulic reservoir pressure manifold for the third time, I decided to figure out why the. . manifolds were not pressurizing the Blue hydraulic reservoir to 50 PSI. After a few hours of troubleshooting the problem, I found that the left engine {pneumatic] supply line in the left wheel well . . . was connected to a "tee " [fitting] in the line that supplies all three hydraulic reservoirs, thereby bypassing the {pressurization] manifold completely and probably over-pressurizing the reservoirs. The B lue system pneumatic supply line (going to the hydraulic reservoir) was connected to a "union" [fitting}, which is the manifold supply connection from the left engine, thereby never supplying pneumatic pressure to the B lue reservoir. So the lines were criss-crossed. B o th "B " nuts will fit on either connection, and there is plenty of room for the lines to cross and not chafe on anything. It appeared that neither line had been replaced . . . . When an Airbus comes into the hangar, a low-pressure check of Each green, Yellow, and Blue hydraulic reservoir's head pressure is performed using ground service air. Although the Blue reservoir's head pressure was above the 22 PSI that sets off warnings in the cockpit, it was not possible to increase the head pressure by applying service air to see if the reservoir pressurization manifold was functioning. When the Blue head pressure did not respond, the thought was that the manifold was again at fault. The aircraft had been flying for some time with the lines crossed, but since the Blue hydraulic reservoir head pressure never went below 22 PSI, no discrepancies were noted. Maintenance history showed the aircraft did have hydraulic issues with the Green and Yellow systems oozing hydraulic fluid, but those discrepancies were probably caused by high reservoir head pressures from the crossed pneumatic supply lines. Question for the reader: what are the ethical implications of not looking for the root issues behind recurring maintenance problems? FLIGHT OPERATIONS Title: After an unexpected " hard bank " resulted in a hard landing, an ERJ 1 4 5 crew discovered that icing may have been the cause. air traffic control . . . descended us to 2,000 feet and vectored us for the approach. We were having a little problem picking up the localizer; however, we finally got a strong signal before the FAF and decided to fly the approach . . . . The Captain called, " Visual," and I said, "Landing." I tried to turn off the autopilot and had a hard time getting the autopilot warning off. The Captain called, "Speed." I had gotten slow by about 3-4 knots, and we were about 2 0 0 feet off the ground. I said, " Correcting," added power , and had no issue from there. We crossed the threshold, and I started my crosswind correction, and that is when the airplane took a hard bank to the right. The Captain and I did everything we could to get the airplane on the ground. The landing was hard, but we decided that the plane could be tipped in. We asked to hold short of the center runway to collect ourselves, talk to the Flight Attendant, and resume the taxi. "Rudder INOP " displayed on the EICAS during taxi in. We got to the gate and deplaned, then started making phone calls to report the rudder and hard landing. After that was done, a ramp agent continuing airworthines management exposition up and let us know that there was some limited wing damage. We both went outside to see, and it was then that we saw a considerable load of ice build up on all leading edges and engine nacelles. Question for the reader: how can pilots use the cabin crew as an extension of their senses outside of the flight deck? AIR TRAFFIC CoNTROL Title: A Boeing 7 3 7 was dispatched without fuel for an alternate airport. As the aircraft descended for landing through 4,000 feet, onboard weather radar detected thunderstorm cells. Credit must now be given to the federal aviation administration for the best job by a controller, which I have seen in 1 9 years of military and civilian flying. The controller began by using a concise stream of descriptive communications to paint a picture of weather location, intensity, reported microburst activity, winds, and runway availability. He then went on to describe various options available to us. At this point, the flight conditions were VFR, but we were maneuvering to avoid several Level 4 returns on our radar. To facilitate our situational awareness, the controller turned the lights on Runway 08 to their highest setting . . . . Our fuel was now 5, 2 0 0 lbs. And Runway 8 appeared clearly in front and to our right. . . . The aircraft touched down on centerline approximately 1100 feet from the threshold . . . . I knew instinctively that time was not on my side, and every moment spent maneuvering at 2,000 feet with the fuel I had was quickly taking away options, and none of them were very good. This aircraft made it safely on deck due to the outstanding work of the federal aviation administration and the skills of the flight crew. Question for the reader: what role does a flight dispatcher play in the safety value chain? RAMP OPERATIONS Title: A communications breakdown between the cockpit and a tug driver at a foreign location led to a pushback with no one in positive control of the aircraft and to some soul-searching afterward by the involved flight crew. The pushback began in a normal fashion. Engine start was uneventful until the after-start flows were accomplished. At that point, we experienced a problem with the left bleed air valve . . . . The minimum equipment list showed this as a return-to-gate item. At this point, I told the mechanic we needed to be tugged back in. His response sounded like he was asking us to release the parking brake; however, neither of We quite understood what he had said about the brakes. I asked him if he was asking us to release the parking brake, to which he responded, "Release the parking brake." I released the parking brake, and the tug operation commenced. With the tug operation underway, I turned my attention to the logbook, thinking about how I was going to write up this problem. The First Officer put away the quick reference handbook and then looked over the MEL, which listed restrictions on flying in icing conditions. What to me seemed like a few seconds after we began to be tugged, the First Officer rhetorically asked, " Where is this guy taking us? " As I looked up, I saw the end of the paved ramp approaching rapidly and heard the The First Officer said something about stopping the aircraft. At that point, we were b o both simultaneously on the brakes . . . . After leaving about 2 0 feet of skid marks on the ramp, the aircraft continuing airworthines management exposition to a stop with the nosewheel approximately 8 feet from the end of the paved surface . . . and without the tug connected!! After stopping the aircraft, shutting down the engines, and trying to comprehend what had just happened, my next concern was the location of the mechanic and whether he was okay. He was okay. Although this mechanic speaks fairly good English, I was truly surprised at the level of communications breakdown that had just occurred . . . . He told me he thought I was telling him I was releasing the parking brake. Once we started rolling, he did not tell us to stop but instead simply unplugged his headset and got out of the way. What lessons can be learned or relearned from all of this? First of all, this is a reminder of something we all know: that being tugged is an operation that requires someone to monitor the aircraft. Second, never assume anything. Since we never saw the tug pull away (it pulled away while we were in the books), and we were told to release the parking brake; we thought we were under tow . . . . Also, next time I have determined I need to do a return to the gate, I will shut down the engines sooner. . . . We were so distracted by what was going on that neither of us thought of shutting down the engines, nor did it seem critical at the moment since we thought we were under tow . . . . Thank goodness no one was hurt, no metal was bent, and no careers were put in jeopardy, but we sure continuing airworthines management exposition darn close. Question for the reader: what specific actions could the flight crew have taken to prevent such a situation? CABIN CREW Title: In the event that inebriated passengers manage to get through the boarding process, sharp cabin crews can prevent in-flight disruptions by removing them before takeoff. I was working as Flight A attendant #1 when Flight Attendant #4 informed me that there were 1 1 first T-class passengers instead of the 1 0 listed on my final paperwork. I called out names on my list and matched them with all passengers except for one in seat 1 X. She told me her name, which was also the woman's name in seat 1 Y. So, I asked to see their boarding passes and 1 Y handed me the one for her connecting flight. . . . She said she didn't have the one for this flight. I asked for her identification and verified that she was who she claimed to be. I then asked the person in 1X for her identification, and she said she didn't have it. I told her she did, or she wouldn't be on the plane. I called the Captain, and he said she had better show some identification now, or we were going to return to the gate. She got out of her seat, stood directly in front of me, and said quietly, "Oh, I'll show you something." She then very slowly lifted the flap of her purse and pulled out her identification. She was not who she claimed to be. I asked her if she had been drinking, and she said, " Well, yeah." I had her sit back down because she was swaying and talking very slowly. I called the Captain again to inform him of the passenger being drunk and lying about who she was. He said the agents were meeting the plane back at the gate . . . . As the inebriated passenger exited the airplane, she turned to me and said, " What a safe airline you run." I said, " We try to keep it as safe as possible. Good-bye." Question for the reader: where did the safety system fail to allow this situation to occur in the first place? Modern commercial aviation is considered an ult a-safe high-risk industry (USHRI ) in that, it manages to operate with a great degree of safety in a high-risk environment. Safety may not be an airline's top priority, and making money is, but safety has to be ever-present in order for an airline to be profitable financially. Since efficiency is often a natural byproduct of safety, a commercial aviation operator that pursues safety processes will often also gain operational efficiencies. Safety philosophy is important to understand, not only because it underpins most of the contents in this book but also because safety processes are not necessarily obvious to the untrained. Most commercial aviation professionals have come a long way from attributing negative effects to unknown powers, but some professionals around the world still see accidents as " acts of God." Doing so brings psychological comfort because it removes ties to the truth that most accidents are preventable and, therefore, that we have an ethical obligation and often the ability to prevent such tragedies. Safety requires careful thought, analysis, and action. For example, the principle of multi-causality, if not properly understood, can lead to " witch hunts " against certain people and short-sighted answers to what are always complex safety issues. Understanding multi-causality is fundamental to grasp how accidents happen and, therefore to break a developing chain of events before they result in tragedy. Every aviation professionals should feel an ethical obligation to detect a growing accident chain and have the moral courage to intervene to break the sequence before the tragedy ensues. Security and safety may sound like the same term, but in reality, they are quite different since the factors that lead up to intentional acts of harm and the factors that produce accidents are quite different. Therefore, different approaches are required to prevent accidents rather than terrorist attacks. The history of aviation safety is intriguing and constantly changing, including the high-tech approaches used at this very moment. Over the past half-century, commercial aviation has come to depend less on accident investigation and more on innovative measures to prevent accidents. We call it the evolution from reactive to proactive safety, and we measure the progress through statistical analyses. The next chapter will expound on accident theory by examining causal chains and types of causes, different models used to understand how the causes combine to produce accidents, the mysterious role played by luck in accidents and incidents, and the different types of hazards that can imperil safe operations.